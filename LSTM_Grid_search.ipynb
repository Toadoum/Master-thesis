{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "eCXrQdNg9pen",
    "outputId": "e9edf1c0-e91e-4ab3-f34d-2fa12b3dc77f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vADdQFKYL40G",
    "outputId": "85c0ed40-979b-44b0-ed57-e830eb399e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "cd '/content/drive/My Drive/Colab Notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "colab_type": "code",
    "id": "konObw-FL706",
    "outputId": "a67077d6-a28f-46a1-d12d-ad8089f81524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BirthData2.xlsx                         Sari_NN_byRock.ipynb\n",
      "'Copie de Bienvenue dans Colaboratory'   Time_serie2.ipynb\n",
      " distplot.png                            ts.csv\n",
      " lstm1plot.png                           tsplot.png\n",
      " lstm4plot.png                           Untitled0.ipynb\n",
      " LSTM_Grid_search.ipynb                  Untitled1.ipynb\n",
      " LSTM_model.ipynb                        Untitled2.ipynb\n",
      " LSTM_model.py\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWyP0pNaL8W-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9Eww8AmL9O6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "qZRsKSnw93ie",
    "outputId": "61084dd6-7457-4bf1-df8e-f9bf046dd51b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAF3CAYAAABnvQURAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVJPDFaSJEk9MVhJkiT15A9BYe+jOrNb2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np                       \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "plt.style.use('seaborn-notebook')\n",
    "\n",
    "\n",
    "ts=pd.read_csv(\"ts.csv\", delimiter=',')\n",
    "from datetime import datetime\n",
    "con=ts['Draw.up.date']\n",
    "ts['Draw.up.date']=pd.to_datetime(ts['Draw.up.date'])\n",
    "ts.set_index('Draw.up.date', inplace=True)\n",
    "#check datatype of index\n",
    "ts.index\n",
    "\n",
    "# weekly baseline\n",
    "ts['baseline'] = ts.daily_count.shift(1)\n",
    "\n",
    "# moving averages\n",
    "ts['MVA2'] = ts.daily_count.rolling(2).mean().shift(1)\n",
    "ts['MVA4'] = ts.daily_count.rolling(4).mean().shift(1)\n",
    "ts['MVA6'] = ts.daily_count.rolling(6).mean().shift(1)\n",
    "ts['MVA8'] = ts.daily_count.rolling(8).mean().shift(1)\n",
    "ts.head(9)\n",
    "\n",
    "ts.drop(ts.index[:8], inplace=True)\n",
    "ts.head(8)\n",
    "\n",
    "#distribution plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.distplot(ts.MVA8, hist_kws={'alpha': 0.1}, kde = True, kde_kws={'alpha': 1})\n",
    "plt.savefig('lstm1plot.png')\n",
    "\n",
    "#Define the training set\n",
    "training_set = ts['MVA8'].values\n",
    "\n",
    "training_set = training_set.reshape(-1,1)\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc=MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled=sc.fit_transform(training_set[0:380])\n",
    "test_set_scaled= sc.fit_transform(training_set[332:449])\n",
    "\n",
    "\n",
    "#Creating a data structure with 48 timesteps and 1 output\n",
    "#train\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "for i in range(48, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-48:i,0])\n",
    "    Y_train.append(training_set_scaled[i,0])\n",
    "X_train, Y_train=np.array(X_train), np.array(Y_train)\n",
    "\n",
    "#test\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "for i in range(48, len(test_set_scaled)):\n",
    "    X_test.append(test_set_scaled[i-48:i,0])\n",
    "    Y_test.append(test_set_scaled[i,0])\n",
    "    \n",
    "X_test,Y_test=np.array(X_test),np.array(Y_test)\n",
    "\n",
    "#Reshaping\n",
    "X_train=np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
    "X_test=np.array(X_test)\n",
    "X_test=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JKkcvfiu6LWb",
    "outputId": "c0f2535f-2cbc-4c5e-9c8a-f8e333c25ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evolution of the gridsearch: step  1\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 56s 241ms/step - loss: 0.1323 - val_loss: 0.0626\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0596 - val_loss: 0.0238\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0423 - val_loss: 0.0241\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0408 - val_loss: 0.0238\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0369 - val_loss: 0.0235\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0377 - val_loss: 0.0232\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0354 - val_loss: 0.0231\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0346 - val_loss: 0.0231\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0336 - val_loss: 0.0234\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0343 - val_loss: 0.0232\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0328 - val_loss: 0.0230\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0327 - val_loss: 0.0229\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0323 - val_loss: 0.0230\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0318 - val_loss: 0.0229\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0314 - val_loss: 0.0223\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0314 - val_loss: 0.0222\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0313 - val_loss: 0.0218\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0331 - val_loss: 0.0214\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0308 - val_loss: 0.0209\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0297 - val_loss: 0.0208\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0292 - val_loss: 0.0204\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0297 - val_loss: 0.0200\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0294 - val_loss: 0.0194\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0276 - val_loss: 0.0190\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0271 - val_loss: 0.0186\n",
      "evolution of the gridsearch: step  2\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 56s 242ms/step - loss: 0.1093 - val_loss: 0.0468\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0478 - val_loss: 0.0326\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0389 - val_loss: 0.0254\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0377 - val_loss: 0.0252\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0366 - val_loss: 0.0254\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0357 - val_loss: 0.0256\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0351 - val_loss: 0.0258\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0349 - val_loss: 0.0259\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0346 - val_loss: 0.0261\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0351 - val_loss: 0.0261\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0342 - val_loss: 0.0259\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0345 - val_loss: 0.0258\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0340 - val_loss: 0.0258\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0340 - val_loss: 0.0256\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0350 - val_loss: 0.0254\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0350 - val_loss: 0.0255\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0344 - val_loss: 0.0251\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0335 - val_loss: 0.0251\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0332 - val_loss: 0.0247\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0331 - val_loss: 0.0247\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0330 - val_loss: 0.0244\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0323 - val_loss: 0.0243\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0322 - val_loss: 0.0241\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0328 - val_loss: 0.0238\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0335 - val_loss: 0.0233\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0324 - val_loss: 0.0231\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0312 - val_loss: 0.0228\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0304 - val_loss: 0.0221\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0299 - val_loss: 0.0214\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0294 - val_loss: 0.0210\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0291 - val_loss: 0.0203\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0277 - val_loss: 0.0196\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0262 - val_loss: 0.0191\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0248 - val_loss: 0.0180\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0232 - val_loss: 0.0168\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0218 - val_loss: 0.0163\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0207 - val_loss: 0.0154\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0191 - val_loss: 0.0146\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0189 - val_loss: 0.0148\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0171 - val_loss: 0.0129\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0162 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0132\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0153 - val_loss: 0.0112\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0126 - val_loss: 0.0097\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0115 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0105 - val_loss: 0.0083\n",
      "evolution of the gridsearch: step  3\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 56s 242ms/step - loss: 0.1075 - val_loss: 0.0376\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0435 - val_loss: 0.0294\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0389 - val_loss: 0.0246\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0372 - val_loss: 0.0247\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0367 - val_loss: 0.0245\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0355 - val_loss: 0.0247\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0354 - val_loss: 0.0252\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0347 - val_loss: 0.0252\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0344 - val_loss: 0.0251\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0342 - val_loss: 0.0252\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0344 - val_loss: 0.0249\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0342 - val_loss: 0.0249\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0336 - val_loss: 0.0248\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0340 - val_loss: 0.0245\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0336 - val_loss: 0.0243\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0339 - val_loss: 0.0244\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0334 - val_loss: 0.0240\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0330 - val_loss: 0.0243\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0327 - val_loss: 0.0239\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0327 - val_loss: 0.0240\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0325 - val_loss: 0.0237\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0333 - val_loss: 0.0234\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0321 - val_loss: 0.0232\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0317 - val_loss: 0.0233\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0320 - val_loss: 0.0228\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0319 - val_loss: 0.0226\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0320 - val_loss: 0.0229\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0313 - val_loss: 0.0224\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0308 - val_loss: 0.0220\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0307 - val_loss: 0.0222\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0312 - val_loss: 0.0219\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0304 - val_loss: 0.0214\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0305 - val_loss: 0.0210\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0292 - val_loss: 0.0207\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0289 - val_loss: 0.0205\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0287 - val_loss: 0.0204\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0286 - val_loss: 0.0198\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0276 - val_loss: 0.0193\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0273 - val_loss: 0.0187\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0266 - val_loss: 0.0184\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0260 - val_loss: 0.0177\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0249 - val_loss: 0.0173\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0240 - val_loss: 0.0165\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0234 - val_loss: 0.0155\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0223 - val_loss: 0.0153\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0213 - val_loss: 0.0150\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0207 - val_loss: 0.0140\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0196 - val_loss: 0.0131\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0184 - val_loss: 0.0133\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0181 - val_loss: 0.0128\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0150 - val_loss: 0.0108\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0096\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0094\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0115 - val_loss: 0.0085\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0077 - val_loss: 0.0062\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0075 - val_loss: 0.0061\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0068 - val_loss: 0.0082\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "evolution of the gridsearch: step  4\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 54s 233ms/step - loss: 0.0824 - val_loss: 0.0385\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0417 - val_loss: 0.0258\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0401 - val_loss: 0.0279\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0355 - val_loss: 0.0244\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0251\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0244\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0348 - val_loss: 0.0247\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0343 - val_loss: 0.0246\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0247\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0248\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0250\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0249\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0249\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0254\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0251\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0249\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0252\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0332 - val_loss: 0.0250\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0248\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0331 - val_loss: 0.0247\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0333 - val_loss: 0.0245\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0242\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0242\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0240\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0326 - val_loss: 0.0245\n",
      "evolution of the gridsearch: step  5\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 57s 244ms/step - loss: 0.1511 - val_loss: 0.0922\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1042 - val_loss: 0.0563\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0682 - val_loss: 0.0282\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0439 - val_loss: 0.0296\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0454 - val_loss: 0.0266\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0410 - val_loss: 0.0253\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0419 - val_loss: 0.0253\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0400 - val_loss: 0.0250\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0389 - val_loss: 0.0254\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0381 - val_loss: 0.0251\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0373 - val_loss: 0.0253\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0366 - val_loss: 0.0257\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0359 - val_loss: 0.0259\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0363 - val_loss: 0.0264\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0355 - val_loss: 0.0262\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0263\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0356 - val_loss: 0.0273\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0362 - val_loss: 0.0258\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0262\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0353 - val_loss: 0.0263\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0350 - val_loss: 0.0257\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0256\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0258\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0255\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0255\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0257\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0252\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0250\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0252\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0342 - val_loss: 0.0249\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0256\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0247\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0245\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0244\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0328 - val_loss: 0.0245\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0327 - val_loss: 0.0242\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0241\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0243\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0322 - val_loss: 0.0238\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0323 - val_loss: 0.0239\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0318 - val_loss: 0.0239\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0316 - val_loss: 0.0231\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0316 - val_loss: 0.0228\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0309 - val_loss: 0.0230\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0226\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0304 - val_loss: 0.0225\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0300 - val_loss: 0.0224\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0297 - val_loss: 0.0219\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0292 - val_loss: 0.0217\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0291 - val_loss: 0.0214\n",
      "evolution of the gridsearch: step  6\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 56s 242ms/step - loss: 0.1536 - val_loss: 0.0908\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.1001 - val_loss: 0.0502\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0580 - val_loss: 0.0253\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0442 - val_loss: 0.0308\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0448 - val_loss: 0.0256\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0407 - val_loss: 0.0243\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0401 - val_loss: 0.0243\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0391 - val_loss: 0.0246\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0382 - val_loss: 0.0245\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0374 - val_loss: 0.0247\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0365 - val_loss: 0.0248\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0359 - val_loss: 0.0251\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0355 - val_loss: 0.0252\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0348 - val_loss: 0.0254\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0254\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0256\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0257\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0257\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0262\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0258\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0257\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0256\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0255\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0254\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0255\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0332 - val_loss: 0.0253\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0251\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0251\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0248\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0246\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0327 - val_loss: 0.0246\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0327 - val_loss: 0.0250\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0242\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0245\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0325 - val_loss: 0.0246\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0237\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0319 - val_loss: 0.0235\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0316 - val_loss: 0.0233\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0230\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0230\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0226\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0225\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0311 - val_loss: 0.0223\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0317 - val_loss: 0.0226\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0304 - val_loss: 0.0222\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0303 - val_loss: 0.0219\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0296 - val_loss: 0.0217\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0295 - val_loss: 0.0214\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0298 - val_loss: 0.0211\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0294 - val_loss: 0.0211\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0287 - val_loss: 0.0206\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0281 - val_loss: 0.0201\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0276 - val_loss: 0.0197\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0272 - val_loss: 0.0192\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0270 - val_loss: 0.0186\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0278 - val_loss: 0.0184\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0272 - val_loss: 0.0177\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0252 - val_loss: 0.0172\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0266 - val_loss: 0.0169\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0244 - val_loss: 0.0163\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0239 - val_loss: 0.0162\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0239 - val_loss: 0.0149\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0220 - val_loss: 0.0150\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0208 - val_loss: 0.0131\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0198 - val_loss: 0.0144\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0200 - val_loss: 0.0127\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0226 - val_loss: 0.0134\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0133\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0168 - val_loss: 0.0108\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0103\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0096\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0092\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0103\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0083\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0084\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0076\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0094\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0075\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0075\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0069\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0069\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0074\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0073\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0064\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "evolution of the gridsearch: step  7\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 58s 249ms/step - loss: 0.1369 - val_loss: 0.0885\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1016 - val_loss: 0.0570\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0667 - val_loss: 0.0310\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0427 - val_loss: 0.0262\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0430 - val_loss: 0.0310\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0419 - val_loss: 0.0247\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0384 - val_loss: 0.0242\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0396 - val_loss: 0.0245\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0387 - val_loss: 0.0240\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0374 - val_loss: 0.0245\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0373 - val_loss: 0.0248\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0368 - val_loss: 0.0242\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0361 - val_loss: 0.0242\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0244\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0245\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0246\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0347 - val_loss: 0.0248\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0249\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0250\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0342 - val_loss: 0.0251\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0341 - val_loss: 0.0251\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0251\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0250\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0341 - val_loss: 0.0250\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0249\n",
      "evolution of the gridsearch: step  8\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 57s 248ms/step - loss: 0.1527 - val_loss: 0.0991\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1159 - val_loss: 0.0717\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0867 - val_loss: 0.0488\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0622 - val_loss: 0.0312\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0451 - val_loss: 0.0239\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0406 - val_loss: 0.0275\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0410 - val_loss: 0.0258\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0387 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0376 - val_loss: 0.0237\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0374 - val_loss: 0.0236\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0236\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0358 - val_loss: 0.0237\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0238\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0239\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0344 - val_loss: 0.0239\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0241\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0344 - val_loss: 0.0242\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0241\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.0336 - val_loss: 0.0242\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0240\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0239\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0239\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.0330 - val_loss: 0.0239\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.0329 - val_loss: 0.0238\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0326 - val_loss: 0.0237\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0325 - val_loss: 0.0237\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0323 - val_loss: 0.0235\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0322 - val_loss: 0.0234\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0232\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0231\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0229\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0316 - val_loss: 0.0227\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0314 - val_loss: 0.0226\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0310 - val_loss: 0.0224\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0308 - val_loss: 0.0222\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0307 - val_loss: 0.0221\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0304 - val_loss: 0.0218\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0306 - val_loss: 0.0218\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0297 - val_loss: 0.0215\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0298 - val_loss: 0.0215\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0293 - val_loss: 0.0209\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0286 - val_loss: 0.0207\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0287 - val_loss: 0.0202\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0281 - val_loss: 0.0199\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0277 - val_loss: 0.0196\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0273 - val_loss: 0.0192\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0266 - val_loss: 0.0189\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0262 - val_loss: 0.0183\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0253 - val_loss: 0.0178\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0247 - val_loss: 0.0173\n",
      "evolution of the gridsearch: step  9\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 58s 248ms/step - loss: 0.1386 - val_loss: 0.0930\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1080 - val_loss: 0.0680\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0792 - val_loss: 0.0428\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0510 - val_loss: 0.0253\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0400 - val_loss: 0.0316\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0423 - val_loss: 0.0264\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0376 - val_loss: 0.0247\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0377 - val_loss: 0.0250\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0378 - val_loss: 0.0248\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0368 - val_loss: 0.0249\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0252\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0361 - val_loss: 0.0250\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0251\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0355 - val_loss: 0.0252\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0253\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0350 - val_loss: 0.0255\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0350 - val_loss: 0.0257\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0259\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0350 - val_loss: 0.0260\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0259\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0347 - val_loss: 0.0259\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0258\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0344 - val_loss: 0.0257\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0257\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0347 - val_loss: 0.0260\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0342 - val_loss: 0.0255\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0255\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0342 - val_loss: 0.0256\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0342 - val_loss: 0.0253\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0341 - val_loss: 0.0252\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0252\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0252\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0337 - val_loss: 0.0253\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0252\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0337 - val_loss: 0.0253\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0250\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0250\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0251\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0248\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0248\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0247\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0246\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0246\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0245\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0244\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0244\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0243\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0241\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0325 - val_loss: 0.0241\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0325 - val_loss: 0.0239\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0239\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0238\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0237\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0236\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0320 - val_loss: 0.0236\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0320 - val_loss: 0.0234\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0233\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0232\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0230\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0313 - val_loss: 0.0230\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0227\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0312 - val_loss: 0.0227\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0319 - val_loss: 0.0225\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0307 - val_loss: 0.0224\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0310 - val_loss: 0.0224\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0310 - val_loss: 0.0224\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0307 - val_loss: 0.0220\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 2ms/step - loss: 0.0303 - val_loss: 0.0219\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0302 - val_loss: 0.0218\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0302 - val_loss: 0.0217\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0300 - val_loss: 0.0214\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0297 - val_loss: 0.0213\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0295 - val_loss: 0.0211\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0291 - val_loss: 0.0209\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0290 - val_loss: 0.0208\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0206\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0203\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0283 - val_loss: 0.0203\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0279 - val_loss: 0.0198\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0276 - val_loss: 0.0196\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0271 - val_loss: 0.0196\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0269 - val_loss: 0.0189\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0269 - val_loss: 0.0185\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0262 - val_loss: 0.0193\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0261 - val_loss: 0.0181\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0253 - val_loss: 0.0177\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0246 - val_loss: 0.0173\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0241 - val_loss: 0.0169\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0235 - val_loss: 0.0163\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0229 - val_loss: 0.0158\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0225 - val_loss: 0.0154\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0215 - val_loss: 0.0151\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0207 - val_loss: 0.0141\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0198 - val_loss: 0.0141\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0190 - val_loss: 0.0130\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0180 - val_loss: 0.0125\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0171 - val_loss: 0.0116\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0165 - val_loss: 0.0137\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0157 - val_loss: 0.0110\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0101\n",
      "evolution of the gridsearch: step  10\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 61s 265ms/step - loss: 0.1084 - val_loss: 0.0494\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0506 - val_loss: 0.0283\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0423 - val_loss: 0.0247\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0418 - val_loss: 0.0240\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0382 - val_loss: 0.0240\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0402 - val_loss: 0.0241\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0360 - val_loss: 0.0250\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0371 - val_loss: 0.0246\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0368 - val_loss: 0.0246\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0344 - val_loss: 0.0244\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0354 - val_loss: 0.0246\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0364 - val_loss: 0.0251\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0354 - val_loss: 0.0242\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0345 - val_loss: 0.0247\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0376 - val_loss: 0.0233\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0342 - val_loss: 0.0233\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0337 - val_loss: 0.0230\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0332 - val_loss: 0.0229\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0358 - val_loss: 0.0229\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0344 - val_loss: 0.0222\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0334 - val_loss: 0.0221\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0312 - val_loss: 0.0214\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0339 - val_loss: 0.0211\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0320 - val_loss: 0.0207\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0341 - val_loss: 0.0201\n",
      "evolution of the gridsearch: step  11\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 60s 260ms/step - loss: 0.0579 - val_loss: 0.0278\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0395 - val_loss: 0.0240\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0387 - val_loss: 0.0248\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0385 - val_loss: 0.0240\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0381 - val_loss: 0.0240\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0353 - val_loss: 0.0241\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0353 - val_loss: 0.0239\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0349 - val_loss: 0.0239\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0352 - val_loss: 0.0240\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0353 - val_loss: 0.0237\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0353 - val_loss: 0.0242\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0346 - val_loss: 0.0233\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0340 - val_loss: 0.0230\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0325 - val_loss: 0.0229\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0335 - val_loss: 0.0227\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0338 - val_loss: 0.0227\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0342 - val_loss: 0.0226\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0354 - val_loss: 0.0222\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0340 - val_loss: 0.0221\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0307 - val_loss: 0.0216\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0323 - val_loss: 0.0214\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0312 - val_loss: 0.0210\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0302 - val_loss: 0.0206\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0310 - val_loss: 0.0201\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0304 - val_loss: 0.0196\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0288 - val_loss: 0.0193\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0277 - val_loss: 0.0188\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0277 - val_loss: 0.0187\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0282 - val_loss: 0.0177\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0287 - val_loss: 0.0169\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0237 - val_loss: 0.0162\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0245 - val_loss: 0.0154\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0252 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0242 - val_loss: 0.0143\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0255 - val_loss: 0.0141\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0213 - val_loss: 0.0135\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0201 - val_loss: 0.0129\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0215 - val_loss: 0.0126\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0176 - val_loss: 0.0120\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0201 - val_loss: 0.0114\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0189 - val_loss: 0.0113\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0191 - val_loss: 0.0109\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0177 - val_loss: 0.0105\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0167 - val_loss: 0.0100\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0144 - val_loss: 0.0096\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0163 - val_loss: 0.0099\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0151 - val_loss: 0.0093\n",
      "evolution of the gridsearch: step  12\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 61s 264ms/step - loss: 0.0938 - val_loss: 0.0316\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0439 - val_loss: 0.0288\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0370 - val_loss: 0.0259\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0381 - val_loss: 0.0249\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0380 - val_loss: 0.0249\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0381 - val_loss: 0.0250\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0373 - val_loss: 0.0253\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0365 - val_loss: 0.0254\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0345 - val_loss: 0.0255\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0383 - val_loss: 0.0257\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0363 - val_loss: 0.0251\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0374 - val_loss: 0.0251\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0357 - val_loss: 0.0249\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0345 - val_loss: 0.0250\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0367 - val_loss: 0.0247\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0360 - val_loss: 0.0244\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0391 - val_loss: 0.0243\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0347 - val_loss: 0.0238\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0335 - val_loss: 0.0238\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0342 - val_loss: 0.0236\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0341 - val_loss: 0.0236\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0345 - val_loss: 0.0233\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0353 - val_loss: 0.0230\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0351 - val_loss: 0.0231\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0343 - val_loss: 0.0224\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0308 - val_loss: 0.0225\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0309 - val_loss: 0.0225\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0311 - val_loss: 0.0220\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0315 - val_loss: 0.0216\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0313 - val_loss: 0.0213\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0327 - val_loss: 0.0210\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0304 - val_loss: 0.0206\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0300 - val_loss: 0.0204\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0288 - val_loss: 0.0199\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0312 - val_loss: 0.0195\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0286 - val_loss: 0.0192\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0286 - val_loss: 0.0188\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0260 - val_loss: 0.0181\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0256 - val_loss: 0.0174\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0248 - val_loss: 0.0167\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0242 - val_loss: 0.0160\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0249 - val_loss: 0.0151\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0235 - val_loss: 0.0144\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0224 - val_loss: 0.0139\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0200 - val_loss: 0.0132\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0190 - val_loss: 0.0128\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0200 - val_loss: 0.0123\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0205 - val_loss: 0.0117\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0191 - val_loss: 0.0116\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0162 - val_loss: 0.0111\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0177 - val_loss: 0.0109\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0176 - val_loss: 0.0106\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0159 - val_loss: 0.0102\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0187 - val_loss: 0.0100\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0164 - val_loss: 0.0104\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0154 - val_loss: 0.0094\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0144 - val_loss: 0.0100\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0145 - val_loss: 0.0093\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0155 - val_loss: 0.0092\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0140 - val_loss: 0.0092\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0144 - val_loss: 0.0089\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0089\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0150 - val_loss: 0.0088\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0091\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0137 - val_loss: 0.0089\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0150 - val_loss: 0.0084\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0149 - val_loss: 0.0090\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0157 - val_loss: 0.0087\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0144 - val_loss: 0.0090\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0143 - val_loss: 0.0084\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0081\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0137 - val_loss: 0.0084\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0130 - val_loss: 0.0081\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0154 - val_loss: 0.0079\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0135 - val_loss: 0.0088\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0134 - val_loss: 0.0079\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0134 - val_loss: 0.0081\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0131 - val_loss: 0.0081\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0120 - val_loss: 0.0077\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0129 - val_loss: 0.0081\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0077\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0077\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0130 - val_loss: 0.0077\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0130 - val_loss: 0.0078\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0136 - val_loss: 0.0075\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0133 - val_loss: 0.0086\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0144 - val_loss: 0.0077\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0076\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0132 - val_loss: 0.0076\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0133 - val_loss: 0.0073\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0129 - val_loss: 0.0071\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0128 - val_loss: 0.0072\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0134 - val_loss: 0.0071\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0128 - val_loss: 0.0079\n",
      "evolution of the gridsearch: step  13\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 58s 249ms/step - loss: 0.1281 - val_loss: 0.0633\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0694 - val_loss: 0.0268\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0440 - val_loss: 0.0270\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0447 - val_loss: 0.0248\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0390 - val_loss: 0.0235\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0406 - val_loss: 0.0238\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0365 - val_loss: 0.0234\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0387 - val_loss: 0.0234\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0235\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0236\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0386 - val_loss: 0.0239\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0358 - val_loss: 0.0243\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0239\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0374 - val_loss: 0.0241\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0240\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0241\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0356 - val_loss: 0.0236\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0239\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0350 - val_loss: 0.0234\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0359 - val_loss: 0.0235\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0235\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0237\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0356 - val_loss: 0.0235\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0231\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0322 - val_loss: 0.0229\n",
      "evolution of the gridsearch: step  14\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 59s 253ms/step - loss: 0.1098 - val_loss: 0.0540\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0571 - val_loss: 0.0250\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0407 - val_loss: 0.0275\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0444 - val_loss: 0.0248\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0418 - val_loss: 0.0256\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0403 - val_loss: 0.0246\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0392 - val_loss: 0.0247\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0372 - val_loss: 0.0248\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0357 - val_loss: 0.0248\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0383 - val_loss: 0.0247\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0381 - val_loss: 0.0252\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0364 - val_loss: 0.0248\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0382 - val_loss: 0.0248\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0362 - val_loss: 0.0258\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0355 - val_loss: 0.0248\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0374 - val_loss: 0.0248\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0359 - val_loss: 0.0252\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0369 - val_loss: 0.0247\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0355 - val_loss: 0.0243\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0243\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0256\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0328 - val_loss: 0.0241\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0366 - val_loss: 0.0240\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0309 - val_loss: 0.0239\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0348 - val_loss: 0.0240\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0238\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0365 - val_loss: 0.0237\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0235\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0234\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0355 - val_loss: 0.0235\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0230\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0231\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0226\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0311 - val_loss: 0.0224\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0223\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0224\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0314 - val_loss: 0.0222\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0219\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0223\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0213\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0323 - val_loss: 0.0214\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0314 - val_loss: 0.0210\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0335 - val_loss: 0.0209\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0318 - val_loss: 0.0207\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0299 - val_loss: 0.0208\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0320 - val_loss: 0.0206\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0298 - val_loss: 0.0201\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0291 - val_loss: 0.0198\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0297 - val_loss: 0.0195\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0311 - val_loss: 0.0197\n",
      "evolution of the gridsearch: step  15\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 61s 263ms/step - loss: 0.1326 - val_loss: 0.0802\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0848 - val_loss: 0.0407\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0405 - val_loss: 0.0283\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0401 - val_loss: 0.0247\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0393 - val_loss: 0.0254\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0409 - val_loss: 0.0248\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0380 - val_loss: 0.0247\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0365 - val_loss: 0.0248\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0353 - val_loss: 0.0249\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0360 - val_loss: 0.0251\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0363 - val_loss: 0.0253\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0379 - val_loss: 0.0250\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0388 - val_loss: 0.0261\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0364 - val_loss: 0.0252\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0250\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0371 - val_loss: 0.0251\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0250\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0248\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0246\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0248\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0250\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0357 - val_loss: 0.0255\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0360 - val_loss: 0.0244\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0371 - val_loss: 0.0244\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0245\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0243\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0240\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0326 - val_loss: 0.0241\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0240\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0246\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0343 - val_loss: 0.0238\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0236\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0237\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0232\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0235\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0230\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0348 - val_loss: 0.0226\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0319 - val_loss: 0.0225\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0226\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0227\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0358 - val_loss: 0.0221\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0350 - val_loss: 0.0220\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0314 - val_loss: 0.0223\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0301 - val_loss: 0.0215\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0319 - val_loss: 0.0214\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0217\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0296 - val_loss: 0.0209\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0307 - val_loss: 0.0210\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0212\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0302 - val_loss: 0.0201\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0299 - val_loss: 0.0198\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0277 - val_loss: 0.0194\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0305 - val_loss: 0.0193\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0261 - val_loss: 0.0190\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0272 - val_loss: 0.0186\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0287 - val_loss: 0.0178\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0248 - val_loss: 0.0180\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0169\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0248 - val_loss: 0.0164\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0248 - val_loss: 0.0160\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0276 - val_loss: 0.0157\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0252 - val_loss: 0.0155\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0246 - val_loss: 0.0151\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0255 - val_loss: 0.0156\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0226 - val_loss: 0.0142\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0235 - val_loss: 0.0144\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0216 - val_loss: 0.0135\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0218 - val_loss: 0.0136\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0197 - val_loss: 0.0130\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0211 - val_loss: 0.0126\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0129\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0122\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0221 - val_loss: 0.0119\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0122\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0196 - val_loss: 0.0113\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0114\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0110\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0104\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0110\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0183 - val_loss: 0.0105\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0103\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0105\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.0100\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0106\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0175 - val_loss: 0.0109\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0100\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0171 - val_loss: 0.0098\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0163 - val_loss: 0.0105\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0163 - val_loss: 0.0094\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0094\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0094\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0093\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0152 - val_loss: 0.0090\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0089\n",
      "evolution of the gridsearch: step  16\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 62s 266ms/step - loss: 0.1289 - val_loss: 0.0844\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0914 - val_loss: 0.0549\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0621 - val_loss: 0.0312\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0450 - val_loss: 0.0264\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0459 - val_loss: 0.0297\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0429 - val_loss: 0.0255\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0414 - val_loss: 0.0256\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0417 - val_loss: 0.0259\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0391 - val_loss: 0.0253\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0392 - val_loss: 0.0256\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0395 - val_loss: 0.0256\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0389 - val_loss: 0.0255\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0401 - val_loss: 0.0259\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0364 - val_loss: 0.0258\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0257\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0368 - val_loss: 0.0258\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0385 - val_loss: 0.0263\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0355 - val_loss: 0.0262\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0375 - val_loss: 0.0260\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0260\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0371 - val_loss: 0.0260\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0258\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0258\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0361 - val_loss: 0.0258\n",
      "evolution of the gridsearch: step  17\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 62s 267ms/step - loss: 0.0922 - val_loss: 0.0508\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0558 - val_loss: 0.0265\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0387 - val_loss: 0.0276\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0418 - val_loss: 0.0265\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0392 - val_loss: 0.0242\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0363 - val_loss: 0.0252\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0374 - val_loss: 0.0246\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0395 - val_loss: 0.0244\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0372 - val_loss: 0.0247\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0245\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0371 - val_loss: 0.0248\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0337 - val_loss: 0.0247\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0362 - val_loss: 0.0246\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0246\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0246\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0247\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0362 - val_loss: 0.0246\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0351 - val_loss: 0.0245\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0246\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0373 - val_loss: 0.0245\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0341 - val_loss: 0.0246\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0247\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0326 - val_loss: 0.0243\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0367 - val_loss: 0.0243\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0355 - val_loss: 0.0243\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0355 - val_loss: 0.0240\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0239\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0331 - val_loss: 0.0239\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0238\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0236\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0315 - val_loss: 0.0234\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0350 - val_loss: 0.0234\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0331 - val_loss: 0.0230\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0230\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0325 - val_loss: 0.0230\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0227\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0226\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0319 - val_loss: 0.0225\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0223\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0315 - val_loss: 0.0222\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0308 - val_loss: 0.0222\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0219\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0310 - val_loss: 0.0217\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0313 - val_loss: 0.0217\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0217\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0291 - val_loss: 0.0212\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0209\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0303 - val_loss: 0.0207\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0302 - val_loss: 0.0204\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0201\n",
      "evolution of the gridsearch: step  18\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 61s 264ms/step - loss: 0.1277 - val_loss: 0.0805\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0901 - val_loss: 0.0478\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0564 - val_loss: 0.0258\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0414 - val_loss: 0.0293\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0456 - val_loss: 0.0271\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0410 - val_loss: 0.0243\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0380 - val_loss: 0.0248\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0420 - val_loss: 0.0246\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0396 - val_loss: 0.0244\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0246\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0375 - val_loss: 0.0246\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0376 - val_loss: 0.0248\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0373 - val_loss: 0.0249\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0367 - val_loss: 0.0250\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0380 - val_loss: 0.0252\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0351 - val_loss: 0.0255\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0252\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0364 - val_loss: 0.0253\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0371 - val_loss: 0.0254\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0368 - val_loss: 0.0255\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0371 - val_loss: 0.0255\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0362 - val_loss: 0.0255\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0265\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0258\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0361 - val_loss: 0.0250\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0387 - val_loss: 0.0248\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0361 - val_loss: 0.0257\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0246\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0342 - val_loss: 0.0245\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0356 - val_loss: 0.0247\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0368 - val_loss: 0.0253\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0244\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0245\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0243\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0250\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0244\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0240\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0240\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0240\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0348 - val_loss: 0.0242\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0240\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0336 - val_loss: 0.0237\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0337 - val_loss: 0.0235\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0238\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0344 - val_loss: 0.0236\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0235\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0312 - val_loss: 0.0234\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0232\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0231\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0228\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0325 - val_loss: 0.0228\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0320 - val_loss: 0.0224\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0223\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0226\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0326 - val_loss: 0.0219\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0303 - val_loss: 0.0216\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0305 - val_loss: 0.0217\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0212\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0300 - val_loss: 0.0210\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0296 - val_loss: 0.0207\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0205\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0201\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0287 - val_loss: 0.0198\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0273 - val_loss: 0.0196\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0272 - val_loss: 0.0193\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0274 - val_loss: 0.0192\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0264 - val_loss: 0.0191\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0250 - val_loss: 0.0188\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0270 - val_loss: 0.0181\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0281 - val_loss: 0.0185\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0250 - val_loss: 0.0182\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0240 - val_loss: 0.0177\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0260 - val_loss: 0.0176\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0240 - val_loss: 0.0174\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0239 - val_loss: 0.0168\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0211 - val_loss: 0.0168\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0232 - val_loss: 0.0164\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0221 - val_loss: 0.0165\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0212 - val_loss: 0.0164\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0222 - val_loss: 0.0166\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0207 - val_loss: 0.0165\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0212 - val_loss: 0.0162\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0214 - val_loss: 0.0162\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0181 - val_loss: 0.0159\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0206 - val_loss: 0.0151\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0203 - val_loss: 0.0155\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0209 - val_loss: 0.0153\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0205 - val_loss: 0.0154\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0169 - val_loss: 0.0146\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0165 - val_loss: 0.0143\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0180 - val_loss: 0.0140\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0188 - val_loss: 0.0138\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0139\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0192 - val_loss: 0.0140\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0186 - val_loss: 0.0137\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0170 - val_loss: 0.0140\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.0144\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0176 - val_loss: 0.0138\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0132\n",
      "evolution of the gridsearch: step  19\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 63s 273ms/step - loss: 0.1277 - val_loss: 0.0562\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0630 - val_loss: 0.0271\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0439 - val_loss: 0.0256\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0440 - val_loss: 0.0254\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0457 - val_loss: 0.0255\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0401 - val_loss: 0.0262\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0386 - val_loss: 0.0257\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0399 - val_loss: 0.0273\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0404 - val_loss: 0.0257\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0404 - val_loss: 0.0260\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0397 - val_loss: 0.0263\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0409 - val_loss: 0.0255\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0387 - val_loss: 0.0257\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0370 - val_loss: 0.0255\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0338 - val_loss: 0.0247\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0365 - val_loss: 0.0245\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0357 - val_loss: 0.0247\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0348 - val_loss: 0.0239\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0372 - val_loss: 0.0239\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0365 - val_loss: 0.0241\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0372 - val_loss: 0.0230\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0335 - val_loss: 0.0228\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0354 - val_loss: 0.0221\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0334 - val_loss: 0.0220\n",
      "evolution of the gridsearch: step  20\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 66s 283ms/step - loss: 0.1082 - val_loss: 0.0480\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0514 - val_loss: 0.0263\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0461 - val_loss: 0.0242\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0409 - val_loss: 0.0242\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0425 - val_loss: 0.0241\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0406 - val_loss: 0.0246\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0402 - val_loss: 0.0243\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0391 - val_loss: 0.0244\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0398 - val_loss: 0.0248\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0347 - val_loss: 0.0245\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0395 - val_loss: 0.0263\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0377 - val_loss: 0.0241\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0351 - val_loss: 0.0245\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0361 - val_loss: 0.0237\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0346 - val_loss: 0.0234\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0381 - val_loss: 0.0236\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0370 - val_loss: 0.0230\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0350 - val_loss: 0.0227\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0374 - val_loss: 0.0224\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0362 - val_loss: 0.0220\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0369 - val_loss: 0.0223\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0365 - val_loss: 0.0218\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0369 - val_loss: 0.0214\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0363 - val_loss: 0.0216\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0321 - val_loss: 0.0208\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0341 - val_loss: 0.0207\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0317 - val_loss: 0.0199\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0293 - val_loss: 0.0194\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0291 - val_loss: 0.0190\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0323 - val_loss: 0.0188\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0319 - val_loss: 0.0184\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0303 - val_loss: 0.0191\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0306 - val_loss: 0.0175\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0286 - val_loss: 0.0182\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0299 - val_loss: 0.0166\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0267 - val_loss: 0.0165\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0271 - val_loss: 0.0157\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0243 - val_loss: 0.0155\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0215 - val_loss: 0.0148\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0260 - val_loss: 0.0160\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0246 - val_loss: 0.0139\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0240 - val_loss: 0.0138\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0236 - val_loss: 0.0133\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0233 - val_loss: 0.0132\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0267 - val_loss: 0.0143\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0236 - val_loss: 0.0129\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0225 - val_loss: 0.0120\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0220 - val_loss: 0.0117\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0192 - val_loss: 0.0110\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0202 - val_loss: 0.0119\n",
      "evolution of the gridsearch: step  21\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 69s 296ms/step - loss: 0.1061 - val_loss: 0.0472\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0514 - val_loss: 0.0249\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0463 - val_loss: 0.0246\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0422 - val_loss: 0.0261\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0444 - val_loss: 0.0249\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0420 - val_loss: 0.0255\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0421 - val_loss: 0.0247\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0380 - val_loss: 0.0246\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0383 - val_loss: 0.0243\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0397 - val_loss: 0.0247\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0347 - val_loss: 0.0240\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0403 - val_loss: 0.0240\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0353 - val_loss: 0.0239\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0386 - val_loss: 0.0245\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0385 - val_loss: 0.0243\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0337 - val_loss: 0.0231\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0385 - val_loss: 0.0239\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0370 - val_loss: 0.0227\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0368 - val_loss: 0.0233\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0364 - val_loss: 0.0225\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0368 - val_loss: 0.0224\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0334 - val_loss: 0.0223\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0346 - val_loss: 0.0221\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0334 - val_loss: 0.0219\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0335 - val_loss: 0.0217\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0349 - val_loss: 0.0215\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0294 - val_loss: 0.0208\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0322 - val_loss: 0.0207\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0327 - val_loss: 0.0210\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0331 - val_loss: 0.0198\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0306 - val_loss: 0.0199\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0330 - val_loss: 0.0195\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0305 - val_loss: 0.0194\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0265 - val_loss: 0.0180\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0251 - val_loss: 0.0178\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0286 - val_loss: 0.0187\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0272 - val_loss: 0.0176\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0263 - val_loss: 0.0168\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0235 - val_loss: 0.0164\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0276 - val_loss: 0.0167\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0238 - val_loss: 0.0162\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0233 - val_loss: 0.0165\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0243 - val_loss: 0.0153\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0241 - val_loss: 0.0156\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0246 - val_loss: 0.0148\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0236 - val_loss: 0.0149\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0223 - val_loss: 0.0140\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0229 - val_loss: 0.0142\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0221 - val_loss: 0.0133\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0187 - val_loss: 0.0135\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0186 - val_loss: 0.0129\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0211 - val_loss: 0.0128\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0206 - val_loss: 0.0122\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0212 - val_loss: 0.0124\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0195 - val_loss: 0.0126\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0197 - val_loss: 0.0130\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0192 - val_loss: 0.0116\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0185 - val_loss: 0.0118\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0194 - val_loss: 0.0124\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0215 - val_loss: 0.0116\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0191 - val_loss: 0.0114\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0180 - val_loss: 0.0113\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0177 - val_loss: 0.0107\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0189 - val_loss: 0.0110\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0184 - val_loss: 0.0103\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0102\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0197 - val_loss: 0.0104\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0190 - val_loss: 0.0099\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0178 - val_loss: 0.0105\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0163 - val_loss: 0.0098\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0187 - val_loss: 0.0103\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0179 - val_loss: 0.0099\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0192 - val_loss: 0.0110\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0191 - val_loss: 0.0101\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0190 - val_loss: 0.0108\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0144 - val_loss: 0.0097\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0175 - val_loss: 0.0095\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0151 - val_loss: 0.0096\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0162 - val_loss: 0.0092\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0106\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0162 - val_loss: 0.0101\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0094\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0153 - val_loss: 0.0093\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0154 - val_loss: 0.0097\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0160 - val_loss: 0.0091\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0183 - val_loss: 0.0096\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0155 - val_loss: 0.0091\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0177 - val_loss: 0.0098\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0154 - val_loss: 0.0095\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0150 - val_loss: 0.0090\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0162 - val_loss: 0.0089\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0145 - val_loss: 0.0086\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0146 - val_loss: 0.0088\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0145 - val_loss: 0.0086\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0155 - val_loss: 0.0101\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0141 - val_loss: 0.0086\n",
      "evolution of the gridsearch: step  22\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 67s 287ms/step - loss: 0.1403 - val_loss: 0.0794\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0881 - val_loss: 0.0385\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0260\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0263\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0447 - val_loss: 0.0257\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0424 - val_loss: 0.0259\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0416 - val_loss: 0.0253\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0388 - val_loss: 0.0254\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0428 - val_loss: 0.0255\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0388 - val_loss: 0.0260\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0398 - val_loss: 0.0258\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0370 - val_loss: 0.0261\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0401 - val_loss: 0.0259\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0355 - val_loss: 0.0259\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0381 - val_loss: 0.0262\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0408 - val_loss: 0.0256\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0395 - val_loss: 0.0254\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0253\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0385 - val_loss: 0.0254\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0353 - val_loss: 0.0253\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0388 - val_loss: 0.0251\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0381 - val_loss: 0.0265\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0400 - val_loss: 0.0255\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0389 - val_loss: 0.0249\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0381 - val_loss: 0.0255\n",
      "evolution of the gridsearch: step  23\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 65s 281ms/step - loss: 0.1304 - val_loss: 0.0714\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0810 - val_loss: 0.0370\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0464 - val_loss: 0.0238\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0486 - val_loss: 0.0265\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0438 - val_loss: 0.0236\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0389 - val_loss: 0.0241\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0387 - val_loss: 0.0237\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0236\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0418 - val_loss: 0.0236\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0382 - val_loss: 0.0241\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0385 - val_loss: 0.0237\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0393 - val_loss: 0.0237\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0358 - val_loss: 0.0238\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0392 - val_loss: 0.0248\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0392 - val_loss: 0.0251\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0367 - val_loss: 0.0241\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0379 - val_loss: 0.0239\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0244\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0238\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0372 - val_loss: 0.0241\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0386 - val_loss: 0.0247\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0400 - val_loss: 0.0242\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0364 - val_loss: 0.0234\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0397 - val_loss: 0.0235\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0365 - val_loss: 0.0239\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0231\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0232\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0359 - val_loss: 0.0240\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0348 - val_loss: 0.0229\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0348 - val_loss: 0.0229\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0359 - val_loss: 0.0228\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0368 - val_loss: 0.0235\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0357 - val_loss: 0.0230\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0370 - val_loss: 0.0224\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0348 - val_loss: 0.0226\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0225\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0221\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0222\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0352 - val_loss: 0.0222\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0325 - val_loss: 0.0220\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0322 - val_loss: 0.0216\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0215\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0322 - val_loss: 0.0214\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0356 - val_loss: 0.0211\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0367 - val_loss: 0.0217\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0208\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0208\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0208\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0316 - val_loss: 0.0204\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0285 - val_loss: 0.0201\n",
      "evolution of the gridsearch: step  24\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 67s 287ms/step - loss: 0.1236 - val_loss: 0.0753\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0811 - val_loss: 0.0376\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0492 - val_loss: 0.0260\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0454 - val_loss: 0.0270\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0432 - val_loss: 0.0252\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0420 - val_loss: 0.0259\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0428 - val_loss: 0.0258\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0406 - val_loss: 0.0253\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0408 - val_loss: 0.0256\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0402 - val_loss: 0.0259\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0388 - val_loss: 0.0257\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0382 - val_loss: 0.0261\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0410 - val_loss: 0.0259\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0389 - val_loss: 0.0258\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0394 - val_loss: 0.0258\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0403 - val_loss: 0.0264\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0369 - val_loss: 0.0262\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0350 - val_loss: 0.0259\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0261\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0380 - val_loss: 0.0258\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0395 - val_loss: 0.0260\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0355 - val_loss: 0.0261\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0259\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0380 - val_loss: 0.0261\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0378 - val_loss: 0.0256\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0368 - val_loss: 0.0255\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0386 - val_loss: 0.0255\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0256\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0362 - val_loss: 0.0254\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0387 - val_loss: 0.0251\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0379 - val_loss: 0.0250\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0372 - val_loss: 0.0254\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0367 - val_loss: 0.0250\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0258\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0246\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0247\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0343 - val_loss: 0.0251\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0371 - val_loss: 0.0247\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0247\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0246\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0353 - val_loss: 0.0247\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0254\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0245\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0351 - val_loss: 0.0244\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0326 - val_loss: 0.0243\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0241\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0344 - val_loss: 0.0245\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0343 - val_loss: 0.0240\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0238\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0238\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0239\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0247\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0376 - val_loss: 0.0235\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0236\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0237\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0326 - val_loss: 0.0237\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0236\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0234\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0231\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0300 - val_loss: 0.0228\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0226\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0224\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0224\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0222\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0326 - val_loss: 0.0223\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0332 - val_loss: 0.0216\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0317 - val_loss: 0.0214\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0325 - val_loss: 0.0217\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0217\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0212\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0292 - val_loss: 0.0207\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0305 - val_loss: 0.0205\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0296 - val_loss: 0.0203\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0291 - val_loss: 0.0200\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0305 - val_loss: 0.0195\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0290 - val_loss: 0.0192\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0269 - val_loss: 0.0192\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0271 - val_loss: 0.0186\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0279 - val_loss: 0.0186\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0289 - val_loss: 0.0183\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0294 - val_loss: 0.0184\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0287 - val_loss: 0.0174\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0258 - val_loss: 0.0172\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0264 - val_loss: 0.0172\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0288 - val_loss: 0.0169\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0260 - val_loss: 0.0169\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0252 - val_loss: 0.0165\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0250 - val_loss: 0.0165\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0243 - val_loss: 0.0167\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0239 - val_loss: 0.0164\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0245 - val_loss: 0.0171\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0241 - val_loss: 0.0160\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0247 - val_loss: 0.0157\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0238 - val_loss: 0.0157\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0227 - val_loss: 0.0158\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0220 - val_loss: 0.0152\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0232 - val_loss: 0.0161\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0231 - val_loss: 0.0150\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0219 - val_loss: 0.0149\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0243 - val_loss: 0.0152\n",
      "evolution of the gridsearch: step  25\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 65s 282ms/step - loss: 0.1449 - val_loss: 0.0959\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1116 - val_loss: 0.0652\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0760 - val_loss: 0.0359\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0490 - val_loss: 0.0255\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0484 - val_loss: 0.0286\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0479 - val_loss: 0.0247\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0440 - val_loss: 0.0251\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0431 - val_loss: 0.0249\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0399 - val_loss: 0.0246\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0412 - val_loss: 0.0248\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0409 - val_loss: 0.0247\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0395 - val_loss: 0.0249\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0375 - val_loss: 0.0250\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0379 - val_loss: 0.0250\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0426 - val_loss: 0.0253\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0398 - val_loss: 0.0255\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0376 - val_loss: 0.0253\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0389 - val_loss: 0.0255\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0394 - val_loss: 0.0259\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0384 - val_loss: 0.0267\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0257\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0255\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0376 - val_loss: 0.0257\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0390 - val_loss: 0.0265\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0390 - val_loss: 0.0261\n",
      "evolution of the gridsearch: step  26\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 67s 289ms/step - loss: 0.1486 - val_loss: 0.0943\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1099 - val_loss: 0.0649\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0801 - val_loss: 0.0404\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0560 - val_loss: 0.0249\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0440 - val_loss: 0.0257\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0475 - val_loss: 0.0253\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0444 - val_loss: 0.0233\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0418 - val_loss: 0.0238\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0363 - val_loss: 0.0237\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0417 - val_loss: 0.0233\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0373 - val_loss: 0.0233\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0378 - val_loss: 0.0234\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0400 - val_loss: 0.0234\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0370 - val_loss: 0.0235\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0378 - val_loss: 0.0236\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0363 - val_loss: 0.0241\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0381 - val_loss: 0.0244\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0239\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0369 - val_loss: 0.0236\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0359 - val_loss: 0.0237\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0358 - val_loss: 0.0239\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0390 - val_loss: 0.0237\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0371 - val_loss: 0.0237\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0374 - val_loss: 0.0240\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0369 - val_loss: 0.0238\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0323 - val_loss: 0.0235\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0234\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0231\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0232\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0231\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0372 - val_loss: 0.0232\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0350 - val_loss: 0.0230\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0230\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0351 - val_loss: 0.0230\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0336 - val_loss: 0.0227\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0359 - val_loss: 0.0229\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0226\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0342 - val_loss: 0.0229\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0224\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0221\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0221\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0224\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0355 - val_loss: 0.0220\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0307 - val_loss: 0.0218\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0216\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0218\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0319 - val_loss: 0.0227\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0331 - val_loss: 0.0218\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0212\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0210\n",
      "evolution of the gridsearch: step  27\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 71s 304ms/step - loss: 0.1358 - val_loss: 0.0901\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.1067 - val_loss: 0.0649\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0828 - val_loss: 0.0414\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0576 - val_loss: 0.0255\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0485 - val_loss: 0.0259\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0496 - val_loss: 0.0252\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0436 - val_loss: 0.0238\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0466 - val_loss: 0.0246\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0412 - val_loss: 0.0248\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0444 - val_loss: 0.0238\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0414 - val_loss: 0.0238\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0439 - val_loss: 0.0238\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0412 - val_loss: 0.0240\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0413 - val_loss: 0.0244\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0414 - val_loss: 0.0245\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0418 - val_loss: 0.0247\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0398 - val_loss: 0.0246\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0416 - val_loss: 0.0245\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0389 - val_loss: 0.0244\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0362 - val_loss: 0.0245\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0367 - val_loss: 0.0248\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0383 - val_loss: 0.0248\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0354 - val_loss: 0.0245\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0251\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0406 - val_loss: 0.0255\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0392 - val_loss: 0.0252\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0362 - val_loss: 0.0246\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0371 - val_loss: 0.0243\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0358 - val_loss: 0.0242\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0354 - val_loss: 0.0247\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0374 - val_loss: 0.0246\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0375 - val_loss: 0.0244\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0394 - val_loss: 0.0240\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0242\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0368 - val_loss: 0.0238\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0380 - val_loss: 0.0238\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0341 - val_loss: 0.0241\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0370 - val_loss: 0.0237\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0238\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0365 - val_loss: 0.0240\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0232\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0369 - val_loss: 0.0232\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0351 - val_loss: 0.0236\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0233\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0354 - val_loss: 0.0227\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0229\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0369 - val_loss: 0.0222\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0363 - val_loss: 0.0223\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0349 - val_loss: 0.0220\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0221\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0347 - val_loss: 0.0217\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0216\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0221\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0361 - val_loss: 0.0217\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0216\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0216\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0213\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0337 - val_loss: 0.0215\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0217\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0323 - val_loss: 0.0212\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0315 - val_loss: 0.0206\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0206\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0312 - val_loss: 0.0202\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0204\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0201\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0347 - val_loss: 0.0201\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0198\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0299 - val_loss: 0.0197\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0200\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0300 - val_loss: 0.0195\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0295 - val_loss: 0.0190\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0303 - val_loss: 0.0189\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0311 - val_loss: 0.0188\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0274 - val_loss: 0.0187\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0316 - val_loss: 0.0186\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0267 - val_loss: 0.0183\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0181\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0297 - val_loss: 0.0180\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0316 - val_loss: 0.0178\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0267 - val_loss: 0.0173\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0277 - val_loss: 0.0171\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0171\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0263 - val_loss: 0.0168\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0290 - val_loss: 0.0161\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0271 - val_loss: 0.0158\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0287 - val_loss: 0.0157\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0260 - val_loss: 0.0154\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0251 - val_loss: 0.0151\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0262 - val_loss: 0.0148\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0227 - val_loss: 0.0144\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0229 - val_loss: 0.0139\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0239 - val_loss: 0.0135\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0233 - val_loss: 0.0133\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0251 - val_loss: 0.0135\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0230 - val_loss: 0.0131\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0229 - val_loss: 0.0125\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0209 - val_loss: 0.0124\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0236 - val_loss: 0.0124\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0208 - val_loss: 0.0140\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0210 - val_loss: 0.0125\n",
      "evolution of the gridsearch: step  28\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 71s 307ms/step - loss: 0.0615 - val_loss: 0.0256\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0353 - val_loss: 0.0246\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0349 - val_loss: 0.0242\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0339 - val_loss: 0.0242\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0334 - val_loss: 0.0242\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0333 - val_loss: 0.0276\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0344 - val_loss: 0.0227\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0313 - val_loss: 0.0218\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0308 - val_loss: 0.0215\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0294 - val_loss: 0.0201\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0278 - val_loss: 0.0190\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0286 - val_loss: 0.0221\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0261 - val_loss: 0.0170\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0223 - val_loss: 0.0157\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0219 - val_loss: 0.0162\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0195 - val_loss: 0.0142\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0186 - val_loss: 0.0134\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0169 - val_loss: 0.0129\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0143 - val_loss: 0.0111\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0136 - val_loss: 0.0094\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0092\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0088\n",
      "evolution of the gridsearch: step  29\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 70s 301ms/step - loss: 0.0775 - val_loss: 0.0375\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0395 - val_loss: 0.0250\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0348 - val_loss: 0.0239\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0339 - val_loss: 0.0232\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0330 - val_loss: 0.0230\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0329 - val_loss: 0.0242\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0326 - val_loss: 0.0235\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0335 - val_loss: 0.0221\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0308 - val_loss: 0.0217\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0306 - val_loss: 0.0216\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0307 - val_loss: 0.0216\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0301 - val_loss: 0.0201\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0266 - val_loss: 0.0192\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0264 - val_loss: 0.0169\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0235 - val_loss: 0.0153\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0217 - val_loss: 0.0146\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0187 - val_loss: 0.0130\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0173 - val_loss: 0.0121\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0154 - val_loss: 0.0115\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0149 - val_loss: 0.0158\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0186 - val_loss: 0.0099\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0136 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0084\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0076\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0091 - val_loss: 0.0066\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0079 - val_loss: 0.0068\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0067 - val_loss: 0.0074\n",
      "evolution of the gridsearch: step  30\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 69s 297ms/step - loss: 0.0818 - val_loss: 0.0313\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0356 - val_loss: 0.0249\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0349 - val_loss: 0.0240\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0346 - val_loss: 0.0244\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0333 - val_loss: 0.0238\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0333 - val_loss: 0.0247\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0326 - val_loss: 0.0235\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0327 - val_loss: 0.0229\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0316 - val_loss: 0.0227\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0337 - val_loss: 0.0247\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0319 - val_loss: 0.0208\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0297 - val_loss: 0.0195\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0282 - val_loss: 0.0190\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0269 - val_loss: 0.0172\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0243 - val_loss: 0.0174\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0233 - val_loss: 0.0146\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0202 - val_loss: 0.0133\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0182 - val_loss: 0.0128\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0167 - val_loss: 0.0119\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0160 - val_loss: 0.0104\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0096\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0128 - val_loss: 0.0091\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0082\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0084\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0102 - val_loss: 0.0073\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0100 - val_loss: 0.0072\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0071 - val_loss: 0.0094\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 2s 6ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0078\n",
      "evolution of the gridsearch: step  31\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 68s 293ms/step - loss: 0.1180 - val_loss: 0.0495\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0468 - val_loss: 0.0341\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0251\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0383 - val_loss: 0.0242\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0352 - val_loss: 0.0247\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0232\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0231\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0231\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0233\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0332 - val_loss: 0.0232\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0326 - val_loss: 0.0232\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0323 - val_loss: 0.0231\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0321 - val_loss: 0.0231\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0320 - val_loss: 0.0227\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0320 - val_loss: 0.0226\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0221\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0218\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0307 - val_loss: 0.0220\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0212\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0297 - val_loss: 0.0209\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0294 - val_loss: 0.0204\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0298 - val_loss: 0.0201\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0282 - val_loss: 0.0194\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0276 - val_loss: 0.0188\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0270 - val_loss: 0.0182\n",
      "evolution of the gridsearch: step  32\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 71s 306ms/step - loss: 0.0888 - val_loss: 0.0249\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0396 - val_loss: 0.0244\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0371 - val_loss: 0.0268\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0244\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0238\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0335 - val_loss: 0.0237\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0332 - val_loss: 0.0237\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0328 - val_loss: 0.0237\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0326 - val_loss: 0.0234\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0320 - val_loss: 0.0231\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0318 - val_loss: 0.0228\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0224\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0310 - val_loss: 0.0223\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0309 - val_loss: 0.0216\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0299 - val_loss: 0.0211\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0296 - val_loss: 0.0204\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0285 - val_loss: 0.0200\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0283 - val_loss: 0.0192\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0268 - val_loss: 0.0181\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0256 - val_loss: 0.0170\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0243 - val_loss: 0.0161\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0233 - val_loss: 0.0152\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0212 - val_loss: 0.0152\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0206 - val_loss: 0.0140\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0131\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0147\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0123\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0163 - val_loss: 0.0117\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0152 - val_loss: 0.0109\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0148 - val_loss: 0.0115\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0112\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0089\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0077\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0075\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0075\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0074\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "evolution of the gridsearch: step  33\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 73s 314ms/step - loss: 0.0959 - val_loss: 0.0269\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0453 - val_loss: 0.0257\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0350 - val_loss: 0.0262\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0373 - val_loss: 0.0242\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0251\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0244\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0249\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0247\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0246\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0244\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0331 - val_loss: 0.0240\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0238\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0236\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0233\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0327 - val_loss: 0.0228\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0318 - val_loss: 0.0226\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0310 - val_loss: 0.0220\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0309 - val_loss: 0.0214\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0311 - val_loss: 0.0211\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0299 - val_loss: 0.0211\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0293 - val_loss: 0.0205\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0282 - val_loss: 0.0193\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0276 - val_loss: 0.0184\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0262 - val_loss: 0.0178\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0254 - val_loss: 0.0170\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0240 - val_loss: 0.0160\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0224 - val_loss: 0.0152\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0209 - val_loss: 0.0153\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0138\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0135\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0170 - val_loss: 0.0122\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.0122\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0157 - val_loss: 0.0117\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0109\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0095\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0087\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0075\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0076 - val_loss: 0.0088\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0077\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0091\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0067\n",
      "evolution of the gridsearch: step  34\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 74s 319ms/step - loss: 0.1117 - val_loss: 0.0468\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0467 - val_loss: 0.0364\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0423 - val_loss: 0.0248\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0379 - val_loss: 0.0266\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0377 - val_loss: 0.0244\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0255\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0356 - val_loss: 0.0243\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0350 - val_loss: 0.0246\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0244\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0244\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0243\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0335 - val_loss: 0.0242\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0335 - val_loss: 0.0242\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0329 - val_loss: 0.0242\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0240\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0336 - val_loss: 0.0237\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0239\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0323 - val_loss: 0.0228\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0224\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0313 - val_loss: 0.0221\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0306 - val_loss: 0.0216\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0301 - val_loss: 0.0211\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0294 - val_loss: 0.0206\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0293 - val_loss: 0.0199\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0278 - val_loss: 0.0194\n",
      "evolution of the gridsearch: step  35\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 75s 325ms/step - loss: 0.1038 - val_loss: 0.0385\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0404 - val_loss: 0.0371\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0408 - val_loss: 0.0256\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0380 - val_loss: 0.0283\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0377 - val_loss: 0.0248\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0348 - val_loss: 0.0260\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0246\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0249\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0245\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0342 - val_loss: 0.0245\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0337 - val_loss: 0.0245\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0245\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0244\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0242\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0239\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0236\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0233\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0231\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0228\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0314 - val_loss: 0.0225\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0312 - val_loss: 0.0223\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0307 - val_loss: 0.0218\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0302 - val_loss: 0.0215\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0296 - val_loss: 0.0211\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0294 - val_loss: 0.0204\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0285 - val_loss: 0.0201\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0283 - val_loss: 0.0193\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0275 - val_loss: 0.0190\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0273 - val_loss: 0.0183\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0253 - val_loss: 0.0180\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0247 - val_loss: 0.0170\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0236 - val_loss: 0.0162\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0224 - val_loss: 0.0156\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0219 - val_loss: 0.0151\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0203 - val_loss: 0.0148\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0198 - val_loss: 0.0143\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0186 - val_loss: 0.0136\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0128\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0171 - val_loss: 0.0123\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0116\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0141 - val_loss: 0.0111\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0090\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0091\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "evolution of the gridsearch: step  36\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 75s 324ms/step - loss: 0.1172 - val_loss: 0.0481\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0473 - val_loss: 0.0286\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0419 - val_loss: 0.0257\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0358 - val_loss: 0.0260\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0374 - val_loss: 0.0247\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0239\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0354 - val_loss: 0.0243\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0239\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0240\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0344 - val_loss: 0.0235\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0332 - val_loss: 0.0234\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0235\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0235\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0326 - val_loss: 0.0232\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0322 - val_loss: 0.0230\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0229\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0322 - val_loss: 0.0230\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0319 - val_loss: 0.0224\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0314 - val_loss: 0.0222\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0219\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0217\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0305 - val_loss: 0.0214\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0300 - val_loss: 0.0211\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0295 - val_loss: 0.0208\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0292 - val_loss: 0.0204\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0202\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0194\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0270 - val_loss: 0.0189\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0262 - val_loss: 0.0180\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0251 - val_loss: 0.0173\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0241 - val_loss: 0.0165\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0226 - val_loss: 0.0159\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0217 - val_loss: 0.0160\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0209 - val_loss: 0.0149\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0198 - val_loss: 0.0143\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0197 - val_loss: 0.0149\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0185 - val_loss: 0.0134\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0190 - val_loss: 0.0149\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0188 - val_loss: 0.0125\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0171 - val_loss: 0.0120\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0111\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0155 - val_loss: 0.0102\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0094\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0090\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0085\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0077\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0079\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0073\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0075\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0068\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0073\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "evolution of the gridsearch: step  37\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 76s 327ms/step - loss: 0.0765 - val_loss: 0.0314\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0374 - val_loss: 0.0253\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0369 - val_loss: 0.0241\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0373 - val_loss: 0.0243\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0360 - val_loss: 0.0247\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0330 - val_loss: 0.0240\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0323 - val_loss: 0.0249\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0333 - val_loss: 0.0226\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0323 - val_loss: 0.0218\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0318 - val_loss: 0.0223\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0304 - val_loss: 0.0204\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0291 - val_loss: 0.0195\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0274 - val_loss: 0.0186\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0264 - val_loss: 0.0176\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0251 - val_loss: 0.0160\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0229 - val_loss: 0.0157\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0211 - val_loss: 0.0143\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0191 - val_loss: 0.0134\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0181 - val_loss: 0.0126\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0188 - val_loss: 0.0127\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0185 - val_loss: 0.0114\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0151 - val_loss: 0.0108\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "evolution of the gridsearch: step  38\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 78s 335ms/step - loss: 0.0779 - val_loss: 0.0261\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0409 - val_loss: 0.0253\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0364 - val_loss: 0.0247\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0373 - val_loss: 0.0241\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0364 - val_loss: 0.0242\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0356 - val_loss: 0.0259\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0376 - val_loss: 0.0235\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0360 - val_loss: 0.0232\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0365 - val_loss: 0.0227\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0337 - val_loss: 0.0229\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0337 - val_loss: 0.0222\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0318 - val_loss: 0.0216\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0323 - val_loss: 0.0210\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0324 - val_loss: 0.0220\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0307 - val_loss: 0.0191\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0290 - val_loss: 0.0182\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0278 - val_loss: 0.0180\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0245 - val_loss: 0.0164\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0232 - val_loss: 0.0169\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0230 - val_loss: 0.0160\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0214 - val_loss: 0.0152\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0206 - val_loss: 0.0142\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0168 - val_loss: 0.0126\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0181 - val_loss: 0.0117\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0167 - val_loss: 0.0113\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0176 - val_loss: 0.0109\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0174 - val_loss: 0.0122\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0145 - val_loss: 0.0089\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0137 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0128 - val_loss: 0.0084\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0137 - val_loss: 0.0088\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0120 - val_loss: 0.0083\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0128 - val_loss: 0.0081\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0120 - val_loss: 0.0079\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0132 - val_loss: 0.0089\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0125 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0122 - val_loss: 0.0077\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0084\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0076\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0079\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0082\n",
      "evolution of the gridsearch: step  39\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 76s 329ms/step - loss: 0.0660 - val_loss: 0.0273\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0357 - val_loss: 0.0246\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0370 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0365 - val_loss: 0.0244\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0344 - val_loss: 0.0236\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0348 - val_loss: 0.0237\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0343 - val_loss: 0.0233\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0353 - val_loss: 0.0234\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0355 - val_loss: 0.0256\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0336 - val_loss: 0.0223\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0312 - val_loss: 0.0221\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0334 - val_loss: 0.0220\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0332 - val_loss: 0.0221\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0305 - val_loss: 0.0202\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0298 - val_loss: 0.0193\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0281 - val_loss: 0.0186\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0270 - val_loss: 0.0176\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0252 - val_loss: 0.0174\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0229 - val_loss: 0.0163\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0224 - val_loss: 0.0158\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0209 - val_loss: 0.0150\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0200 - val_loss: 0.0141\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0197 - val_loss: 0.0134\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0186 - val_loss: 0.0126\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0186 - val_loss: 0.0131\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0165 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0150 - val_loss: 0.0112\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0151 - val_loss: 0.0102\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0146 - val_loss: 0.0109\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0138 - val_loss: 0.0092\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0134 - val_loss: 0.0089\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0123 - val_loss: 0.0094\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0124 - val_loss: 0.0093\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0124 - val_loss: 0.0084\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0135 - val_loss: 0.0089\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0125 - val_loss: 0.0079\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0125 - val_loss: 0.0078\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0086\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0130 - val_loss: 0.0096\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0075\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0074\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0071\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0071\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0125 - val_loss: 0.0073\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0079\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0098 - val_loss: 0.0072\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0068\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0102 - val_loss: 0.0075\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0069\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0101 - val_loss: 0.0077\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0105 - val_loss: 0.0072\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0091 - val_loss: 0.0081\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0091 - val_loss: 0.0066\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0066\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0093\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0102 - val_loss: 0.0065\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0089 - val_loss: 0.0062\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0089 - val_loss: 0.0064\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0099 - val_loss: 0.0062\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "evolution of the gridsearch: step  40\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 76s 328ms/step - loss: 0.0977 - val_loss: 0.0281\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0428 - val_loss: 0.0258\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0373 - val_loss: 0.0266\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0387 - val_loss: 0.0248\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0363 - val_loss: 0.0245\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0356 - val_loss: 0.0248\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0245\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0343 - val_loss: 0.0243\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0245\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0357 - val_loss: 0.0243\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0254\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0239\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0353 - val_loss: 0.0237\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0235\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0240\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0231\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0237\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0225\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0317 - val_loss: 0.0222\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0217\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0311 - val_loss: 0.0212\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0294 - val_loss: 0.0212\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0300 - val_loss: 0.0201\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0287 - val_loss: 0.0194\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0282 - val_loss: 0.0189\n",
      "evolution of the gridsearch: step  41\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 79s 340ms/step - loss: 0.1115 - val_loss: 0.0340\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0450 - val_loss: 0.0308\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0268\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0386 - val_loss: 0.0247\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0359 - val_loss: 0.0250\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0367 - val_loss: 0.0245\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0362 - val_loss: 0.0249\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0374 - val_loss: 0.0253\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0367 - val_loss: 0.0245\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0249\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0352 - val_loss: 0.0243\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0243\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0239\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0239\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0343 - val_loss: 0.0237\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0236\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0241\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0323 - val_loss: 0.0229\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0343 - val_loss: 0.0226\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0321 - val_loss: 0.0224\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0319 - val_loss: 0.0218\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0219\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0323 - val_loss: 0.0214\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0305 - val_loss: 0.0213\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0303 - val_loss: 0.0204\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0297 - val_loss: 0.0201\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0286 - val_loss: 0.0195\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0290 - val_loss: 0.0189\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0276 - val_loss: 0.0183\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0263 - val_loss: 0.0174\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0264 - val_loss: 0.0168\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0237 - val_loss: 0.0165\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0226 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0222 - val_loss: 0.0144\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0207 - val_loss: 0.0145\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0195 - val_loss: 0.0135\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0190 - val_loss: 0.0134\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0207 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0166 - val_loss: 0.0140\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0115\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0108\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.0109\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0171 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0173 - val_loss: 0.0103\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0090\n",
      "evolution of the gridsearch: step  42\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 77s 332ms/step - loss: 0.1209 - val_loss: 0.0487\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0428 - val_loss: 0.0428\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0446 - val_loss: 0.0255\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0410 - val_loss: 0.0255\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0249\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0377 - val_loss: 0.0245\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0360 - val_loss: 0.0246\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0378 - val_loss: 0.0250\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0247\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0241\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0242\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0348 - val_loss: 0.0243\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0237\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0234\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0228\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0229\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0328 - val_loss: 0.0223\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0314 - val_loss: 0.0221\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0215\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0316 - val_loss: 0.0210\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0290 - val_loss: 0.0209\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0308 - val_loss: 0.0200\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0295 - val_loss: 0.0197\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0274 - val_loss: 0.0190\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0279 - val_loss: 0.0183\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0302 - val_loss: 0.0177\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0263 - val_loss: 0.0170\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0264 - val_loss: 0.0166\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0243 - val_loss: 0.0153\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0231 - val_loss: 0.0164\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0200 - val_loss: 0.0148\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0207 - val_loss: 0.0148\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0201 - val_loss: 0.0139\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0136\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0145\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0131\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0186 - val_loss: 0.0131\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0123\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0122\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0168 - val_loss: 0.0111\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0171 - val_loss: 0.0108\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0148 - val_loss: 0.0107\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0100\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0157 - val_loss: 0.0097\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0092\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0099\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0129 - val_loss: 0.0095\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0093\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0091\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0087\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0085\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0089\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0086\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0080\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0083\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0079\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0079\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0079\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0074\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0075\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0075\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0075\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0076\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0074\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0075\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0075\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0070\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0071\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0073\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0071\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0073\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0071\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0072\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0075\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0070\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0068\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0068\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0069\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0069\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0073\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0068\n",
      "evolution of the gridsearch: step  43\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 78s 335ms/step - loss: 0.0817 - val_loss: 0.0264\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0413 - val_loss: 0.0287\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0397 - val_loss: 0.0274\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0376 - val_loss: 0.0255\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0253\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0370 - val_loss: 0.0242\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0364 - val_loss: 0.0252\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0362 - val_loss: 0.0242\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0239\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0238\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0342 - val_loss: 0.0237\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0235\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0325 - val_loss: 0.0237\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0333 - val_loss: 0.0234\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0348 - val_loss: 0.0232\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0331 - val_loss: 0.0233\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0226\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0291 - val_loss: 0.0226\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0218\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0310 - val_loss: 0.0228\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0315 - val_loss: 0.0212\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0210\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0308 - val_loss: 0.0209\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0316 - val_loss: 0.0197\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0295 - val_loss: 0.0192\n",
      "evolution of the gridsearch: step  44\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 80s 344ms/step - loss: 0.1140 - val_loss: 0.0471\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0423 - val_loss: 0.0356\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0454 - val_loss: 0.0248\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0365 - val_loss: 0.0272\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0380 - val_loss: 0.0244\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0369 - val_loss: 0.0253\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0359 - val_loss: 0.0238\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0239\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0347 - val_loss: 0.0235\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0235\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0345 - val_loss: 0.0238\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0232\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0325 - val_loss: 0.0230\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0317 - val_loss: 0.0229\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0228\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0224\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0311 - val_loss: 0.0221\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0309 - val_loss: 0.0218\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0316 - val_loss: 0.0215\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0303 - val_loss: 0.0211\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0308 - val_loss: 0.0209\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0288 - val_loss: 0.0204\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0292 - val_loss: 0.0199\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0295 - val_loss: 0.0195\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0190\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0281 - val_loss: 0.0183\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0264 - val_loss: 0.0180\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0272 - val_loss: 0.0175\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0248 - val_loss: 0.0167\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0239 - val_loss: 0.0159\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0234 - val_loss: 0.0153\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0227 - val_loss: 0.0150\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0210 - val_loss: 0.0139\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0191 - val_loss: 0.0134\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0187 - val_loss: 0.0134\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0199 - val_loss: 0.0129\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0173 - val_loss: 0.0121\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0164 - val_loss: 0.0126\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0176 - val_loss: 0.0112\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0172 - val_loss: 0.0106\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0159 - val_loss: 0.0106\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0099\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0145 - val_loss: 0.0095\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0155 - val_loss: 0.0095\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.0092\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0090\n",
      "evolution of the gridsearch: step  45\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 82s 355ms/step - loss: 0.1027 - val_loss: 0.0407\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0478 - val_loss: 0.0349\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0419 - val_loss: 0.0248\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0374 - val_loss: 0.0259\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0369 - val_loss: 0.0239\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0356 - val_loss: 0.0247\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0237\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0344 - val_loss: 0.0239\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0236\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0341 - val_loss: 0.0236\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0237\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0336 - val_loss: 0.0237\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0337 - val_loss: 0.0234\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0233\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0355 - val_loss: 0.0233\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0237\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0326 - val_loss: 0.0232\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0333 - val_loss: 0.0226\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0325 - val_loss: 0.0231\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0222\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0319 - val_loss: 0.0220\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0222\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0327 - val_loss: 0.0216\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0321 - val_loss: 0.0213\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0308 - val_loss: 0.0210\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0208\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0313 - val_loss: 0.0201\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0289 - val_loss: 0.0199\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0291 - val_loss: 0.0193\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0281 - val_loss: 0.0191\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0184\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0275 - val_loss: 0.0177\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0255 - val_loss: 0.0173\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0266 - val_loss: 0.0167\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0245 - val_loss: 0.0164\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0247 - val_loss: 0.0157\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0232 - val_loss: 0.0154\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0225 - val_loss: 0.0147\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0203 - val_loss: 0.0143\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0140\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0202 - val_loss: 0.0136\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0210 - val_loss: 0.0133\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0207 - val_loss: 0.0133\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0201 - val_loss: 0.0125\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0188 - val_loss: 0.0131\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0117\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0171 - val_loss: 0.0108\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0160 - val_loss: 0.0103\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0160 - val_loss: 0.0098\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0095\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0150 - val_loss: 0.0094\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0160 - val_loss: 0.0098\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0092\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0092\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0088\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0139 - val_loss: 0.0089\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0130 - val_loss: 0.0086\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0134 - val_loss: 0.0082\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0080\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0085\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0081\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0078\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0079\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0079\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0078\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0075\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0076\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0116 - val_loss: 0.0076\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0074\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0077\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0072\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0071\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0071\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0109 - val_loss: 0.0072\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0073\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0071\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0078\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0071\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0074\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0072\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0069\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0069\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0070\n",
      "evolution of the gridsearch: step  46\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 81s 347ms/step - loss: 0.0912 - val_loss: 0.0270\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0380 - val_loss: 0.0253\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0378 - val_loss: 0.0243\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0358 - val_loss: 0.0243\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0360 - val_loss: 0.0247\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0368 - val_loss: 0.0248\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0344 - val_loss: 0.0246\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0345 - val_loss: 0.0237\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0330 - val_loss: 0.0235\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0371 - val_loss: 0.0232\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0339 - val_loss: 0.0232\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0338 - val_loss: 0.0225\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0314 - val_loss: 0.0229\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0356 - val_loss: 0.0215\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0322 - val_loss: 0.0212\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0293 - val_loss: 0.0208\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0292 - val_loss: 0.0198\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0295 - val_loss: 0.0197\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0290 - val_loss: 0.0172\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0255 - val_loss: 0.0164\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0238 - val_loss: 0.0158\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0209 - val_loss: 0.0148\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0228 - val_loss: 0.0146\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0212 - val_loss: 0.0130\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0212 - val_loss: 0.0125\n",
      "evolution of the gridsearch: step  47\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 84s 364ms/step - loss: 0.0537 - val_loss: 0.0271\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0475 - val_loss: 0.0248\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0370 - val_loss: 0.0235\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0365 - val_loss: 0.0234\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0357 - val_loss: 0.0241\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0353 - val_loss: 0.0235\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0355 - val_loss: 0.0244\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0358 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0339 - val_loss: 0.0229\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0329 - val_loss: 0.0245\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0355 - val_loss: 0.0218\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0339 - val_loss: 0.0216\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0333 - val_loss: 0.0214\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0307 - val_loss: 0.0209\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0307 - val_loss: 0.0207\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0310 - val_loss: 0.0197\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0299 - val_loss: 0.0190\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0303 - val_loss: 0.0186\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0261 - val_loss: 0.0172\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0255 - val_loss: 0.0164\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0229 - val_loss: 0.0153\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0226 - val_loss: 0.0143\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0211 - val_loss: 0.0140\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0233 - val_loss: 0.0166\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0207 - val_loss: 0.0137\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0183 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0185 - val_loss: 0.0117\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0188 - val_loss: 0.0121\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0193 - val_loss: 0.0120\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0186 - val_loss: 0.0107\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0180 - val_loss: 0.0102\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0156 - val_loss: 0.0099\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0164 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0153 - val_loss: 0.0091\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0139 - val_loss: 0.0089\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0160 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0143 - val_loss: 0.0086\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0091\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0147 - val_loss: 0.0088\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0154 - val_loss: 0.0095\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0152 - val_loss: 0.0084\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0136 - val_loss: 0.0084\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0131 - val_loss: 0.0082\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0139 - val_loss: 0.0079\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0146 - val_loss: 0.0084\n",
      "evolution of the gridsearch: step  48\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 83s 357ms/step - loss: 0.0797 - val_loss: 0.0380\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0416 - val_loss: 0.0260\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0370 - val_loss: 0.0244\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0359 - val_loss: 0.0241\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0374 - val_loss: 0.0241\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0364 - val_loss: 0.0241\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0362 - val_loss: 0.0243\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0348 - val_loss: 0.0239\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0348 - val_loss: 0.0239\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0343 - val_loss: 0.0232\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0315 - val_loss: 0.0231\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0335 - val_loss: 0.0219\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0319 - val_loss: 0.0224\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0325 - val_loss: 0.0211\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0314 - val_loss: 0.0209\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0327 - val_loss: 0.0200\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0317 - val_loss: 0.0201\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0298 - val_loss: 0.0184\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0280 - val_loss: 0.0177\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0272 - val_loss: 0.0167\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0262 - val_loss: 0.0160\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0264 - val_loss: 0.0167\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0241 - val_loss: 0.0168\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0229 - val_loss: 0.0132\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0191 - val_loss: 0.0130\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0234 - val_loss: 0.0133\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0210 - val_loss: 0.0146\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0192 - val_loss: 0.0118\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0188 - val_loss: 0.0130\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0187 - val_loss: 0.0109\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0179 - val_loss: 0.0110\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0193 - val_loss: 0.0145\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0190 - val_loss: 0.0116\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0153 - val_loss: 0.0096\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0177 - val_loss: 0.0115\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0181 - val_loss: 0.0102\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0159 - val_loss: 0.0098\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0092\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0144 - val_loss: 0.0088\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0154 - val_loss: 0.0090\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0146 - val_loss: 0.0084\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0161 - val_loss: 0.0090\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0154 - val_loss: 0.0086\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0151 - val_loss: 0.0087\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0173 - val_loss: 0.0083\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0164 - val_loss: 0.0081\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0134 - val_loss: 0.0081\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0130 - val_loss: 0.0085\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0137 - val_loss: 0.0086\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0133 - val_loss: 0.0085\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0132 - val_loss: 0.0089\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0146 - val_loss: 0.0080\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0121 - val_loss: 0.0079\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0087\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0137 - val_loss: 0.0073\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0131 - val_loss: 0.0073\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0131 - val_loss: 0.0078\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0126 - val_loss: 0.0077\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0074\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0074\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0075\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0132 - val_loss: 0.0081\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0123 - val_loss: 0.0069\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0124 - val_loss: 0.0073\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0122 - val_loss: 0.0079\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0139 - val_loss: 0.0074\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0070\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0077\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0074\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0070\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0100 - val_loss: 0.0070\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0066\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0066\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0072\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0071\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0069\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0132 - val_loss: 0.0092\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0074\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0068\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0073\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0103 - val_loss: 0.0073\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0066\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0095 - val_loss: 0.0065\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0074\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0066\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0065\n",
      "evolution of the gridsearch: step  49\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 83s 360ms/step - loss: 0.1194 - val_loss: 0.0341\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0455 - val_loss: 0.0277\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0381 - val_loss: 0.0276\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0418 - val_loss: 0.0243\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0382 - val_loss: 0.0255\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0382 - val_loss: 0.0252\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0244\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0360 - val_loss: 0.0247\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0358 - val_loss: 0.0246\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0238\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0363 - val_loss: 0.0237\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0366 - val_loss: 0.0237\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0238\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0363 - val_loss: 0.0237\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0234\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0362 - val_loss: 0.0234\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0231\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0223\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0220\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0219\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0317 - val_loss: 0.0218\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0328 - val_loss: 0.0217\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0217\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0212\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0214\n",
      "evolution of the gridsearch: step  50\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 86s 370ms/step - loss: 0.1114 - val_loss: 0.0352\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0415 - val_loss: 0.0304\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0424 - val_loss: 0.0257\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0401 - val_loss: 0.0241\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0366 - val_loss: 0.0238\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0366 - val_loss: 0.0238\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0241\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0346 - val_loss: 0.0238\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0355 - val_loss: 0.0242\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0344 - val_loss: 0.0239\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0342 - val_loss: 0.0238\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0352 - val_loss: 0.0243\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0330 - val_loss: 0.0232\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0333 - val_loss: 0.0226\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0329 - val_loss: 0.0222\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0332 - val_loss: 0.0222\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0217\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0214\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0212\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0210\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0310 - val_loss: 0.0201\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0303 - val_loss: 0.0198\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0193\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0304 - val_loss: 0.0188\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0286 - val_loss: 0.0185\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0270 - val_loss: 0.0187\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0295 - val_loss: 0.0174\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0260 - val_loss: 0.0173\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0266 - val_loss: 0.0167\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0251 - val_loss: 0.0156\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0243 - val_loss: 0.0152\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0226 - val_loss: 0.0142\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0137\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0128\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0210 - val_loss: 0.0135\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0196 - val_loss: 0.0126\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0137\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0173 - val_loss: 0.0119\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0122\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0113\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0186 - val_loss: 0.0108\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0108\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0099\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0092\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0148 - val_loss: 0.0092\n",
      "evolution of the gridsearch: step  51\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 87s 377ms/step - loss: 0.1165 - val_loss: 0.0406\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0410 - val_loss: 0.0315\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0398 - val_loss: 0.0257\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0382 - val_loss: 0.0247\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0397 - val_loss: 0.0248\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0377 - val_loss: 0.0248\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0251\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0248\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0254\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0371 - val_loss: 0.0250\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0248\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0371 - val_loss: 0.0250\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0247\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0236\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0234\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0230\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0228\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0223\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0237\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0318 - val_loss: 0.0218\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0212\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0322 - val_loss: 0.0208\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0305 - val_loss: 0.0203\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0303 - val_loss: 0.0203\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0290 - val_loss: 0.0194\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0262 - val_loss: 0.0187\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0261 - val_loss: 0.0186\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0260 - val_loss: 0.0173\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0249 - val_loss: 0.0165\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0240 - val_loss: 0.0157\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0229 - val_loss: 0.0150\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0232 - val_loss: 0.0149\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0222 - val_loss: 0.0148\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0250 - val_loss: 0.0147\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0201 - val_loss: 0.0140\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0213 - val_loss: 0.0140\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0201 - val_loss: 0.0129\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0127\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0173 - val_loss: 0.0115\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0212 - val_loss: 0.0118\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0192 - val_loss: 0.0128\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0179 - val_loss: 0.0113\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0200 - val_loss: 0.0127\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0187 - val_loss: 0.0109\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0184 - val_loss: 0.0097\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0095\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0162 - val_loss: 0.0094\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0171 - val_loss: 0.0093\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.0095\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0149 - val_loss: 0.0091\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0089\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0088\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0144 - val_loss: 0.0100\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0136 - val_loss: 0.0089\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0167 - val_loss: 0.0087\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0084\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0092\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0085\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0088\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0086\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0082\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0149 - val_loss: 0.0094\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0081\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0148 - val_loss: 0.0086\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0081\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0078\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0078\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0138 - val_loss: 0.0078\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0121 - val_loss: 0.0080\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0119 - val_loss: 0.0084\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0129 - val_loss: 0.0082\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0144 - val_loss: 0.0085\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0153 - val_loss: 0.0081\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0090\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0078\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0075\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0075\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0074\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0077\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0075\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0085\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0071\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0073\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0075\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0073\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0077\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0072\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0073\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0077\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0072\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0071\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0079\n",
      "evolution of the gridsearch: step  52\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 86s 372ms/step - loss: 0.1011 - val_loss: 0.0376\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0447 - val_loss: 0.0357\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0438 - val_loss: 0.0253\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0379 - val_loss: 0.0276\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0385 - val_loss: 0.0246\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0376 - val_loss: 0.0245\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0350 - val_loss: 0.0242\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0248\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0382 - val_loss: 0.0246\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0354 - val_loss: 0.0241\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0380 - val_loss: 0.0241\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0339 - val_loss: 0.0241\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0240\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0344 - val_loss: 0.0239\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0341 - val_loss: 0.0242\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0352 - val_loss: 0.0235\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0234\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0366 - val_loss: 0.0234\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0337 - val_loss: 0.0230\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0228\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0320 - val_loss: 0.0224\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0324 - val_loss: 0.0220\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0335 - val_loss: 0.0222\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0215\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0213\n",
      "evolution of the gridsearch: step  53\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 86s 371ms/step - loss: 0.1082 - val_loss: 0.0437\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0504 - val_loss: 0.0310\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0442 - val_loss: 0.0242\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0402 - val_loss: 0.0270\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0385 - val_loss: 0.0239\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0387 - val_loss: 0.0241\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0350 - val_loss: 0.0235\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0235\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0361 - val_loss: 0.0236\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0235\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0234\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0346 - val_loss: 0.0237\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0360 - val_loss: 0.0233\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0334 - val_loss: 0.0233\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0347 - val_loss: 0.0234\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0230\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0227\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0237\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0220\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0331 - val_loss: 0.0220\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0314 - val_loss: 0.0217\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0298 - val_loss: 0.0215\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0322 - val_loss: 0.0212\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0330 - val_loss: 0.0209\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0211\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0203\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0285 - val_loss: 0.0198\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0293 - val_loss: 0.0193\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0189\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0311 - val_loss: 0.0185\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0181\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0276 - val_loss: 0.0177\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0267 - val_loss: 0.0176\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0259 - val_loss: 0.0167\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0245 - val_loss: 0.0161\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0230 - val_loss: 0.0156\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0234 - val_loss: 0.0152\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0223 - val_loss: 0.0149\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0223 - val_loss: 0.0149\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0216 - val_loss: 0.0140\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0215 - val_loss: 0.0141\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0221 - val_loss: 0.0131\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0208 - val_loss: 0.0125\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0204 - val_loss: 0.0124\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0198 - val_loss: 0.0122\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0183 - val_loss: 0.0122\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0177 - val_loss: 0.0115\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0173 - val_loss: 0.0115\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0188 - val_loss: 0.0112\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0173 - val_loss: 0.0111\n",
      "evolution of the gridsearch: step  54\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 88s 379ms/step - loss: 0.1013 - val_loss: 0.0352\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0418 - val_loss: 0.0316\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0418 - val_loss: 0.0256\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0377 - val_loss: 0.0264\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0245\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0387 - val_loss: 0.0244\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0379 - val_loss: 0.0254\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0343 - val_loss: 0.0244\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0355 - val_loss: 0.0244\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0248\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0362 - val_loss: 0.0248\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0353 - val_loss: 0.0244\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0365 - val_loss: 0.0242\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0356 - val_loss: 0.0241\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0338 - val_loss: 0.0239\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0347 - val_loss: 0.0241\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0340 - val_loss: 0.0238\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0231\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0318 - val_loss: 0.0232\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0348 - val_loss: 0.0225\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0319 - val_loss: 0.0223\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0222\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0335 - val_loss: 0.0220\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0306 - val_loss: 0.0219\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0322 - val_loss: 0.0216\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0310 - val_loss: 0.0211\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0314 - val_loss: 0.0208\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0302 - val_loss: 0.0204\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0312 - val_loss: 0.0199\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0303 - val_loss: 0.0195\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0305 - val_loss: 0.0191\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0302 - val_loss: 0.0188\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0294 - val_loss: 0.0185\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0291 - val_loss: 0.0176\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0253 - val_loss: 0.0174\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0254 - val_loss: 0.0169\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0263 - val_loss: 0.0167\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0222 - val_loss: 0.0158\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0254 - val_loss: 0.0151\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0212 - val_loss: 0.0146\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0222 - val_loss: 0.0149\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0216 - val_loss: 0.0140\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0200 - val_loss: 0.0137\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0201 - val_loss: 0.0134\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0184 - val_loss: 0.0131\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0192 - val_loss: 0.0127\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0174 - val_loss: 0.0133\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0203 - val_loss: 0.0126\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0120\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0191 - val_loss: 0.0117\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0208 - val_loss: 0.0115\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0176 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0166 - val_loss: 0.0106\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0163 - val_loss: 0.0098\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0167 - val_loss: 0.0100\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0148 - val_loss: 0.0097\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0163 - val_loss: 0.0093\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0091\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0163 - val_loss: 0.0092\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0090\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0145 - val_loss: 0.0087\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0087\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0094\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0088\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0091\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0088\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0136 - val_loss: 0.0088\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0083\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0082\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0142 - val_loss: 0.0082\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0081\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0131 - val_loss: 0.0080\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0135 - val_loss: 0.0089\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0140 - val_loss: 0.0082\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0130 - val_loss: 0.0083\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0081\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0139 - val_loss: 0.0080\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0079\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0081\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0079\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0131 - val_loss: 0.0078\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0077\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0138 - val_loss: 0.0076\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0147 - val_loss: 0.0080\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0129 - val_loss: 0.0076\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0076\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0078\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0077\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0077\n",
      "evolution of the gridsearch: step  55\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 89s 384ms/step - loss: 0.0718 - val_loss: 0.0251\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0365 - val_loss: 0.0255\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0350 - val_loss: 0.0239\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0355 - val_loss: 0.0233\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0336 - val_loss: 0.0254\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0329 - val_loss: 0.0235\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0310 - val_loss: 0.0223\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0315 - val_loss: 0.0207\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0298 - val_loss: 0.0195\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0273 - val_loss: 0.0181\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0256 - val_loss: 0.0185\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0233 - val_loss: 0.0150\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0201 - val_loss: 0.0145\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0184 - val_loss: 0.0124\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0174 - val_loss: 0.0123\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0149 - val_loss: 0.0145\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0145 - val_loss: 0.0095\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0125 - val_loss: 0.0095\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0115 - val_loss: 0.0096\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0105 - val_loss: 0.0076\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0079\n",
      "evolution of the gridsearch: step  56\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 90s 390ms/step - loss: 0.0636 - val_loss: 0.0309\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0372 - val_loss: 0.0249\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0353 - val_loss: 0.0242\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0340 - val_loss: 0.0242\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0337 - val_loss: 0.0242\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0365 - val_loss: 0.0232\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0349 - val_loss: 0.0232\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0312 - val_loss: 0.0221\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0302 - val_loss: 0.0245\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0321 - val_loss: 0.0202\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0277 - val_loss: 0.0188\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0257 - val_loss: 0.0213\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0291 - val_loss: 0.0194\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0225 - val_loss: 0.0154\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0193 - val_loss: 0.0130\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0177 - val_loss: 0.0121\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0139 - val_loss: 0.0096\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0090\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0104 - val_loss: 0.0075\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0077\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "evolution of the gridsearch: step  57\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 88s 381ms/step - loss: 0.0603 - val_loss: 0.0265\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0354 - val_loss: 0.0310\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0377 - val_loss: 0.0261\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0345 - val_loss: 0.0236\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0342 - val_loss: 0.0235\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0331 - val_loss: 0.0232\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0337 - val_loss: 0.0220\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0342 - val_loss: 0.0217\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0307 - val_loss: 0.0213\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0282 - val_loss: 0.0180\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0251 - val_loss: 0.0161\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0219 - val_loss: 0.0146\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0192 - val_loss: 0.0136\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0186 - val_loss: 0.0126\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0165 - val_loss: 0.0136\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0145 - val_loss: 0.0096\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0089\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0079\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0103 - val_loss: 0.0075\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0101 - val_loss: 0.0072\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0100 - val_loss: 0.0072\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0075\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0073 - val_loss: 0.0074\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0071 - val_loss: 0.0083\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0102 - val_loss: 0.0064\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0079 - val_loss: 0.0066\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0070 - val_loss: 0.0092\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0063 - val_loss: 0.0073\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0072 - val_loss: 0.0084\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0063 - val_loss: 0.0087\n",
      "evolution of the gridsearch: step  58\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 91s 390ms/step - loss: 0.1186 - val_loss: 0.0360\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0470 - val_loss: 0.0249\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0408 - val_loss: 0.0266\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0358 - val_loss: 0.0271\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0366 - val_loss: 0.0241\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0348 - val_loss: 0.0239\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0336 - val_loss: 0.0242\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0335 - val_loss: 0.0242\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0331 - val_loss: 0.0237\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0327 - val_loss: 0.0234\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0322 - val_loss: 0.0234\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0315 - val_loss: 0.0227\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0315 - val_loss: 0.0220\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0302 - val_loss: 0.0209\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0288 - val_loss: 0.0201\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0187\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0264 - val_loss: 0.0174\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0260 - val_loss: 0.0164\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0258 - val_loss: 0.0159\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0230 - val_loss: 0.0145\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0206 - val_loss: 0.0141\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0194 - val_loss: 0.0132\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0187 - val_loss: 0.0129\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0170 - val_loss: 0.0118\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0159 - val_loss: 0.0116\n",
      "evolution of the gridsearch: step  59\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 94s 405ms/step - loss: 0.0866 - val_loss: 0.0398\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0458 - val_loss: 0.0286\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0369 - val_loss: 0.0244\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0353 - val_loss: 0.0242\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0339 - val_loss: 0.0242\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0341 - val_loss: 0.0244\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0337 - val_loss: 0.0240\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0334 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0327 - val_loss: 0.0235\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0333 - val_loss: 0.0234\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0325 - val_loss: 0.0228\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0317 - val_loss: 0.0226\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0318 - val_loss: 0.0219\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0309 - val_loss: 0.0213\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0305 - val_loss: 0.0208\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0294 - val_loss: 0.0204\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0293 - val_loss: 0.0198\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0190\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0268 - val_loss: 0.0182\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0260 - val_loss: 0.0175\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0250 - val_loss: 0.0160\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0222 - val_loss: 0.0150\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0203 - val_loss: 0.0141\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0193 - val_loss: 0.0134\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0181 - val_loss: 0.0130\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0171 - val_loss: 0.0124\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0171 - val_loss: 0.0143\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0176 - val_loss: 0.0114\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0144 - val_loss: 0.0108\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0145 - val_loss: 0.0108\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0128 - val_loss: 0.0095\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0132 - val_loss: 0.0090\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0129 - val_loss: 0.0100\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0124 - val_loss: 0.0084\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0108 - val_loss: 0.0077\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0101 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0101 - val_loss: 0.0075\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 6ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0098 - val_loss: 0.0071\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0087 - val_loss: 0.0068\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "evolution of the gridsearch: step  60\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 93s 402ms/step - loss: 0.0673 - val_loss: 0.0479\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0474 - val_loss: 0.0321\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0401 - val_loss: 0.0241\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0358 - val_loss: 0.0247\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0342 - val_loss: 0.0237\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0337 - val_loss: 0.0238\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0338 - val_loss: 0.0232\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0328 - val_loss: 0.0230\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0322 - val_loss: 0.0227\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0331 - val_loss: 0.0224\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0344 - val_loss: 0.0228\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0314 - val_loss: 0.0221\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0306 - val_loss: 0.0221\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0296 - val_loss: 0.0211\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0299 - val_loss: 0.0199\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0192\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0271 - val_loss: 0.0182\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0267 - val_loss: 0.0175\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0272 - val_loss: 0.0163\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0256 - val_loss: 0.0153\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0228 - val_loss: 0.0143\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0197 - val_loss: 0.0137\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0185 - val_loss: 0.0126\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0175 - val_loss: 0.0121\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0152 - val_loss: 0.0114\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0145 - val_loss: 0.0093\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0125 - val_loss: 0.0089\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0121 - val_loss: 0.0092\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0129 - val_loss: 0.0107\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0130 - val_loss: 0.0115\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0112 - val_loss: 0.0088\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0107 - val_loss: 0.0080\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0076\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0076\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0123 - val_loss: 0.0074\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0070\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0101 - val_loss: 0.0083\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0100 - val_loss: 0.0092\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0066\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0073 - val_loss: 0.0064\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0069\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "evolution of the gridsearch: step  61\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 94s 407ms/step - loss: 0.0806 - val_loss: 0.0315\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0507 - val_loss: 0.0259\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0407 - val_loss: 0.0317\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0396 - val_loss: 0.0245\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0260\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0241\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0242\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0240\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0238\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0238\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0236\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0325 - val_loss: 0.0241\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0321 - val_loss: 0.0231\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0318 - val_loss: 0.0229\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0314 - val_loss: 0.0223\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0218\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0300 - val_loss: 0.0214\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0297 - val_loss: 0.0207\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0288 - val_loss: 0.0200\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0283 - val_loss: 0.0193\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0276 - val_loss: 0.0184\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0257 - val_loss: 0.0177\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0246 - val_loss: 0.0165\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0230 - val_loss: 0.0155\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0213 - val_loss: 0.0147\n",
      "evolution of the gridsearch: step  62\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 94s 404ms/step - loss: 0.1001 - val_loss: 0.0264\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0415 - val_loss: 0.0256\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0264\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0357 - val_loss: 0.0242\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0356 - val_loss: 0.0242\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0242\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0239\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0239\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0248\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0335 - val_loss: 0.0238\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0332 - val_loss: 0.0234\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0328 - val_loss: 0.0237\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0323 - val_loss: 0.0230\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0332 - val_loss: 0.0227\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0323 - val_loss: 0.0234\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0319 - val_loss: 0.0222\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0310 - val_loss: 0.0216\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0303 - val_loss: 0.0213\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0297 - val_loss: 0.0209\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0291 - val_loss: 0.0204\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0290 - val_loss: 0.0197\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0276 - val_loss: 0.0188\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0263 - val_loss: 0.0179\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0251 - val_loss: 0.0167\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0236 - val_loss: 0.0156\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0219 - val_loss: 0.0147\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0210 - val_loss: 0.0141\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0198 - val_loss: 0.0142\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0123\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.0110\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0085\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0074\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0071\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0070\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0072\n",
      "evolution of the gridsearch: step  63\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 97s 417ms/step - loss: 0.1201 - val_loss: 0.0367\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0457 - val_loss: 0.0325\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0285\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0401 - val_loss: 0.0260\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0348 - val_loss: 0.0263\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0357 - val_loss: 0.0241\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0245\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0238\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0240\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0238\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0236\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0326 - val_loss: 0.0234\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0233\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0322 - val_loss: 0.0231\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0317 - val_loss: 0.0227\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0314 - val_loss: 0.0224\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0310 - val_loss: 0.0221\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0307 - val_loss: 0.0217\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0214\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0296 - val_loss: 0.0210\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0296 - val_loss: 0.0203\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0285 - val_loss: 0.0197\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0291 - val_loss: 0.0190\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0287 - val_loss: 0.0196\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0275 - val_loss: 0.0182\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0247 - val_loss: 0.0171\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0236 - val_loss: 0.0159\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0222 - val_loss: 0.0149\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0208 - val_loss: 0.0145\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0194 - val_loss: 0.0137\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0133\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0119\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0117\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0090\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0086\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0077\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0081\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0074\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0071\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0066\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "evolution of the gridsearch: step  64\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 100s 432ms/step - loss: 0.0575 - val_loss: 0.0264\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0340 - val_loss: 0.0266\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0346 - val_loss: 0.0258\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0348 - val_loss: 0.0242\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0417 - val_loss: 0.0236\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0334 - val_loss: 0.0222\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0313 - val_loss: 0.0212\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0312 - val_loss: 0.0198\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0296 - val_loss: 0.0195\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0286 - val_loss: 0.0188\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0311 - val_loss: 0.0202\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0244 - val_loss: 0.0163\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0216 - val_loss: 0.0143\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0204 - val_loss: 0.0127\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0169 - val_loss: 0.0104\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0151 - val_loss: 0.0098\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0139 - val_loss: 0.0094\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0149 - val_loss: 0.0090\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0134 - val_loss: 0.0090\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0128 - val_loss: 0.0089\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0124 - val_loss: 0.0081\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0118 - val_loss: 0.0081\n",
      "evolution of the gridsearch: step  65\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 105s 452ms/step - loss: 0.0655 - val_loss: 0.0271\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0362 - val_loss: 0.0247\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0341 - val_loss: 0.0239\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0348 - val_loss: 0.0237\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0342 - val_loss: 0.0240\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0339 - val_loss: 0.0234\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0324 - val_loss: 0.0223\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0317 - val_loss: 0.0220\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0314 - val_loss: 0.0212\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0301 - val_loss: 0.0208\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0283 - val_loss: 0.0186\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0271 - val_loss: 0.0177\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0248 - val_loss: 0.0159\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0226 - val_loss: 0.0193\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0225 - val_loss: 0.0133\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0193 - val_loss: 0.0130\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0201 - val_loss: 0.0122\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0174 - val_loss: 0.0137\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0167 - val_loss: 0.0106\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0158 - val_loss: 0.0101\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0151 - val_loss: 0.0091\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0148 - val_loss: 0.0087\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0145 - val_loss: 0.0090\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0129 - val_loss: 0.0081\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0122 - val_loss: 0.0086\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0132 - val_loss: 0.0076\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 2s 9ms/step - loss: 0.0118 - val_loss: 0.0073\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0122 - val_loss: 0.0074\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0115 - val_loss: 0.0075\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0072\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0073\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0070\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0076\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0100 - val_loss: 0.0074\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0091 - val_loss: 0.0066\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0067\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0092 - val_loss: 0.0084\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0104 - val_loss: 0.0064\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0099 - val_loss: 0.0073\n",
      "evolution of the gridsearch: step  66\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 100s 430ms/step - loss: 0.0672 - val_loss: 0.0245\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0388 - val_loss: 0.0250\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0361 - val_loss: 0.0234\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0335 - val_loss: 0.0226\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0337 - val_loss: 0.0222\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0331 - val_loss: 0.0216\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0306 - val_loss: 0.0208\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0301 - val_loss: 0.0205\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0313 - val_loss: 0.0197\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0298 - val_loss: 0.0210\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0289 - val_loss: 0.0172\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0241 - val_loss: 0.0154\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0229 - val_loss: 0.0143\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0196 - val_loss: 0.0130\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0190 - val_loss: 0.0127\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0166 - val_loss: 0.0109\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0157 - val_loss: 0.0097\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0143 - val_loss: 0.0097\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0148 - val_loss: 0.0090\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0124 - val_loss: 0.0098\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0078\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0137 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0123 - val_loss: 0.0079\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0085\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0073\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0105 - val_loss: 0.0074\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0069\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0114 - val_loss: 0.0075\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0104 - val_loss: 0.0071\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0067\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0076\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0072\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0092 - val_loss: 0.0067\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0065\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0103 - val_loss: 0.0069\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0098 - val_loss: 0.0063\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0066\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0081\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0090 - val_loss: 0.0062\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0062\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0079 - val_loss: 0.0060\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0076 - val_loss: 0.0062\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0083 - val_loss: 0.0060\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0079 - val_loss: 0.0062\n",
      "evolution of the gridsearch: step  67\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 91s 391ms/step - loss: 0.0718 - val_loss: 0.0369\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0405 - val_loss: 0.0288\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0371 - val_loss: 0.0254\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0350 - val_loss: 0.0245\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0350 - val_loss: 0.0238\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0354 - val_loss: 0.0241\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0334 - val_loss: 0.0246\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0329 - val_loss: 0.0233\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0332 - val_loss: 0.0235\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0339 - val_loss: 0.0233\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0330 - val_loss: 0.0225\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0332 - val_loss: 0.0235\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0321 - val_loss: 0.0224\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0319 - val_loss: 0.0217\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0315 - val_loss: 0.0214\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0295 - val_loss: 0.0204\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0197\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0298 - val_loss: 0.0188\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0274 - val_loss: 0.0180\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0271 - val_loss: 0.0168\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0252 - val_loss: 0.0161\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0233 - val_loss: 0.0151\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0212 - val_loss: 0.0140\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0214 - val_loss: 0.0136\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0190 - val_loss: 0.0135\n",
      "evolution of the gridsearch: step  68\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 91s 394ms/step - loss: 0.0883 - val_loss: 0.0294\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0413 - val_loss: 0.0260\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0398 - val_loss: 0.0249\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0344 - val_loss: 0.0258\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0353 - val_loss: 0.0247\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0358 - val_loss: 0.0237\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0338 - val_loss: 0.0234\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0343 - val_loss: 0.0234\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0338 - val_loss: 0.0233\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0337 - val_loss: 0.0229\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0320 - val_loss: 0.0226\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0326 - val_loss: 0.0219\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0321 - val_loss: 0.0215\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0311 - val_loss: 0.0208\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0301 - val_loss: 0.0202\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0291 - val_loss: 0.0193\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0282 - val_loss: 0.0185\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0265 - val_loss: 0.0179\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0254 - val_loss: 0.0167\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0247 - val_loss: 0.0160\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0221 - val_loss: 0.0149\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0214 - val_loss: 0.0146\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0196 - val_loss: 0.0136\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0209 - val_loss: 0.0158\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0184 - val_loss: 0.0144\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0211 - val_loss: 0.0139\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0179 - val_loss: 0.0111\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0154 - val_loss: 0.0098\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0161 - val_loss: 0.0105\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0144 - val_loss: 0.0094\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0141 - val_loss: 0.0091\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0143 - val_loss: 0.0086\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0150 - val_loss: 0.0084\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0142 - val_loss: 0.0087\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0137 - val_loss: 0.0083\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0125 - val_loss: 0.0081\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0129 - val_loss: 0.0080\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0120 - val_loss: 0.0081\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0119 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0117 - val_loss: 0.0078\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0127 - val_loss: 0.0078\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0125 - val_loss: 0.0084\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0111 - val_loss: 0.0077\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0118 - val_loss: 0.0076\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0115 - val_loss: 0.0074\n",
      "evolution of the gridsearch: step  69\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 92s 397ms/step - loss: 0.0853 - val_loss: 0.0429\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0488 - val_loss: 0.0300\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0434 - val_loss: 0.0258\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0352 - val_loss: 0.0259\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0366 - val_loss: 0.0242\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0348 - val_loss: 0.0240\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0346 - val_loss: 0.0238\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0339 - val_loss: 0.0239\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0336 - val_loss: 0.0235\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0355 - val_loss: 0.0239\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0328 - val_loss: 0.0237\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0340 - val_loss: 0.0234\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0330 - val_loss: 0.0225\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0317 - val_loss: 0.0224\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0317 - val_loss: 0.0220\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0319 - val_loss: 0.0213\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0308 - val_loss: 0.0208\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0304 - val_loss: 0.0205\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0290 - val_loss: 0.0196\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0286 - val_loss: 0.0188\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0263 - val_loss: 0.0180\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0260 - val_loss: 0.0168\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0243 - val_loss: 0.0158\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0234 - val_loss: 0.0151\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0215 - val_loss: 0.0141\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0184 - val_loss: 0.0142\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0196 - val_loss: 0.0128\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0186 - val_loss: 0.0122\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0184 - val_loss: 0.0120\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0178 - val_loss: 0.0115\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0165 - val_loss: 0.0113\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0156 - val_loss: 0.0096\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0156 - val_loss: 0.0096\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0135 - val_loss: 0.0086\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0130 - val_loss: 0.0082\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0122 - val_loss: 0.0095\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0128 - val_loss: 0.0082\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0122 - val_loss: 0.0083\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0120 - val_loss: 0.0080\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0138 - val_loss: 0.0079\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0114 - val_loss: 0.0076\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0125 - val_loss: 0.0076\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0108 - val_loss: 0.0075\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0126 - val_loss: 0.0082\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0109 - val_loss: 0.0075\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0113 - val_loss: 0.0072\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0107 - val_loss: 0.0071\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0101 - val_loss: 0.0070\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0115 - val_loss: 0.0074\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0102 - val_loss: 0.0073\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0072\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0112 - val_loss: 0.0072\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0112 - val_loss: 0.0069\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0098 - val_loss: 0.0084\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0112 - val_loss: 0.0068\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0071\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0100 - val_loss: 0.0076\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0073\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0065\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0064\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0068\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0064\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0083 - val_loss: 0.0065\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0091 - val_loss: 0.0062\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "evolution of the gridsearch: step  70\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 92s 396ms/step - loss: 0.0899 - val_loss: 0.0257\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0457 - val_loss: 0.0250\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0376 - val_loss: 0.0277\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0368 - val_loss: 0.0241\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0350 - val_loss: 0.0240\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0237\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0344 - val_loss: 0.0237\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0331 - val_loss: 0.0234\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0230\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0316 - val_loss: 0.0230\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0317 - val_loss: 0.0225\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0313 - val_loss: 0.0220\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0310 - val_loss: 0.0216\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0310 - val_loss: 0.0212\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0295 - val_loss: 0.0207\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0292 - val_loss: 0.0199\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0289 - val_loss: 0.0195\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0279 - val_loss: 0.0187\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0280 - val_loss: 0.0177\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0257 - val_loss: 0.0167\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0270 - val_loss: 0.0161\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0239 - val_loss: 0.0154\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0220 - val_loss: 0.0147\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0211 - val_loss: 0.0142\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0136\n",
      "evolution of the gridsearch: step  71\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 94s 406ms/step - loss: 0.0973 - val_loss: 0.0262\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0394 - val_loss: 0.0259\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0369 - val_loss: 0.0256\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0242\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0245\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0251\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0350 - val_loss: 0.0237\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0331 - val_loss: 0.0238\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0235\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0332 - val_loss: 0.0232\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0352 - val_loss: 0.0229\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0227\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0321 - val_loss: 0.0223\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0311 - val_loss: 0.0220\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0316 - val_loss: 0.0218\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0307 - val_loss: 0.0210\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0207\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0288 - val_loss: 0.0202\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0298 - val_loss: 0.0193\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0285 - val_loss: 0.0186\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0276 - val_loss: 0.0178\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0254 - val_loss: 0.0174\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0250 - val_loss: 0.0163\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0234 - val_loss: 0.0156\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0223 - val_loss: 0.0147\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0204 - val_loss: 0.0147\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0202 - val_loss: 0.0135\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0193 - val_loss: 0.0132\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0135\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0187 - val_loss: 0.0124\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0170 - val_loss: 0.0122\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0167 - val_loss: 0.0107\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0095\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0090\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0086\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0085\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0126 - val_loss: 0.0086\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0085\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0083\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0081\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0076\n",
      "evolution of the gridsearch: step  72\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 93s 400ms/step - loss: 0.0830 - val_loss: 0.0276\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0500 - val_loss: 0.0258\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0436 - val_loss: 0.0323\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0394 - val_loss: 0.0238\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0268\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0350 - val_loss: 0.0231\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0338 - val_loss: 0.0239\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0228\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0229\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0342 - val_loss: 0.0225\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0333 - val_loss: 0.0226\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0325 - val_loss: 0.0222\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0310 - val_loss: 0.0219\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0216\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0212\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0210\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0305 - val_loss: 0.0202\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0286 - val_loss: 0.0196\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0297 - val_loss: 0.0191\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0268 - val_loss: 0.0184\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0274 - val_loss: 0.0176\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0264 - val_loss: 0.0179\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0251 - val_loss: 0.0161\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0229 - val_loss: 0.0155\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0201 - val_loss: 0.0148\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0204 - val_loss: 0.0147\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0204 - val_loss: 0.0136\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0136\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0180 - val_loss: 0.0125\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0177 - val_loss: 0.0122\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0156 - val_loss: 0.0111\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0107\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0103\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0099\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0095\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0094\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0090\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0129 - val_loss: 0.0091\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0085\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0143 - val_loss: 0.0087\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0084\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0084\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0082\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0081\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0079\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0084\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0077\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0079\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0077\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0076\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0078\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0072\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0072\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0076\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0070\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0073\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0070\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0070\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0071\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0069\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0069\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0067\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0067\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0068\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0095 - val_loss: 0.0066\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0069\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0067\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0092 - val_loss: 0.0074\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0064\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0064\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0089 - val_loss: 0.0064\n",
      "evolution of the gridsearch: step  73\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 94s 407ms/step - loss: 0.0702 - val_loss: 0.0268\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0387 - val_loss: 0.0246\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0358 - val_loss: 0.0249\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0356 - val_loss: 0.0237\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0368 - val_loss: 0.0235\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0341 - val_loss: 0.0233\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0344 - val_loss: 0.0238\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0324 - val_loss: 0.0213\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0324 - val_loss: 0.0208\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0325 - val_loss: 0.0265\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0312 - val_loss: 0.0235\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0293 - val_loss: 0.0178\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0266 - val_loss: 0.0162\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0263 - val_loss: 0.0155\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0225 - val_loss: 0.0144\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0223 - val_loss: 0.0175\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0244 - val_loss: 0.0121\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0188 - val_loss: 0.0147\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0203 - val_loss: 0.0141\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0179 - val_loss: 0.0138\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0198 - val_loss: 0.0106\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0145 - val_loss: 0.0094\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0151 - val_loss: 0.0089\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0137 - val_loss: 0.0089\n",
      "evolution of the gridsearch: step  74\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 95s 409ms/step - loss: 0.0649 - val_loss: 0.0249\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0375 - val_loss: 0.0256\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0340 - val_loss: 0.0241\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0364 - val_loss: 0.0234\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0344 - val_loss: 0.0259\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0337 - val_loss: 0.0237\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0365 - val_loss: 0.0227\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0336 - val_loss: 0.0214\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0296 - val_loss: 0.0216\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0316 - val_loss: 0.0199\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0299 - val_loss: 0.0227\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0298 - val_loss: 0.0177\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0273 - val_loss: 0.0175\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0242 - val_loss: 0.0153\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0219 - val_loss: 0.0140\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0211 - val_loss: 0.0141\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0188 - val_loss: 0.0136\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0180 - val_loss: 0.0122\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0174 - val_loss: 0.0111\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0153 - val_loss: 0.0105\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0160 - val_loss: 0.0098\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0159 - val_loss: 0.0100\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0098\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0090\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0150 - val_loss: 0.0090\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0137 - val_loss: 0.0083\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0132 - val_loss: 0.0082\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0143 - val_loss: 0.0078\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0127 - val_loss: 0.0091\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0125 - val_loss: 0.0076\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0130 - val_loss: 0.0083\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0136 - val_loss: 0.0084\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0136 - val_loss: 0.0078\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0129 - val_loss: 0.0072\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0075\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0123 - val_loss: 0.0073\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0121 - val_loss: 0.0070\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0070\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0069\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0068\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0067\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0100 - val_loss: 0.0073\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0067\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0083\n",
      "evolution of the gridsearch: step  75\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 95s 408ms/step - loss: 0.0766 - val_loss: 0.0262\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0375 - val_loss: 0.0249\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0356 - val_loss: 0.0245\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0362 - val_loss: 0.0244\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0356 - val_loss: 0.0232\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0356 - val_loss: 0.0235\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0346 - val_loss: 0.0235\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0344 - val_loss: 0.0220\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0336 - val_loss: 0.0219\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0333 - val_loss: 0.0218\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0291 - val_loss: 0.0227\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0314 - val_loss: 0.0197\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0299 - val_loss: 0.0190\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0288 - val_loss: 0.0182\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0286 - val_loss: 0.0180\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0253 - val_loss: 0.0160\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0250 - val_loss: 0.0153\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0245 - val_loss: 0.0136\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0205 - val_loss: 0.0128\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0186 - val_loss: 0.0116\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0178 - val_loss: 0.0113\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0195 - val_loss: 0.0106\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0177 - val_loss: 0.0110\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0157 - val_loss: 0.0093\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0157 - val_loss: 0.0086\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0150 - val_loss: 0.0085\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0141 - val_loss: 0.0092\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0140 - val_loss: 0.0084\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0143 - val_loss: 0.0090\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0137 - val_loss: 0.0081\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0126 - val_loss: 0.0080\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0128 - val_loss: 0.0079\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0139 - val_loss: 0.0088\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0125 - val_loss: 0.0074\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0131 - val_loss: 0.0076\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0121 - val_loss: 0.0074\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0125 - val_loss: 0.0078\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0121 - val_loss: 0.0073\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0126 - val_loss: 0.0082\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0123 - val_loss: 0.0075\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0073\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0132 - val_loss: 0.0069\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0085\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0123 - val_loss: 0.0072\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0075\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0132 - val_loss: 0.0073\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0103 - val_loss: 0.0070\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0115 - val_loss: 0.0068\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0099 - val_loss: 0.0068\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0136 - val_loss: 0.0067\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0124 - val_loss: 0.0085\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0101 - val_loss: 0.0089\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0103 - val_loss: 0.0064\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0065\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0100 - val_loss: 0.0066\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0113 - val_loss: 0.0068\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0073\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0066\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0097 - val_loss: 0.0063\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0101 - val_loss: 0.0062\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0062\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0099 - val_loss: 0.0062\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0098 - val_loss: 0.0062\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0100 - val_loss: 0.0063\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0103 - val_loss: 0.0062\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0063\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0061\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0063\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0099 - val_loss: 0.0061\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0087 - val_loss: 0.0062\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0092 - val_loss: 0.0063\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0063\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0079 - val_loss: 0.0063\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 2s 8ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 2s 7ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "evolution of the gridsearch: step  76\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 100s 432ms/step - loss: 0.0843 - val_loss: 0.0355\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0419 - val_loss: 0.0268\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0381 - val_loss: 0.0245\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0377 - val_loss: 0.0242\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0359 - val_loss: 0.0246\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0368 - val_loss: 0.0240\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0366 - val_loss: 0.0241\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0349 - val_loss: 0.0241\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0342 - val_loss: 0.0240\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0350 - val_loss: 0.0244\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0343 - val_loss: 0.0237\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0336 - val_loss: 0.0234\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0337 - val_loss: 0.0231\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0327 - val_loss: 0.0229\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0349 - val_loss: 0.0228\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0332 - val_loss: 0.0225\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0328 - val_loss: 0.0221\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0308 - val_loss: 0.0213\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0319 - val_loss: 0.0206\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0305 - val_loss: 0.0200\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0315 - val_loss: 0.0195\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0305 - val_loss: 0.0189\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0305 - val_loss: 0.0183\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0287 - val_loss: 0.0183\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0278 - val_loss: 0.0174\n",
      "evolution of the gridsearch: step  77\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 101s 434ms/step - loss: 0.0818 - val_loss: 0.0370\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0421 - val_loss: 0.0282\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0391 - val_loss: 0.0239\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0360 - val_loss: 0.0236\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0343 - val_loss: 0.0236\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0333 - val_loss: 0.0235\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0235\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0348 - val_loss: 0.0233\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0332 - val_loss: 0.0233\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0339 - val_loss: 0.0233\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0317 - val_loss: 0.0231\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0328 - val_loss: 0.0224\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0328 - val_loss: 0.0220\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0327 - val_loss: 0.0216\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0321 - val_loss: 0.0214\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0303 - val_loss: 0.0203\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0303 - val_loss: 0.0200\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0298 - val_loss: 0.0195\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0291 - val_loss: 0.0196\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0283 - val_loss: 0.0182\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0282 - val_loss: 0.0177\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0169\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0159\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0234 - val_loss: 0.0151\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0234 - val_loss: 0.0143\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0218 - val_loss: 0.0139\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0218 - val_loss: 0.0132\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0198 - val_loss: 0.0131\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0194 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0199 - val_loss: 0.0149\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0181 - val_loss: 0.0118\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0196 - val_loss: 0.0130\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0183 - val_loss: 0.0110\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0178 - val_loss: 0.0111\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0112\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0189 - val_loss: 0.0102\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0117\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0153 - val_loss: 0.0102\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0166 - val_loss: 0.0100\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0164 - val_loss: 0.0097\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0178 - val_loss: 0.0097\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0170 - val_loss: 0.0101\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0092\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0149 - val_loss: 0.0086\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0144 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0152 - val_loss: 0.0088\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0135 - val_loss: 0.0086\n",
      "evolution of the gridsearch: step  78\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 95s 410ms/step - loss: 0.0859 - val_loss: 0.0334\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0472 - val_loss: 0.0280\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0434 - val_loss: 0.0253\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0360 - val_loss: 0.0251\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0358 - val_loss: 0.0240\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0239\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0239\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0353 - val_loss: 0.0239\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0343 - val_loss: 0.0244\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0238\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0349 - val_loss: 0.0236\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0363 - val_loss: 0.0233\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0331 - val_loss: 0.0223\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0223\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0330 - val_loss: 0.0235\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0351 - val_loss: 0.0216\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0314 - val_loss: 0.0209\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0318 - val_loss: 0.0203\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0314 - val_loss: 0.0198\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0297 - val_loss: 0.0193\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0292 - val_loss: 0.0192\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0300 - val_loss: 0.0181\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0269 - val_loss: 0.0174\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0255 - val_loss: 0.0166\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0250 - val_loss: 0.0167\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0256 - val_loss: 0.0151\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0245 - val_loss: 0.0144\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0237 - val_loss: 0.0148\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0221 - val_loss: 0.0140\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0203 - val_loss: 0.0130\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0204 - val_loss: 0.0128\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0183 - val_loss: 0.0119\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0193 - val_loss: 0.0129\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0181 - val_loss: 0.0116\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0113\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0172 - val_loss: 0.0107\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0186 - val_loss: 0.0104\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0163 - val_loss: 0.0101\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0156 - val_loss: 0.0098\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0167 - val_loss: 0.0097\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0148 - val_loss: 0.0089\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0089\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.0089\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0087\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0141 - val_loss: 0.0088\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0086\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0086\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0084\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0138 - val_loss: 0.0084\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0080\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0131 - val_loss: 0.0079\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0121 - val_loss: 0.0079\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0107 - val_loss: 0.0078\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0083\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0077\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0074\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0135 - val_loss: 0.0079\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0119 - val_loss: 0.0075\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0104 - val_loss: 0.0075\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0072\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0075\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0075\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0072\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0072\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0123 - val_loss: 0.0070\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0081\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0156 - val_loss: 0.0078\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0083\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0105 - val_loss: 0.0086\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0072\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0070\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0108 - val_loss: 0.0074\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0067\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0070\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0068\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0067\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0106 - val_loss: 0.0067\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0065\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0069\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0067\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 0.0110 - val_loss: 0.0065\n",
      "evolution of the gridsearch: step  79\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/25\n",
      "232/232 [==============================] - 96s 413ms/step - loss: 0.1138 - val_loss: 0.0358\n",
      "Epoch 2/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0493 - val_loss: 0.0275\n",
      "Epoch 3/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0368 - val_loss: 0.0266\n",
      "Epoch 4/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0381 - val_loss: 0.0240\n",
      "Epoch 5/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0366 - val_loss: 0.0243\n",
      "Epoch 6/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0359 - val_loss: 0.0242\n",
      "Epoch 7/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0352 - val_loss: 0.0236\n",
      "Epoch 8/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0346 - val_loss: 0.0235\n",
      "Epoch 9/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0355 - val_loss: 0.0235\n",
      "Epoch 10/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0240\n",
      "Epoch 11/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0336 - val_loss: 0.0232\n",
      "Epoch 12/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0334 - val_loss: 0.0230\n",
      "Epoch 13/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0325 - val_loss: 0.0228\n",
      "Epoch 14/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0223\n",
      "Epoch 15/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0325 - val_loss: 0.0220\n",
      "Epoch 16/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0218\n",
      "Epoch 17/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0213\n",
      "Epoch 18/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0321 - val_loss: 0.0210\n",
      "Epoch 19/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0310 - val_loss: 0.0207\n",
      "Epoch 20/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0304 - val_loss: 0.0204\n",
      "Epoch 21/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0196\n",
      "Epoch 22/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0274 - val_loss: 0.0194\n",
      "Epoch 23/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0279 - val_loss: 0.0187\n",
      "Epoch 24/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0257 - val_loss: 0.0178\n",
      "Epoch 25/25\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0288 - val_loss: 0.0171\n",
      "evolution of the gridsearch: step  80\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 97s 419ms/step - loss: 0.0809 - val_loss: 0.0267\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0450 - val_loss: 0.0255\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0397 - val_loss: 0.0279\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0377 - val_loss: 0.0241\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0369 - val_loss: 0.0247\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0353 - val_loss: 0.0246\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0335 - val_loss: 0.0236\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0350 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0340 - val_loss: 0.0240\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0233\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0232\n",
      "Epoch 12/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0331 - val_loss: 0.0236\n",
      "Epoch 13/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0347 - val_loss: 0.0229\n",
      "Epoch 14/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0331 - val_loss: 0.0227\n",
      "Epoch 15/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0327 - val_loss: 0.0225\n",
      "Epoch 16/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0314 - val_loss: 0.0219\n",
      "Epoch 17/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0307 - val_loss: 0.0217\n",
      "Epoch 18/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0315 - val_loss: 0.0219\n",
      "Epoch 19/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0290 - val_loss: 0.0209\n",
      "Epoch 20/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0321 - val_loss: 0.0202\n",
      "Epoch 21/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0301 - val_loss: 0.0196\n",
      "Epoch 22/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0285 - val_loss: 0.0193\n",
      "Epoch 23/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0280 - val_loss: 0.0182\n",
      "Epoch 24/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0251 - val_loss: 0.0175\n",
      "Epoch 25/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0279 - val_loss: 0.0167\n",
      "Epoch 26/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0248 - val_loss: 0.0161\n",
      "Epoch 27/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0220 - val_loss: 0.0154\n",
      "Epoch 28/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0229 - val_loss: 0.0148\n",
      "Epoch 29/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0207 - val_loss: 0.0146\n",
      "Epoch 30/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0200 - val_loss: 0.0137\n",
      "Epoch 31/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0235 - val_loss: 0.0140\n",
      "Epoch 32/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0191 - val_loss: 0.0128\n",
      "Epoch 33/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 34/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0188 - val_loss: 0.0130\n",
      "Epoch 35/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0193 - val_loss: 0.0122\n",
      "Epoch 36/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0165 - val_loss: 0.0117\n",
      "Epoch 37/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0154 - val_loss: 0.0112\n",
      "Epoch 38/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0161 - val_loss: 0.0108\n",
      "Epoch 39/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0168 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 41/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0099\n",
      "Epoch 42/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 43/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0103\n",
      "Epoch 44/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0160 - val_loss: 0.0090\n",
      "Epoch 45/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 46/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0086\n",
      "Epoch 47/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0127 - val_loss: 0.0090\n",
      "Epoch 48/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0083\n",
      "Epoch 50/50\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0085\n",
      "evolution of the gridsearch: step  81\n",
      "Train on 232 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "232/232 [==============================] - 98s 422ms/step - loss: 0.1190 - val_loss: 0.0367\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0490 - val_loss: 0.0319\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0415 - val_loss: 0.0285\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0404 - val_loss: 0.0262\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0374 - val_loss: 0.0247\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0387 - val_loss: 0.0241\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0363 - val_loss: 0.0252\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0372 - val_loss: 0.0243\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0359 - val_loss: 0.0235\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0233\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0327 - val_loss: 0.0233\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0236\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0231\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0345 - val_loss: 0.0229\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0339 - val_loss: 0.0237\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0322 - val_loss: 0.0224\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 1s 3ms/step - loss: 0.0328 - val_loss: 0.0222\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0327 - val_loss: 0.0219\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0316 - val_loss: 0.0216\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0298 - val_loss: 0.0213\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0312 - val_loss: 0.0210\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0328 - val_loss: 0.0211\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0201\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0308 - val_loss: 0.0195\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0296 - val_loss: 0.0191\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0295 - val_loss: 0.0185\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0279 - val_loss: 0.0179\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0268 - val_loss: 0.0172\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0267 - val_loss: 0.0168\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0240 - val_loss: 0.0159\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0233 - val_loss: 0.0152\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0221 - val_loss: 0.0148\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0199 - val_loss: 0.0138\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0203 - val_loss: 0.0137\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0182 - val_loss: 0.0133\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0195 - val_loss: 0.0132\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0199 - val_loss: 0.0123\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0173 - val_loss: 0.0118\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0166 - val_loss: 0.0109\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0174 - val_loss: 0.0112\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0169 - val_loss: 0.0104\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0176 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0153 - val_loss: 0.0100\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0147 - val_loss: 0.0100\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0155 - val_loss: 0.0090\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0145 - val_loss: 0.0092\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0088\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0087\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0136 - val_loss: 0.0090\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0137 - val_loss: 0.0085\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0087\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0140 - val_loss: 0.0082\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0131 - val_loss: 0.0086\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0081\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0135 - val_loss: 0.0082\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0125 - val_loss: 0.0079\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0080\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0078\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0077\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0130 - val_loss: 0.0080\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0074\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0121 - val_loss: 0.0078\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0073\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 75/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 76/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 77/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0132 - val_loss: 0.0075\n",
      "Epoch 78/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0081\n",
      "Epoch 79/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0122 - val_loss: 0.0072\n",
      "Epoch 80/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0072\n",
      "Epoch 81/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 82/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0073\n",
      "Epoch 83/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0073\n",
      "Epoch 84/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0119 - val_loss: 0.0070\n",
      "Epoch 85/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 86/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 87/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 88/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0068\n",
      "Epoch 89/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 90/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0067\n",
      "Epoch 91/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 92/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0098 - val_loss: 0.0067\n",
      "Epoch 93/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 94/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 95/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0067\n",
      "Epoch 96/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0073\n",
      "Epoch 97/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0066\n",
      "Epoch 98/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0070\n",
      "Epoch 99/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 100/100\n",
      "232/232 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0068\n"
     ]
    }
   ],
   "source": [
    "#Building the RNN\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import pandas as pd\n",
    "\n",
    "#initialising the RNN\n",
    "\n",
    "def model(dropout_prop=0.2,nb_units=50,batchsize=32,epoch=100,optimizer='adam',X_train=X_train,Y_train=Y_train):\n",
    "  regressor= Sequential()\n",
    "\n",
    "  #adding the first LSTM layer and some dropout regularization\n",
    "  regressor.add(LSTM(units=nb_units, return_sequences = True , input_shape=(X_train.shape[1],1)))\n",
    "  regressor.add(Dropout(dropout_prop))\n",
    "\n",
    "  #adding a third LSTM layer and some Dropout regularisation\n",
    "  regressor.add(LSTM(units=nb_units, return_sequences = True ))\n",
    "  regressor.add(Dropout(dropout_prop))\n",
    "\n",
    "  #adding a fourth LSTM layer and some Dropout regularisation\n",
    "  regressor.add(LSTM(units=nb_units ))\n",
    "  regressor.add(Dropout(dropout_prop))\n",
    "\n",
    "  #adding the output layer\n",
    "  regressor.add(Dense(units=1))\n",
    "  #Compiling the RNN\n",
    "\n",
    "  regressor.compile(optimizer= optimizer, loss= 'mean_squared_error')\n",
    "\n",
    "\n",
    "  #Fitting the RNN to the training set\n",
    "  history=regressor.fit(X_train, Y_train,validation_split=0.20, epochs=epoch, batch_size=batchsize)\n",
    "\n",
    "  return regressor\n",
    "\n",
    "#evaluation error\n",
    "\n",
    "def evaluate_error(model,X_test=X_test,Y_test=Y_test):\n",
    "  predicted_birth=model.predict(X_test)\n",
    "  predicted_birth=sc.inverse_transform(predicted_birth)\n",
    "  Y_test=sc.inverse_transform(np.array(Y_test).reshape(-1,1))\n",
    "  errors = abs(predicted_birth - Y_test)\n",
    "  MAE=round(np.mean(errors), 2)\n",
    "  rmse =np.sqrt(mean_squared_error(Y_test,predicted_birth))\n",
    "  mape = 100 * (errors / Y_test)\n",
    "  MAPE=round(np.mean(mape), 2)\n",
    "  return rmse\n",
    "\n",
    "\n",
    "\n",
    "def Grid_Search(X_train=X_train,Y_train=Y_train, X_test=X_test,Y_test=Y_test):\n",
    "  Result=pd.DataFrame(columns=['units','dropout_prob','batch_size','optimizer','epochs''RMSE'])\n",
    "  units_matrix=[]\n",
    "  dropout_prob_matrix=[]\n",
    "  batch_size_matrix=[]\n",
    "  optimizer_matrix=[]\n",
    "  epochs_matrix=[]\n",
    "  #MAE_matrix=[]\n",
    "  rmse_matrix=[]\n",
    "  #MAPE_matrix=[]\n",
    "\n",
    "  units =[10,30, 50]\n",
    "  dropout_rate = [0.0,0.1, 0.2]\n",
    "  batch_size = [16, 32,42]\n",
    "  epochs = [25,50, 100]\n",
    "  optimizer = ['Adam']\n",
    "  count=1\n",
    "  for u in units:\n",
    "    for d in dropout_rate:\n",
    "      for b in batch_size:\n",
    "        for o in optimizer:\n",
    "          for e in epochs:\n",
    "            print('evolution of the gridsearch: step ',count)\n",
    "            model_regressor=model(dropout_prop=d,nb_units=u,batchsize=b,epoch=e,optimizer=o,X_train=X_train,Y_train=Y_train)\n",
    "            rmse=evaluate_error(model=model_regressor,X_test=X_test,Y_test=Y_test)\n",
    "\n",
    "            units_matrix.append(u)\n",
    "            dropout_prob_matrix.append(d)\n",
    "            batch_size_matrix.append(b)\n",
    "            optimizer_matrix.append(o)\n",
    "            epochs_matrix.append(e)\n",
    "            #MAE_matrix.append(MAE)\n",
    "            rmse_matrix.append(rmse)\n",
    "            #MAPE_matrix.append(MAPE)\n",
    "            count+=1\n",
    "\n",
    "          \n",
    "  Result['units']= units_matrix\n",
    "  Result['dropout_prob']=dropout_prob_matrix\n",
    "  Result['batch_size']=batch_size_matrix\n",
    "  Result['optimizer']=optimizer_matrix\n",
    "  Result['epochs']=epochs_matrix\n",
    "  #Result['MAE']=MAE_matrix\n",
    "  Result['RMSE']=rmse_matrix\n",
    "  #Result['MAPE']=MAPE_matrix\n",
    "  return Result\n",
    "\n",
    "Final_Result=Grid_Search(X_train=X_train,Y_train=Y_train, X_test=X_test,Y_test=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "re1rYNFUCO5w",
    "outputId": "8b9c9a37-6f79-48b5-bec4-0cde513f2650"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_prob</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>epochsRMSE</th>\n",
       "      <th>epochs</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.217429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.771877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.589180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.471216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1.328195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.642518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.477869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1.164084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.910721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.292935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.847705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.729217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.381961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1.271639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.808039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.497015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1.284638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1.169267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.365696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.968760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.792857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.512222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1.278319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1.127907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.517889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1.316531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1.008443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.816700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.698444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.743128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.218568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.692996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.624193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.277752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.824284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.608323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.925205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.728865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.668641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.258672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.816885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.691734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.246633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.776044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.663761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.015079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.780980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.640953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.347973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.853182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.764316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.314789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.980840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>30</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.725135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.735506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.672963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.710922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.981601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.689134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.642407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.101934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.665120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.621675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.758449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.689664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.606761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.094562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.708437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.642412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.100113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.724155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.656240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.818294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.734722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.626039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.151496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.801149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.654394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>1.174820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.797998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Adam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.652079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    units  dropout_prob  batch_size optimizer epochsRMSE  epochs      RMSE\n",
       "0      10           0.0          16      Adam        NaN      25  1.217429\n",
       "1      10           0.0          16      Adam        NaN      50  0.771877\n",
       "2      10           0.0          16      Adam        NaN     100  0.589180\n",
       "3      10           0.0          32      Adam        NaN      25  1.471216\n",
       "4      10           0.0          32      Adam        NaN      50  1.328195\n",
       "5      10           0.0          32      Adam        NaN     100  0.642518\n",
       "6      10           0.0          42      Adam        NaN      25  1.477869\n",
       "7      10           0.0          42      Adam        NaN      50  1.164084\n",
       "8      10           0.0          42      Adam        NaN     100  0.910721\n",
       "9      10           0.1          16      Adam        NaN      25  1.292935\n",
       "10     10           0.1          16      Adam        NaN      50  0.847705\n",
       "11     10           0.1          16      Adam        NaN     100  0.729217\n",
       "12     10           0.1          32      Adam        NaN      25  1.381961\n",
       "13     10           0.1          32      Adam        NaN      50  1.271639\n",
       "14     10           0.1          32      Adam        NaN     100  0.808039\n",
       "15     10           0.1          42      Adam        NaN      25  1.497015\n",
       "16     10           0.1          42      Adam        NaN      50  1.284638\n",
       "17     10           0.1          42      Adam        NaN     100  1.169267\n",
       "18     10           0.2          16      Adam        NaN      25  1.365696\n",
       "19     10           0.2          16      Adam        NaN      50  0.968760\n",
       "20     10           0.2          16      Adam        NaN     100  0.792857\n",
       "21     10           0.2          32      Adam        NaN      25  1.512222\n",
       "22     10           0.2          32      Adam        NaN      50  1.278319\n",
       "23     10           0.2          32      Adam        NaN     100  1.127907\n",
       "24     10           0.2          42      Adam        NaN      25  1.517889\n",
       "25     10           0.2          42      Adam        NaN      50  1.316531\n",
       "26     10           0.2          42      Adam        NaN     100  1.008443\n",
       "27     30           0.0          16      Adam        NaN      25  0.816700\n",
       "28     30           0.0          16      Adam        NaN      50  0.698444\n",
       "29     30           0.0          16      Adam        NaN     100  0.743128\n",
       "30     30           0.0          32      Adam        NaN      25  1.218568\n",
       "31     30           0.0          32      Adam        NaN      50  0.692996\n",
       "32     30           0.0          32      Adam        NaN     100  0.624193\n",
       "33     30           0.0          42      Adam        NaN      25  1.277752\n",
       "34     30           0.0          42      Adam        NaN      50  0.824284\n",
       "35     30           0.0          42      Adam        NaN     100  0.608323\n",
       "36     30           0.1          16      Adam        NaN      25  0.925205\n",
       "37     30           0.1          16      Adam        NaN      50  0.728865\n",
       "38     30           0.1          16      Adam        NaN     100  0.668641\n",
       "39     30           0.1          32      Adam        NaN      25  1.258672\n",
       "40     30           0.1          32      Adam        NaN      50  0.816885\n",
       "41     30           0.1          32      Adam        NaN     100  0.691734\n",
       "42     30           0.1          42      Adam        NaN      25  1.246633\n",
       "43     30           0.1          42      Adam        NaN      50  0.776044\n",
       "44     30           0.1          42      Adam        NaN     100  0.663761\n",
       "45     30           0.2          16      Adam        NaN      25  1.015079\n",
       "46     30           0.2          16      Adam        NaN      50  0.780980\n",
       "47     30           0.2          16      Adam        NaN     100  0.640953\n",
       "48     30           0.2          32      Adam        NaN      25  1.347973\n",
       "49     30           0.2          32      Adam        NaN      50  0.853182\n",
       "50     30           0.2          32      Adam        NaN     100  0.764316\n",
       "51     30           0.2          42      Adam        NaN      25  1.314789\n",
       "52     30           0.2          42      Adam        NaN      50  0.980840\n",
       "53     30           0.2          42      Adam        NaN     100  0.725135\n",
       "54     50           0.0          16      Adam        NaN      25  0.735506\n",
       "55     50           0.0          16      Adam        NaN      50  0.672963\n",
       "56     50           0.0          16      Adam        NaN     100  0.710922\n",
       "57     50           0.0          32      Adam        NaN      25  0.981601\n",
       "58     50           0.0          32      Adam        NaN      50  0.689134\n",
       "59     50           0.0          32      Adam        NaN     100  0.642407\n",
       "60     50           0.0          42      Adam        NaN      25  1.101934\n",
       "61     50           0.0          42      Adam        NaN      50  0.665120\n",
       "62     50           0.0          42      Adam        NaN     100  0.621675\n",
       "63     50           0.1          16      Adam        NaN      25  0.758449\n",
       "64     50           0.1          16      Adam        NaN      50  0.689664\n",
       "65     50           0.1          16      Adam        NaN     100  0.606761\n",
       "66     50           0.1          32      Adam        NaN      25  1.094562\n",
       "67     50           0.1          32      Adam        NaN      50  0.708437\n",
       "68     50           0.1          32      Adam        NaN     100  0.642412\n",
       "69     50           0.1          42      Adam        NaN      25  1.100113\n",
       "70     50           0.1          42      Adam        NaN      50  0.724155\n",
       "71     50           0.1          42      Adam        NaN     100  0.656240\n",
       "72     50           0.2          16      Adam        NaN      25  0.818294\n",
       "73     50           0.2          16      Adam        NaN      50  0.734722\n",
       "74     50           0.2          16      Adam        NaN     100  0.626039\n",
       "75     50           0.2          32      Adam        NaN      25  1.151496\n",
       "76     50           0.2          32      Adam        NaN      50  0.801149\n",
       "77     50           0.2          32      Adam        NaN     100  0.654394\n",
       "78     50           0.2          42      Adam        NaN      25  1.174820\n",
       "79     50           0.2          42      Adam        NaN      50  0.797998\n",
       "80     50           0.2          42      Adam        NaN     100  0.652079"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "Final_Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GlNzGzhhlOS"
   },
   "source": [
    "The best model is the one with the smallest error RMSE=0.583306 His hyperparameters are:\n",
    "Units=10, dropout=0.0, batch_size=16 and epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEK5-VM0AP77"
   },
   "outputs": [],
   "source": [
    "#Building the RNN\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#initialising the RNN\n",
    "regressor= Sequential()\n",
    "\n",
    "#adding the first LSTM layer and some dropout regularization\n",
    "regressor.add(LSTM(units=10, return_sequences = True , input_shape=(X_train.shape[1],1)))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "#adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units=10, return_sequences = True ))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "#adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units=10 ))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "#adding the output layer\n",
    "regressor.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6uSJrk_0w2BF",
    "outputId": "a3abb979-924c-4399-a0be-263a7a51056a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "#Compiling the RNN\n",
    "import keras\n",
    "keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "regressor.compile(optimizer= 'adam', loss= 'mean_squared_error')\n",
    "\n",
    "#Fitting the RNN to the training set\n",
    "history=regressor.fit(X_train, Y_train, validation_split=0.30, epochs=100, batch_size=16, verbose=0)\n",
    "history.history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "HVcAZqjbw2qy",
    "outputId": "abaaee87-46de-4346-8ed0-a76573c67b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_490 (LSTM)              (None, 48, 10)            480       \n",
      "_________________________________________________________________\n",
      "lstm_491 (LSTM)              (None, 48, 10)            840       \n",
      "_________________________________________________________________\n",
      "lstm_492 (LSTM)              (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,171\n",
      "Trainable params: 2,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_No3nKrSxZBY"
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "X_test=np.array(X_test)\n",
    "X_test_shape=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "predicted_birth=regressor.predict(X_test_shape)\n",
    "predicted_birth=sc.inverse_transform(predicted_birth)\n",
    "Y_test=sc.inverse_transform(np.array(Y_test).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "4NLTegJ1xZ2d",
    "outputId": "b5abe350-c273-41fa-864c-2ed09b6560c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAFQCAYAAADdi1hxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOy9d5hjZ3n3/3nUpRlN29lu4133dWNt\nrxcCoTgOYEogVJuE+hIgvJRwJXnfQC5CnAQnwA9MSYC8cWiBgHFMc4IDoZiOwTa4rPvau+vtM7M7\nM9Kol+f3x3PO0ZF01KapzP25rrkknSNpHkkzOt/zvZvSWiMIgiAIgiAMBr5uL0AQBEEQBEFYPkTc\nCYIgCIIgDBAi7gRBEARBEAYIEXeCIAiCIAgDhIg7QRAEQRCEAULEnSAIgiAIwgAh4k4QBGGRKKW2\nKaW0UirQxn1fp5T66VKfRxAEoRUi7gRBWBMopfYrpfJKqcma7b+xhNW27qxMEARheRFxJwjCWmIf\n8Er7hlLqQiDWveUIgiAsPyLuBEFYS3wBeI3r9muBf3PfQSk1qpT6N6XUtFLqgFLqPUopn7XPr5T6\nkFJqRin1GPB8j8d+Wil1VCl1WCn1PqWUv9NFKqW2KKVuVkqdVErtVUq90bVvt1LqDqVUQil1XCl1\nnbU9opT6olLqhFJqTil1u1JqY6e/WxCE/kfEnSAIa4nbgBGl1A5LdF0NfLHmPv8IjAKnA8/AiMHX\nW/veCLwAuBjYBbys5rGfA4rAmdZ9ng380SLWeQNwCNhi/Y6/V0r9jrXvY8DHtNYjwBnAjdb211rr\nPhVYB/wxkFnE7xYEoc8RcScIwlrDdu+eBTwAHLZ3uATfu7XWSa31fuDDwKutu7wC+KjW+qDW+iTw\nD67HbgSeB7xTa53SWk8BH7Ger22UUqcCTwX+Qmud1VrfBfwrFcexAJyplJrUWi9orW9zbV8HnKm1\nLmmt79RaJzr53YIgDAYi7gRBWGt8AfgD4HXUhGSBSSAIHHBtOwBsta5vAQ7W7LM5zXrsUSssOgf8\nP2BDh+vbApzUWicbrOENwNnAg1bo9QWu1/Ud4Aal1BGl1AeVUsEOf7cgCAOAiDtBENYUWusDmMKK\n5wFfq9k9g3HATnNtewIVd+8oJuzp3mdzEMgBk1rrMetnRGt9fodLPAJMKKXiXmvQWj+itX4lRjR+\nALhJKTWktS5orf9Ga30e8BRM+Pg1CIKw5hBxJwjCWuQNwO9orVPujVrrEiaH7VqlVFwpdRrwp1Ty\n8m4E3qGUOkUpNQ68y/XYo8D/AB9WSo0opXxKqTOUUs/oZGFa64PAz4F/sIokLrLW+0UApdSrlFLr\ntdZlYM56WFkpdblS6kIrtJzAiNRyJ79bEITBQMSdIAhrDq31o1rrOxrsfjuQAh4Dfgp8CfiMte96\nTOjzbuDX1Dt/rwFCwP3ALHATsHkRS3wlsA3j4n0d+Gut9fesfVcC9ymlFjDFFVdrrTPAJuv3JTC5\nhD/ChGoFQVhjKK11t9cgCIIgCIIgLBPi3AmCIAiCIAwQIu4EQRAEQRAGCBF3giAIgiAIA4SIO0EQ\nBEEQhAFCxJ2FUurb3V6DIAiCIAhCOzTTLYHVXEgvMzIy8pxdu3ZJ6bAgCIIgCP1Aw/GCIu4szjrr\nLO64o1HbK0EQBEEQhN5BKfVIo30SlhUEQRAEQRggRNwJgiAIgiAMEBKWbUGxWKRclvGMy4HP5yMQ\nkD85QRAEQVhJxLlrQjKZJJ/Pd3sZA0M+nyeZTHZ7GYIgCIIw0IiN0oBisYjf7ycWi3V7KQNDKBQi\nnU5TLBbFwRMEQRCEFUKcuwaUy2URICuA3++XMLcgCIIgrCAi7oRVRSnV7SUIgiAIwkAj4q7HmZub\n45Of/GTHj3ve857H3NzcCqxIEARBEIReRsRdj9NI3BWLxaaPu+WWWxgbG1upZQnLhdbmRxAEQRCW\nCUkq63He9a538eijj7Jz506CwSCRSITx8XEefPBBHn74YX7/93+fgwcPks1m+ZM/+RPe9KY3AbBt\n2zbuuOMOFhYWeO5zn8tv//Zv8/Of/5ytW7fyzW9+k2g02uVXJgDw9TdD+gS86qvdXokgCIIwIIi4\na5OXfernHJ3PLutzbh6NcNNbntL0Pu9///vZs2cPd911Fz/84Q95/vOfz549e9i+fTsAn/nMZ5iY\nmCCTyXDZZZfx0pe+lHXr1lU9xyOPPMKXv/xlrr/+el7xilfw1a9+lVe96lXL+lqERXLwl5A60e1V\nCIIgCAOEiLs+Y/fu3Y6wA/j4xz/O17/+dQAOHjzII488Uifutm/fzs6dOwG49NJL2b9//6qtV2hB\nPg35JJRL4PN3ezWCIAjCACDirk1aOWyrxdDQkHP9hz/8Id/73vf4xS9+QSwW45nPfCbZbL27GA6H\nnet+v59MJrMqaxXaoGB9FvkFiIx2dy2CIAjCQCAFFT1OPB5vONVhfn6e8fFxYrEYDz74ILfddtsq\nr05YElpDIW2u52RyhyAIgrA8iHPX46xbt46nPvWpXHDBBUSjUTZu3Ojsu/LKK/nnf/5nduzYwTnn\nnMOTn/zkLq5U6JhSAXTJXBdxJwiCICwTSksbBgB27dql77jjDue2PVM2FAp1a0kDibyvLjJz8IHT\nzPU3fBdO3d3d9QiCIAh9g1LqTq31Lq99EpYVhG5RcOU+5hLdW4cgCIIwUIi4E4RuYefbgYRlBUEQ\nhGVDxJ0gdIsq507EnSAIgrA8iLgThG7hFndZCcsKgiAIy4OIO0HoFhKWFQRBEFYAEXeC0C1E3AmC\nIAgrgIi7AWN4eBiAI0eO8LKXvczzPs985jNxt33x4qMf/SjpdEV8PO95z2Nubm75FirUiDsJywqC\nIAjLg4i7AWXLli3cdNNNi358rbi75ZZbGBsbW46lCTZSUCEIgiCsACLuepx3vetdfOITn3BuX3PN\nNbzvfe/jiiuu4JJLLuHCCy/km9/8Zt3j9u/fzwUXXABAJpPh6quvZseOHbz4xS+umi37lre8hV27\ndnH++efz13/91wB8/OMf58iRI1x++eVcfvnlAGzbto2ZmRkArrvuOi644AIuuOACPvrRjzq/b8eO\nHbzxjW/k/PPP59nPfrbMsG2FiDtBEARhBZDxY+3y6edA4sjyPufIFnjDd5re5aqrruKd73wnb33r\nWwG48cYb+c53vsM73vEORkZGmJmZ4clPfjIvfOELUUp5PsenPvUpYrEYDzzwAPfccw+XXHKJs+/a\na69lYmKCUqnEFVdcwT333MM73vEOrrvuOm699VYmJyernuvOO+/ks5/9LL/85S/RWvOkJz2JZzzj\nGYyPj/PII4/w5S9/meuvv55XvOIVfPWrX+VVr3rVEt+kAUZy7gRBEIQVQJy7Hufiiy9mamqKI0eO\ncPfddzM+Ps6mTZv4y7/8Sy666CJ+93d/l8OHD3P8+PGGz/HjH//YEVkXXXQRF110kbPvxhtv5JJL\nLuHiiy/mvvvu4/7772+6np/+9Ke8+MUvZmhoiOHhYV7ykpfwk5/8BIDt27ezc+dOAC699FL279+/\nxFc/4MiECkEQBGEFEOeuXVo4bCvJy1/+cm666SaOHTvGVVddxb//+78zPT3NnXfeSTAYZNu2bWSz\n2Y6fd9++fXzoQx/i9ttvZ3x8nNe97nWLeh6bcDjsXPf7/RKWbYU4d4IgCMIKIM5dH3DVVVdxww03\ncNNNN/Hyl7+c+fl5NmzYQDAY5NZbb+XAgQNNH//0pz+dL33pSwDs2bOHe+65B4BEIsHQ0BCjo6Mc\nP36c//7v/3YeE4/HSSbrBcfTnvY0vvGNb5BOp0mlUnz961/naU972jK+2jWE7dwpv4g7QRAEYdkQ\n564POP/880kmk2zdupXNmzfzh3/4h/ze7/0eF154Ibt27eLcc89t+vi3vOUtvP71r2fHjh3s2LGD\nSy+9FIAnPvGJXHzxxZx77rmceuqpPPWpT3Ue86Y3vYkrr7ySLVu2cOuttzrbL7nkEl73utexe/du\nAP7oj/6Iiy++WEKwi8F27oY3QPIYlMvgk/MtQRAEYWkorXW319AT7Nq1S7t7v+XzeQBCoVC3ljSQ\nyPvq4qb/BXu+Cpt3wtG74N2HIBzv9qoEQRCEPkApdafWepfXvhW1CZRSVyqlHlJK7VVKvctjf1gp\n9RVr/y+VUttc+95tbX9IKfUca9s5Sqm7XD8JpdQ7rX3XKKUOu/Y9byVfmyAsmbzt3G00lxKaFQRB\nEJaBFQvLKqX8wCeAZwGHgNuVUjdrrd3lmG8AZrXWZyqlrgY+AFyllDoPuBo4H9gCfE8pdbbW+iFg\np+v5DwNfdz3fR7TWH1qp1yQIy4o7LAsi7nqMTL5ENOTv9jIEQRA6ZiWdu93AXq31Y1rrPHAD8KKa\n+7wI+Lx1/SbgCmWatb0IuEFrndNa7wP2Ws/n5grgUa1182oCoaeQNAAXhQz4AhCbMLez0g6lF/jN\n47P84b/exo73fptfPHqi28sRBEHomJUUd1uBg67bh6xtnvfRWheBeWBdm4+9Gvhyzba3KaXuUUp9\nRik13mqBVihXK6X0kSPVDYp9Ph/FYrHVUwgdUiqV8EnRgKGQgWCskmcnve66ygNHE/zR52/nxZ/8\nOT/ba0TdI1PipgqC0H/0ZbWsUioEvBB4t2vzp4C/A7R1+WHgfzV7Hq31NcA1YAoq3PsCgQCZTIZ0\nOo3f7284/UFoD601pVKJUqlEINCXf3bLTyFtibsRc1vCsl1hZiHH3/zn/fzn3eYE77Jt4+zePsEn\nbn2UTL7U5dUJgiB0zkpaKIeBU123T7G2ed5HKRUARoETbTz2ucCvtdbOWAat9XGtdUlrXQaupz6M\n2zHxeJxQKCTCbhlQShEKhYjHpRrUoZCBYNTl3Im46wZfuf0g/3n3Ec7fMsLnXn8ZN775t3jKGWbs\nXrZQ7vLqBEEQOmclLZTbgbOUUtsxwuxq4A9q7nMz8FrgF8DLgB9orbVS6mbgS0qp6zAFFWcBv3I9\n7pXUhGSVUpu11ketmy8G9izHixCXSVgxCmmIjou46zInU6Y9z/tfchEXnjIKQCRoznszBXHuBEHo\nP1ZMuWiti0qptwHfAfzAZ7TW9yml/ha4Q2t9M/Bp4AtKqb3ASYwAxLrfjcD9QBF4q9a6BKCUGsJU\n4L655ld+UCm1ExOW3e+xXxB6C8e5k7BsN0lkCgCMRCtfh5GgqZLNirgTBKEPWVFbSmt9C3BLzbb3\nuq5ngZc3eOy1wLUe21OYoova7a9e6noFYdUol6CUqwnLSkFFN0hkLXEXCTrbRNwJgtDPSNmiIHQD\ne65sVUGFiLtukMyaqvh4pHKuGxVxJwhCHyPiThC6gd3AWAoquk4iWyAW8hPwV74OK86dFFQIgtB/\niLgThG7giLuYiLsuk8gUq0KyUHHupKBCEIR+RMSdIHQDJywbNT/KL+KuSySyhapiCoBwwHw1Slh2\nsJhN5bnx9oMyKUcYeETcCUI3cIdllTLunYi7VUdrTTJb79z5fIpwwCfibsD47M/28X+/eg+/OTjX\n7aUIwooi4k4QuoHt3IWGzGV4RMRdF0jnS5TKmpFosG5fJOiXnLsB49Cc+b+z298IwqAi4k4QuoE7\nLAsQGZFq2S5gt0FxV8raRII+ybkbMKaTOUAKZYTBR8SdIHQDd0EFVMKykgu0qiQypg1KbVgWTFGF\nhGUHi6mEEXe5onyuwmAj4k4QukGtcxeOgy5DPtW9Na1BnAbGUS/nzi/O3YAxlcwCkBPnThhwRNwJ\nQjfwcu5A8u5WGWf0mIdzFwn6RQQMEPlimdm0+byz4twJA46IO0HoBl7OHYi4W2Xs6RTeBRU+8qUy\npbKEygeB6YWcc13C7cKgI+JOELpB3tUKBUTcdYlmBRUygmywmEpkneviyAqDjog7QegGdWFZmS/b\nDVqFZUHE3aBwPOFy7iQsKww4Iu4EoRtIWLYnSDQNy8oIskFiOllx7qQVijDoiLgThG7Q0LkTcbea\nVJw772pZECEwKEwlK86dtEIRBh0Rd4LQDRznrrZaVsKyq0mrggqQsOygMOUOy4pgFwYcEXeC0A0K\nUlDRC0hBxdphqiosK5+pMNiIuBOEblDn3ElBRTdIZAqEAz7CAX/dPgnLDhZTyRxKmevymQqDjog7\nQegGhQygIBA2t8W56wqJbNEzJAsV504KKgaDqWSOTSMRQHLuhMFHxJ0gdINC2rh2tpUg4q4rJDIF\nz2IKkJy7QaJU1pxYyHHKeBSlpM+dMPiIuBOEblDIVPLtQMRdF9Bak2zi3EkrlMHhxEKOsoYN8Qjh\ngE/63AkDj4g7QegGtnNnExoC5RNxt4rkimXypTJxjwbGUBF3ORF3fY/dwHh9PCwzg4U1gYg7QegG\nhXS1c6eUce+yUlCxWjTrcQfi3A0SdqXshpGwOHfCmkDEnSB0g9qwLJiKWXHuVg27DUqrggqprOx/\n7AbGG+IRIkG/5FEKA4+IO0FYbbSuD8uCce6kFcqqMZ+xGhg3DMuar0dx7vofu4HxhniYSMBPriiC\nXRhsRNwJwmpTtJqphrzEXdKIP2HFSTrOXfOwrLg8/Y87LBsJ+uQzFQYeEXeC0CaFUpl/+8V+Urni\nEp/IbmBcG5aNgy5V9gsrSsIaPdaqoELCsv2POywbDvjJFspoOYkSBhgRd4LQJt+9/zjv/eZ9fPOu\nI0t7Imf0mIdzB5J3t0q0KqiIhsS5GxSmkjmCfsV4LEjYCrdLaFYYZETcCWuer955iCs+/EMnTNeI\nqYQJ7cxl8kv7hc2cOxBxt0q0KqiIBKSJ8aAwnciyIR5BKVVpcSPiThhgRNwJA8EXbzvAd+8/vqjH\n/uChKR6dTrF3aqHp/WbTRgykc0s82Dd07mS+7GqSaFlQIa1QBgGtNdMLOdbHzai/sCXapX+hMMh4\nxyMEoY+YTxf4q2/uYcemEZ513saOH39kzjhps+nmjtyctT+VX6mcOxF3q4nt1I5KQcVAM5suUChp\nNljiTnIphbWAOHdC33PHgZNoDclc87BqIxxxl2r++GVz7vIpcylh2a7SqqDC71OE/D4yIgL6muOJ\nSqUsVFrc5KSRsTDAiLgT+p5f7TsJwEK2c0ctXyw7lXStnLvZZXfupKCim1QKKrzFHRghIOG7/sZd\nKQsQDohzJww+Iu6EvueXtrjLFTtub3A8kXXayrUOy1rOXX6pOXdSUNELJLIFgn7lODleyDSD/scu\nhKqEZa1CGXHuhAFGxJ3Q16TzRfYcngegUNIdV8DZIVmAky3CsidTlnO35D53rVqhSM7dapDIFBiJ\nBFFKNbxPNOSXgopeI3kcFqbavrvj3Nlh2YDkUgqDj4g7oa/5zeNzFMsVt26hQ+F1ZL4i7ubaLKhY\nPueuUbWsOHerQSJbbNgGxSZiNbwVeogvvhT+/WVt3326JizrtEKRz1UYYETcCX2NHZK12xwkO8y7\nOzKXda7bzpwX+WKZlCXqlp5zJ02Me4FktkC8QQNjm4g4d71H8ggkj7V9d/foMcBpYixhWWGQEXEn\n9DW/2ncCpeAZZ68HOi+qODzndu4ah2Xdrt7S+9y1yLnLSlh2pckVS2QL5abFFGAaGeeLZcplGVXV\nMxQylfnMbTCVyOFTsG6oNiwrzp0wuIi4E/qWXLHEbx6f49xNI2wdM0Kp03Yods7d5HC4aUHFrEv4\nLZ9zVyPuIhKWXS1sh3ekQY87G6cnmrg8vYHW5v+n0IG4S+aYHA7j95ncyrC0QhHWACLuhL7l3kPz\n5IplnrR9wgmvdercHZ3LMhIJcMp4lNl0vmG1rVv4pfOlpQ0db5RzFxwClIi7VaCdNigAUWl421sU\nTf4cpRyUW38mWmumklknJAvSCkVYGzQVd0opv1Lqv1ZrMYLQCb/ab/LtLtvmEnedFlTMZdgyFmVi\nKEShpJ28ulrcYdlSufOq3CoahWV9PhOaFXG34iQc565FWNZyeSTvrkewXW8wAq8FyVyRbKHsFFOA\nqxWKfKbCANNU3GmtS8A6pZQ4fEJvoDXc/HZ48FtO8+LLto8zHDYH6U7EXSJbIJkrsmUsyljMPH62\nQVHFbE0+3pIqZgv2hIpY/b5wXFqhrAL26LF4uHlYNhqSthk9RSHjfb0BtT3uwFUtu5QTNEHocdqZ\nLXsb8DWl1JcAZ7K61vqWFVuVIDQieQx+/W/ohWnu2P96Tp8cYkM8wrDl3HVSLWvn220ZizhJ1rPp\nPKdO1IsuOyy7bijEiVSeVK7IxFBoca+hkXMHRtx10MNLWByJTHvOXVh6ovUWbkHXRlHFVMJug+Ih\n7uQzFQaYdsTdTuvyLa5tGhBxJ6w+1lzW1EKChVyRF1y0GYDh8FLEXdSZUtGoHYpdSbt1PMqJVH6J\nzl0LcXfiUeNQNmmuKyyNhOXctSqoEOeux3CHZdsRd1aPu/UjlbBsOCBhWWHwaSnutNaXr8ZCBKEt\n8sY8TqdMXtru7RMArpy79qtl7R53W8eipKz2Jo3aodjh2q1jUe45NN9xbl8VhTQEIuDz1+8Lx6Fc\nMAcuL/EnLAvtFlRI24weoyos2464axyWlc9UGGTace5QSj0H+F3r5v9orb+7cksShCZY4i6fqRZ3\ntnPXSbWs27mbsc7wGzl3ds6d3XIlvZR2KIVMY+HmbmQs4m7FqDh3bRZULHUqibA8VDl37eTcmf/r\njSP1BRXSCkUYZFoWSiil/g/wYWDO+rlOKfXn7Ty5UupKpdRDSqm9Sql3eewPK6W+Yu3/pVJqm2vf\nu63tD1niEqXUOUqpu1w/CaXUO619E0qp7yqlHrEux9tZo9BnWGFZnU+zdSzKKeMmP24x1bJucTcW\nM/lzjUaQzaXz+BRsGjUHidRSGhkX0t7FFCAjyFYJO3zfakKFE5YVIdAbVOXcta6WdebKxqUVirC2\naKcK9tXAb2mtr9VaXws8BXhNqwcppfzAJ4DnAucBr1RKnVdztzcAs1rrM4GPAB+wHnsecDVwPnAl\n8EmllF9r/ZDWeqfWeidwKZAGvm4917uA72utzwK+b90WBg3LuQvrHJdtq+j3odBicu6y+BRsjIed\n4oiTDcTdbDrPWCzkOIQr59zZ4k4qZleSTsOy4tz1CMUOq2WtsOzksDssK+PHhMGnHXGntNaOjWBd\nbyfTezewV2v9mNY6D9wAvKjmPi8CPm9dvwm4QimlrO03aK1zWut9wF7r+dxcATyqtT7g8VyfB36/\njTUK/Ybl3EXJsXv7Omezz6cYDgc6EneH5zJsHIkQ8PsYt1uhNMi5m0sXGIsFiVnirlE/vLZoNywr\nrBht97lznDtxeXqCTqtlkzkmhkKEApVDne3c5cS5EwaYdsTd7UqpzyqlnmL9fBq4o43HbQUOum4f\nsrZ53kdrXQTmgXVtPvZq4Muu2xu11ket68eAja0WqJS6RimllVL6yJEjre4u9AI549zFyLJ7W3Xk\nfTgcaDssWyprjiWybLFy6OywrFefO601c5kC47EQQ9bBPr3UgoqGYVkRd6tBIlPAp3A+z0ZELFEg\nbTN6hA7F3XQiVxWSBfD7FEG/EudOGGjaEXdvB44DH7d+poG3reSiWqGUCgEvBP7Da782s6FazofS\nWl+jtVZaa7Vly5ZlXqWwEmgrLOtXmjMmqvOlhiPti7vpZI5SWTviLhTwMRwOeDp3iWyRUlkzHgsS\nCy3RuSsVoFwU567LJLIFRqJBVIt2M3bOnYRlewR3QUWLatl0vkgyV2R9jbgDE26XnDthkGmaTWzl\nzf2h1nox+WuHgVNdt0+xtnnd55BSKgCMAifaeOxzgV9rrY+7th1XSm3WWh9VSm0GpBPsAJJZSGB7\nXqomvBmPBHj8RNr7gTUcdjUwthkfCno6d3aRxVgsxFB4ic5dvsl0CqiIu6zk3K0kyWyxZTEFuNpm\niMvTG3Tg3FUaGEfq9oWDfnFjhYGmnfFjb17kc98OnKWU2m45bVcDN9fc52bgtdb1lwE/sFy3m4Gr\nrWra7cBZwK9cj3sl1SHZ2ud6LfDNRa5b6GEyKZfosYWSxXA4QL5UbqvFgVMpO1oRh+OxkDOJwo3t\n5i2Lc9esgTFIQcUqkcgUWhZTAESDtnMnLk9P0EETY6dSdsTDuQv6ZPyYMNC0E5b9gVLqZZ0+sZVD\n9zbgO8ADwI1a6/uUUn+rlHqhdbdPY2bX7gX+FKvCVWt9H3AjcD/wbeCtltBEKTUEPAv4Ws2vfD/w\nLKXUI5iefO/vdM1C9yiVNd/4zeGWXePzaZfoKVS7dE47lDaKKtxtUGzGYyFyxXJdCG7Wy7lbbLWs\nvWYJy3aNYqlMKl9qS9xJZWWP0cFsWbtSdqNHWDYc8PXXhIpyGY7tMZeC0AbtNDF+HfBnSqkMkMJU\nymqt9YZWD7Tmz95Ss+29rutZ4OUNHnstcK3H9hSm6KJ2+wlMBa3Qh9xy71He+ZW7+LvcBbz6yac1\nvF8x6xI9Hs4dmJDbuuH6L3Q3R7zCslbF7Ml0nq2hiviyw7LjsVDFuVtsnzvHuRvy3h+RPncrTdKp\nlG399ef0RJOcu96gyrlr3ufOCcuO1IdlI0E/2TYmXPQMD9wM//Fa+IMb4ezndHs1Qh/QjrjbteKr\nWAPki2XuPTxPLORnx+aRbi+n59hzeB6AQyeb58yVswuVGzXO3XDYiLOmRRWpE5A+wZH5yugxm/Gh\nSsWse/tsyh2WXapz1yosK87dSuNMp2gnLCtNjHsLtyBrMaHCq4GxTSTo76+wbPJo9aUgtKBpWNZu\nRKy1PlD7s0rrGxhSuSIv/dTP+ej3Hu72UnqSB44ZMXMs0eJsuuBy6/I14i7SRiPjb/8FXH85M7Nz\nxEJ+Rl19zsbtdig1eXfugoqg30co4FtCzp0dlpVWKN2iMp2inbCsVMv2FB3Mlj02b+7rWVAR8FEs\na4qlPhF4dpQi317BmCC0U1CxTinVTm6e0AS7WWqjwfRrnQePmly6Y/PNv7D9BbdzVx2WHWlnBNnJ\nfZBfID03zebRSFUrDMe5q/mMnIKKIfMZDoX8i6+WbeXchYbNpYi7FcOZTtFGWNbucydtM3qEDgoq\n7juSYCjkZ+t4/f9apQq6Tz5X+3UXRNwJ7dFOWPY24GtKqS8BzpHVyqcT2sTvU4xEAiLuPDixkHNC\nKPZlIwLuUEytcxe2xV2T90c2tgIAACAASURBVDhzEgCdnWfLKadX7XKmVNS0Q5l15dwBxEIB0kt2\n7hqIO5+fvD/G0aPHOLWs8fnaGQYjdEInYdmA3ycNb3uJNluhpHJFHp1eYNdpE/g9/ofsQplcoeR8\nb/Q09usWcSe0STt/1Tuty7e4tmlqCiWE1ozFQsxlvGeXrmUePFZxqY7NZ9FaN2wuGy67m5h6h2Wb\nVsumjbgbJVWVVwfNwrJGDIxZ4m8o7G8pQhviOHcNwrLAfDkChQSz6XzLwhChcxKZ9kaP2USCfgnL\n9gpVTYwb59zdfzRBWcOFp4x67ncKZfrFuZOwrNAhLcWd1vry1VjIWmAsFuShY31UobVKPGCFZP0+\nRaZQIpkreroqWmsiOluZbNygWjbRSNyVS5A1hRujKlXVBgVc4s7DuYuF/M4BYSgcID2zyC/ZFs7d\nVCJLohRhXCWZTRdE3K0AFeeuPcem75LvB5lCxlSaF1JNq2XvOWT+zy9qIO6cFjf90g5FwrJChzTM\npVNKvcR1/aKafW9ayUUNKmNWH7W++UJZJWzn7tLTzKzY4w3y7uYWMkRVnrL9Z9uoz12jfLjsPPZU\nuhE8xJ2VU1ebczeXLjjCD2AoZJol5xdzwG9RUPHrx2dZIMowGaeQQ1heEh0UVIARAmvaubvnP+B7\n13R7FYZCBmIT5nqTsKxdfX/B1hbOXb98F+dF3Amd0axQ4j2u65+r2ffHy7+UwWdMiio8efBYgnDA\nx5O3my/t4wnvM/KZk7MApAJGBNY7d1YrlEbOnRWSBcu5G62uomsUlp1N552QLOC0Q1nUAb9FQcWd\nB2ZJ6BhhVWQ+ueB5H2FpdFJQAWZKxZrOubv9evjpR1o2DV4VCmkIDYE/1HQ99xyaYzgcYPs6736S\ndkFF3ziydvFYL3wGQl/QTNypBte9bgttYAsEyburUCyVefj4AmdvjDtOWqN2KCfnjDjLhq0e1p06\nd5mKuBshXefcRYJ+okF/lbjLFUuk86Vq5y5sjyBbRMVsC+fuzgPGuQNYSMx2/vxCSzopqADJuXNO\nojJz3V0HGLcuGIVApGFYdiFX5LGZFBdsHWlYkBQO9FtY1hJ1NSe0gtCIZuJON7judVtoA9u5s5vi\nCrD/RIp8scy5m+JstJy04w3E3dycObgUo5NmQ6d97mqcu02j9f2vJoZCVZ9PbTEFsLRGxvaXdKhe\n3GULJfYcTrCgjbhLJ0XcrQSLKajIFcuUy2v0a88Rd13+e9TanBwFY5a483ax7js8j9Zw0SljDZ/K\nce76pcWNhGWFDmkWl1ivlPrfHtcBJldwTQPLqOX+zItz5/DAUZNvd+7mETaNNBd3yXnLORiahBnq\n+twNhWxx10A8uw5OG4JZ5wvezVgsyL6ZyvOeTFW3QQGXc7eYEWRNCir2HJ4nXyoTGRuFLGRT850/\nv9CSRLaAUhC3W2AkjsAdn4Vn/F/w1ws+dwjPnlixprDFXbbLzp2dY9fCubu3Rb4duFqh9Eu43QnL\nirgT2qOZc/c94DLrx339MuD7K7+0wcPuoyY5dxUePGYqZXdsirPREneNGhkvLJiDS2Bks9lQk3/i\n9ymGQv62wrLrg95n/RNDIdL5khOuqfS4q3fuFheWbdwK5c4DRnxuXL8egPxCD4TBBpBktshwKFAJ\n2d3+afjxB2H/TzzvH+23ysrlplecO3e+ajDSMP/MqZRtIu4qBRV95txJKxShTRo6d1rr16/mQtYC\nlZw7EXc2D1rO3Tmb4ozHgoT8Po436CGXWTBCMDK2AVCeX3TDkUBjcecKy074vL8kxyyHbi5dYNOo\n3xWWra6WBUgvyrlrXFBhi7vTNm+Eg1DMiHO3EiQyheqQ7PxBc5n1fr8r0wzWoLgrlytuUdfFnStf\nNRBpWC275/A88UiA09Y17iUprVCEQUfGiq0io9GKcBAMDxxNsCEeZt1wGKUUG0bCDVuh5FJG3MWG\nR80XfKE+uXg4HGhcLesuqFDeX5IT9pQKy7FznLshl3MXXopz511QobXmzgOzbBmNsH7SZD2UsjKC\nbCVIZAtO8Q0A84fNZYNk9ehani9bzOCkWHdd3FknRoFIQ3GXyBZ4bCbFhVtHGzZCB5dgF3EnDCgi\n7lYRx7mT/mUAzKcLHJnPcu7mEWfbppEI0ws5Sh7J64WM1ew4EjcFCR7OXTwSJNkwLGsOThkdYqjs\n3WZkrKaRcVPnbrGtUHyButyuAyfSnEjlueS0cfxRK5yUTXT+/EJTymXNQq5Y7dwlDpnLnPffREUI\n9EkIbzlxC96uizvXiVEwAuUilKr/1+3+do0mU9hUcu764DMt5s1rBQnLCm0j4m4VkT531bjz7Ww2\njkQolTUnFupDs6WsdfANDVnOnZe4C5Avlr0Tpa2w7ON6A5GityvmzJe1PqNZj4IKJ+eukYhshl3t\nV4Mdkr30tHEIW++HtD1YdpK5Ilq72qCUy6agAiDv/TcRtoRApl9cnuUk7xK83W6F4k5pCFhpDTUV\ns7a4u2hr40pZ6LOcO3eEolyAkhw/hNaIuFtFRqPS586NPZlih8u5c4oqaipmF3JFgiVLzIWGjcDz\nED/2CDLP0GzmJDlfjBk9SqCU9vySHB8yIu6kE5Y193EXVNjVsoty7vJp73y7x42423XahCPuAoUk\nWq/R9hsrhNPA2A7LpmegZP0/tgjL5takuHOdQHXduXMVIwWssXw1FbN2McWFTYopwJVz1w95lLVu\nnYRmhTZoWFChlLqdJv3stNa7V2RFA0zA7yMeCYhzZ2E7d+durjh3m0bNl3btlIqpRJYhZW0LDTd0\n7hxxlyvWz2VNz7LgizOP1bU+O2/aqriwHbo5JyxrLse8nLvFVst6ibv9s0SDfvNeTJv3I6ozpPIl\n5zUJS8fugeiEZecPVXa2CMuuTeeul8Ky7mrZaPU2i3sPzzMaDXLqhPcEGBvbueuLPne133P5NESa\ni1dBaHbU+HPr8vnAucCnrduvBx5ayUUNMmOxIPNSLQuYHndBv+L0yWFnWyPnbiqZYwi7AfCQybkr\n5U3Ojb/yZ9y0kXHmJHNsZkFZ4i4zVyfuJuqcuzx+n6oaMu84d4vtcxetDhnNZwo8PJXkSdsnCPp9\njnMXVxlmU3kRd8tIZTqF9Z66xV3eW9xF13TOnTss221x5+oRGbAakLuKKubTBQ6cSPO0syabFlNA\nnzl3teJOnDuhDZq1QvkRgFLqg8CTtRUfUkr9F/Dz1Vne4DEWDbF3SmaGlsuah44lOWP9MKFAJTvA\nFndTHuIupqxtoSEIWgKtkAJ/5SzWHgZf1w6lkIVCmpO+YYrBESjh2fpirKYX4Vy6wFg0WHWwWFrO\nXaYu5+6ug3NobeXbAYRNmHqYDHPpAqdOdP5rBG8qc2Ut5y5xuLIz551z13dtM5aTQq+GZevF3Z4j\nrZsX21Ry7vrgM5WwrLAI2sm5mwDcc5rC1jZhEYzFgmQKpf74UllBHj+ZJlMoVeXbAQ0bGU8lsgxh\nhWXD8cr4rpovvnijnDvrwHS8GEPbIY1s/cHKce5SFefOzsOzsatlOw7LlktQytWFZauKKcCEnYFh\n0lVzboWlk7DDshGPsGyDnDsJy1p0e0JFbRNjMCdtFu00L7ZxTx3peZyCCusEUypmhTZoR9x9BfiF\nUurdSql3Az8DbljZZQ0uY84IsrUdmnXy7VyVsgAbR0yeXG1YdjqZI4bbubPEXc1ZrB2WrXPurB53\nJ8vD+KKWiPJw7qJBP6GAj7l0nnJZM58pVBVTQKXPXccFFQ2mU9x5wKztkidY6wqEKPrCDKuMiLtl\nxnbunD53bueuQVi273qiLSfu9yQ7b05QukVVWLa+Wvbew0Z8tmqDApUK6L4okrHFXGydufTo7ykI\ntbQUd1rr9wB/hZknOwm8R2v9Vyu9sEFF2qEY3DNl3cRCAeKRAFO1BRXJHMMqg/YFwB8yAg/q3BY7\nP61uvqzVBmWWYYLDlojyaO2glGIiFuJkOk8iW6Csq4spAEJ+HwGf6jws6zGdolgqc9fjc5y5Ybjq\n95SCw8TJOK1YhOWhvqDisOk7GBlto89dHwiB5cYWFn7rb7PBFI9VoaoVSn217L2H5xmPBdk61ryY\nAiDSV61QrM/Azg9uMHZNENy0lamttf5PpdRtWuvplV7QoCONjA0PHK3vcWezaSTiUVCRJUbOiDql\nWjp3dY2MrbDsvB7mjLiVVdAgzDQWC3J4NuPZBgWMAIyF/Itw7uqnUzx0PEkqX+JS27WzKIeGGc7O\nO2tYMtMPw/hplYPiGqVSUOHKuYtvMdeloKIe++RpZAvM7jf/R7EuZeVUNTGurpadTeU5eDLD089e\n37KYAiDoV/hUnwh2+3XHLHEnYVmhDVo6d0qpJymlDgC/tm7vUkr9y4qvbECp9Lpb287dg8eSrBsK\nsT5eLzY2jUaYzxSqvninEjniviwqZIlBJ+eu2rlrnHNnOXd6mKFR60uygQsxMRQimSsybc24Ha9x\n7sBUzHacc+fh3P26Nt/OJhS3CiqW4SRgZi98Yjf8Sv5t552CioCptE4ehdGtVt/ERs6dNDFm5BRz\n2c1GxlXOXXVBxb2H28+3A3OCFgn6+yPnLl/r3ElYVmhNOzl31wHPBWYAtNZ3AE9dyUUNMpXB9GvX\nuVvIFXn8ZJpzN8c9z7I3xM0X93GXezeVzJk+d3Y41qmWrSmoaFQt6wrLjoxZX5INDlS2mNs/Y75E\na8OyYCpmO26F4s4ZsrjDFnfbqsWdLxpnSOWYS3nP2e2I2X2AhpP7lv5cfY4zTi4aMsJOl2FkK4SH\nG4Zlo2s5LGv/zY7a4q6LFbPF1uKunXw7m3DA1x+fqYRlhUXQjrgLaa3vr9m2dpXJEhmPSc7dQ9Zk\ninM3jXjur21knC2UmM8UiOlMRdw1qJZ1CioaOHdzOs7E5HqzrYFzNz5kPqNHZ8zBvjYsC4t17urD\nsvccMk1XT58cqrprwJovm00tQ46TLWJzMqt2Lp3Hp6yCCruYYnSrqVAuF+omHoBUywLmPYLuijt3\nQVJNtey9bU6mcBMJ+vujz539GQytr74tCE1oR9zllFLDWNMqlFLnActgJ6xNnJy7NRyW/ckjJnWz\ntlLWpraR8XQyR4AiIQoezl2DgooGOXdzDLFucoPZ1iDnznbu9k03d+6yhTKlcgfjwWrCsoVSmcdP\npjlzw3Cdg+mPGOFbWBZxZx2QsyLu5jIFxmIhfD5VaYMycopx7sDTvXPaZqzlnLtecO48Z8ua74iD\ns2miQT+bRyMNHlxPJOjvj8+0zrmTnDuhNe2Iu78H/gfYopT6HPADTPWssAhGo3ZYdm2Ku1sfnOLj\n33+EyeEQzzxng+d9bHF33Op15xRTgDO9oaFz17Ba1hyUsoEx4kND5uDQICxri7nHrLCsp3MXsufL\nduDe1Th3B0+mKZU129YN1d/Xep2FzDKIO1vENmjSu5aYS+edivU65w488+7WdBPjupy7boo71/+P\nUy1rviNOLOSZjIfaKqaw6buwbEzCskL7tKyW1VrfopR6EHgOpovi+7TWe1d8ZQOK7dzNZ9ZeZPvB\nYwne/uXfEPT7uP41uzyLKcAl7iznbipR0+MOXNVy1eLO7zOVrF597kr4iI1MmANAdKxJQYX5jA6c\nsMTdkIdzZ48gy5ecPL+W2F/KljDdbz3/6esbi7tydhmmmdgH5DUeltVaM5cu8IQJ68Rg3hZ3p7QQ\nd2s5LJs2rWKGm7vdq0IhA8oP/mBVtazWmhOpHOdv6WzeajjoJ9uPBRUSlhXaoKm4U0r5gW9qrV8A\nfGp1ljTYjK7RPndTySxv+NwdLOSK/NMfXMzFNa0/3GyqCcuaYopacefd5w6Me1ebc6fTJ5nXMdaP\nWAeFyCgsHPf8/bZzVyhp67aXc7eIEWQ1zt1jVth3+2RjcecvJMkXy1Uj2jrGdijXeFh2IVekWNaV\nMLvt3LUIywatvoZ94fIsN/mU+Z+zG39327mz81Vdfe4S2SKFkmZyuP4krBmRgI98sUy5rE2Yvldx\nwrLrq28LQhOaHjG01iVgnVJqCUcWwU3Q7yMeDixf/7I+IFso8cZ/u5PDcxn+/Nln84KLtjS9/+Rw\nCJ/CaWQ8lcwy5Dh31kHYDst6hCjikUCdc1dOn2BWxx1XkIjl3On6nLmJmhy7sahXzl3FuWubmpy7\nfVbY1zss65ovu1SX13HuutiAtgdwKmVjrtFjgYjp2+Y4d43my/rJ9EN+1nKTXzDvTU+Iu0zFsXNN\nqDixYL4n1g111sPRdmTzpR7/XO0TWAnLCh3Qjmi7DfiaUuoVSqnn2T8rvbBBZjQWZH6NtEIplzV/\nduPd3H1wjpdcspW3Xn5my8cE/D4mh8MV5y7hdu6sg7DTxNjDuYsEnUkEAGiNLzPHPENsshOuo2Om\nDYZHHpq7r91wOODpmg2Fl+LcmQOTHZbdNhmrv6/l3A2rzNJdXnfOnYeYXSvMOU2prc93/pBpg6KU\nS9w1ni/bF6OqlhvbLQvHTUi0V8Sdq1r2hDXFZV2Hzl040Ce5lIU0+MMVd1nCskIbtDOhYqd1+RbX\nNg3csvzLWRuMxYJOSG7Q+eIvD/Cte4+ye9sE//CSC9tOeN40GuGhY0m01kzVzpV1X3p0a4+HA+SK\n5Uo4M5dE6SKzOs4GO88vYuXnZOcgUt2SxW6FAt4hWViqc2fE3L7pFJtGIs5zVWGJu2UZQWYfkHXZ\nHBjsg8Qaw57TOxYNmhYa6RnYeJ7Z2SQsC6aoYi3k3P3zjx4F4I+fcYbZkE9VBHB0rPtNjIc3muuu\nPneOcze8OOeu5yeP5NMmUuEPGYEtYVmhDdopqLh8NRaylhiLhkjnE+SKJcLWjMNB5Wd7ZwC47qon\ndvRaN8Qj3HNonvlMgalkjgsDlsBxcu68x49BpWJ2IVdkIhCq9LhjuDosC55FFcPhAAGfoljWntMp\nwOXcdVQtWwnLZgsljsxn+a3T13nf13buyDiiZNG43ZZcQsTdUKg63w6aFlSAaWQ8s1DfA2/Q+Jcf\nP4ZPWeKuXDb/X/Z7Ex3vHefOJe5mFszn2nHOnVUFnev1Xne2e6qU+f4TcSe0QVu5dEqpUaXUbqXU\n0+2flV7YIDPqVMwOft7dY9Mp4uFAW8O83diNjI8lskwns2yMWl/ATs5dk4KK2kbG6crosYq4s5w7\nDydCKcV4LEiIQmvnrpMpFa6CikpI1iPfDqrCskvKz9S6+jWu4aIK+/9tLBp0tUGpEXcN2sVEgv7e\nd3iWSKFUZjadZz5TQGtd+Xu181ttcdeN0H65bCZU2Cd1rmrZE5a46zTnzj7Z7PnP1V1IEozKbFmh\nLdqZLXsVsAfT3+564Fbgoyu8roFmrUypKJU1B06kOX39UEf9pwA2WiPIjsxlOJHKMxmy3ivbdfL5\nTR6Kx1lsPGI3MrYeY7kNszruVOISbezcAbwgdAf3h1/Pef5DnvudatlOnLt8JefOHm1WO5nCwVVQ\nsSTnrpCBkstxWsPtUGZTrpy7eVePO2iZzxQN+skUSkb0DCgnU3m0NlXimUKp8l7YJ1KRMTPFoxs5\nX1Y/O0fU+UOAgmKOEyk7LLs4567nc+7ssCwYkSfOndAG7Th3fwlcCjyitT4HuBK4fUVXNeCMrZFG\nxodm0+RLZU5f33kYcKNV+HDf4QRawzpb3IVcYigUa5hzBy7nzhJ38wyxYcTOubPFnXcO0aXqIQKq\nzAWl2sl7Bnefu7ZxOXd2g+RWzl18qQUVta9vDYs7u+p4LBaEhGs6BbQMy4adEF6PuzxLYDpZOQmY\nSxcq74X9P9fNitmaSnOUMqHZosu561jcWZNHevkztR3UoCvXWMSd0AbtiLui1noKKz9Pa/1d4LIV\nXdWA44wgG/CKWbtopKE71QTbYbvHGgg+4eTcuYRicKhBtWwl5w5wwrK54Jjzhd4sLAuwhRMAbC4d\n9dy/uD53lQOU7dx59riD6py7pRRU2AdiZb3uNRyWrWqF0si5a1hQYYfwetzlWQLunML5TMF1MlIj\n7rrRyLim0txcj0Ah66y7toVRK/qiWraQAbTLuZOwrNAe7c6WVcAjSqm3K6V+D1ibGdnLhNPIeMBz\n7h6dNgfKMzYswrmzxN0eS9yN+msKKqChczccNu+vI+6sggrfkKt4oUVYdn3ZzL/dUDjsuX/x1bLG\ncdg3k8KnqExLqCUYRSvf0nPubPE6YomYNezc2eFtE5a1nTvrfWnR5y7aL5WVS8Dt3M1nCvVh2V5y\n7sBy7kwrlPFYkIC/s3asfSHYa193MGZC46XBPnYIS6ed/4b3ACPAXwAvAt4L/O+VXNSgY3fInx/w\nsOyj003Ga7XAdu6OWvNl4z7rwFPl3Hnnn9jOXcIKyxYXjAsXGHaJO3crFA/Gi2Z6xVjOW9wtus+d\nVfW2bybNKeOxxpMnlIJwnDiZpTm89oF4/DRzucadu6DfjKcjcdjkNdptcFr2uTOf0yC3Q7GrTqEX\nw7LV012AirhbyHXcBgXM+DGgt0eQ2ZGJYE0LKAnNCi1opxXKD6yr88Dvruxy1gZ2QcWSW1z0OI9N\nL6BUgwkMLRiJBggHfE4+TN34Mft6IW0q6XwVkVSbc5dNzDAMREcmK4+1c+68wrKFLMMF4/YNpw/W\nPT8swbkLRklmC8ws5Hj62eub3l2FRxjJLrGgwhavY08wlw2qQdcCc+k8YzFruPz84YprB2aclS/Q\nMCwb7QeXZ4m4w7KJTAF8drWs3QrF/p/pgrirLaiwruvsHLPpAmdvjHf8lBHrxKqnm1PnayqW7def\nT1dOUAXBg5biTin1Qa/tWuv/u/zLWRs4OXcDHpZ9bCbF1rFoJc+tA5RSbBqNcOCE+XKLlq3wRK1z\nB6ZFgkv0xZ2cO/P+2s5dfHxD5bHNwrKJilvnK2Zh4RiMVI9Ms3vpddznLhhj/4x5TS1zEcNxhjm5\ntIIK+0DsiLs17NxlCqaJdS5pRrGN7q7stKdUNCiosP+GB9u5qwnLBu2wrKsVCnSnkbFXzl0gbJpR\nA5MD79zFqi/FuRNa0E5YNuX6KQHPBZpbDkJTRqODH5ZNZgtMJ3OLqpS1sduhAITKGfAFIeBKmrYP\nOjV5d7V97nTmJDkdZGLMdaYbGjZFBl5hWTsfy2ed+5x8rO4ukaAPpRbR5y4Y5bEZIyC2rWuQb2cT\njhOzZssuugVHpsa5W6Nh2VJZM58pmEr12mIKm9Dwmi6oqKqWzeR7LCxbPd0FgEAUVTQFBxNDnRVT\nQL85dxKWFTqjpbjTWv+N6+fdwFOA5pPfhaZUCioGNyy7lEpZG7sdSijgw19M109WsPNQaipmbVct\naeXD+TOzzDLMhlHXWb9SJqzh5dzZ4m7LJebSQ9wppRgKBTp07tJWpaz5Yt7eSviG4/gpEyznnPzB\njnGcOyvnbo06d4lMAa0btEGxCbd27nIDXFBR59w5BRWuCRXQOwUV1nzZEMWO26BAn7RCqSuocIVl\nBaEJnZUXGRaAJyz3QtYSoYCPoZB/oPvc2e7UGYsoprDZZPWk2xAPo/Kp6pAsNHTu4na1rCWIgoX5\n6ukUNpFR7xCTLe62W4NYPMQdQCzkbz/nLp824i62jn3We7O9VS7icsyXdXLuTrVue1cHDzp2CoRn\nGxSbJmHZ6BopqLDzVeczxfoihkgXc+4aFVQAEfKLK6joi1YoNQUVDU5oBaGWdiZUfND18yHMpIoH\n2nlypdSVSqmHlFJ7lVLv8tgfVkp9xdr/S6XUNte+d1vbH1JKPce1fUwpdZNS6kGl1ANKqd+ytl+j\nlDqslLrL+nleO2vsFmOx0GCLO6dSdglhWUuMbYiHTYuKUI0YapB/YleyJrNFKBWJlpLMM1yZTmET\nHWsQlj1oLh1xt89zfUPhQPvVsgum+pbhjew7kSboV2wdbzGSrWoE2SLFnX0gHloPgeiaLaho2gbF\nJjwMpTwU69/rQQ/LFkplTqbyTtuiuXTeoxVKN8Wd5WAFXP/D1vUweSYXE5bth8+0tqDCvrTfD0Fo\nQKc5d7PAPwNXtXqQUsoPfAKTo3ce8Eql1Hk1d3sDMKu1PhP4CPAB67HnAVcD52MmYnzSej6AjwHf\n1lqfCzyRaqH5Ea31TuvnljZeW9cYiwUHuonxY0tog2JTEXcRc6CpFXcN5ssG/D6iQb/pc2eJt1k9\nXD9YPDJmqvCspGwH++C/9VIjiJbDubPEnR7ewL7pBU5bN4Tf12Ikm2sE2aJPBDJz5iAYjJq2H2s0\nLDvvNDAO1c+VtWkypWLQCypOWs7wKeNRwgGfqZZ1cu6s98UfhFC8y02MXc6dFaIMq8KinLtIP/Qu\nrH3dEpYV2qSdVih/s8jn3g3s1Vo/BqCUugHTJ889z+lFwDXW9ZuAf7IaJr8IuEFrnQP2KaX2AruV\nUvcDTwdeZ60tD/SlQhqLBUnlS+SL5ca9zvqYR6cXiIX89W5ZB2yycu62DPuMo1IblnWGh3vPl13I\nFZ3pFNnAaH2TU6fX3byTvwMYcRedME7OxOnGudPa5Om5sHPutNatZ+da4i4dniSRLbJ7exuid7mc\nOzucFh7pjuvSA9jv31gsCAds564mddgt7mITVbv6QggsAbuYYnI4zGg0aOXc1bhGYPLuulIt69XE\n2Ag6E5bt3Lmzw7K5Yg8L9lr3VMKyQpu00wrlxmb7tdavaLBrK3DQdfsQ8KRG99FaF5VS88A6a/tt\nNY/dCmSAaeCzSqknAncCf6K1tv/S36aUeg1wB/BnWuuePZLZ82XnMwXWxzs/6+xlymXNvpkUZ20c\nbi16mnDJE8Z5xxVn8eJzY3A3HuLOzrnzHkGWyBTRmZMooBger/8F7nYo8Y3mutZG3E2eZW5PbIep\n+yA1A8PVReKxsB+tzQE/GmrR7iVpxN3xkhGUbTmaTs5devFTKrJzMLzJXI+MwNyBxT1Pn2O/f+Ox\noHHuYpPVQgGajiDrmyHzi2TaKqZYHzfibnohVy8sAKKjDdMUVpQG1bJgxN3k0KA6dzWiVsKyQpu0\nYxlNA9uBn1k/pwHHQl41JgAAIABJREFUgW9ZP6tJALgE+JTW+mJMqNjO5fsUcAawEzgKfLjVk1l5\neloppY8cObJCS/Zm1Op1Nz+AFbOH5zLkimVOn1zalDq/T/Gnzzqb7XGrDUijsKzHF108HGAhVyA9\nZ8aI6ZiHuPOaUpE+afrmjVoFCBPbzaVHaHYoVDPDthmWc/d4wYRa22rs7Jovu6gQfrlsXJaoy7kr\n5aGYa/64AWTeev9GI1ZBRW0xBTQNyw56E+MZy7lbPxxmLBY01cX2+xB0i7tx8/6s9virJs5dzFdk\nJNrSp6ijLwR7XUGFHZYV505oTjvibifwdK31x7TWHwOeCVyitf681vrzTR53GDjVdfsUa5vnfZRS\nAWAUONHksYeAQ1rrX1rbb8KIPbTWx7XWJa11GbgeExZuitb6Gq210lqrLVtWt7vLmN0OZQCLKh6b\nWXq+XRVeDgI0beg5HAmQLZSZO2FElb8mzAZ4T6mwiynsfKyJ082lh7iLWW5dup12KJa425s2a97e\nTouYpYZlcwlAV1pYWM+3Fnvd2c7dukDKiPfaNihQEXceRSd9kXy/BOzRY5PxEKPRIGUNpVyqvrdk\ntxoZe7ZCMdc3RMuLihD0RSuUugkV0udOaI92xN16wH2qn6e9Jsa3A2cppbYrpUKYAomba+5zM/Ba\n6/rLgB9o0631ZuBqq5p2O3AW8Cut9THgoFLqHOsxV2Dl8CmlNrue98XAnjbW2DXGrfmySxoK36M8\nNm3O+JdSKVuFLe5q+9w1KKiASq87W9yF3aPHbLymVNjFFLXibrY+FDVkT6lop5GxJe7uTy5C3JFZ\n3N+JnV9ni1h7juoaLKqwW6GsKxon19O5s/++PP6e7LD7oBZUuHPuRqwTz3Juof6Eqlu97pq0QpkM\nL67Bd8jfD85dzeuWsKzQJu142bcCtyilbJfu1da2plg5dG8DvgP4gc9ore9TSv0tcIfW+mbg08AX\nrIKJkxgBiHW/GzHCrQi8VWtt/we+Hfh3SzA+Brze2v5BpdROQAP7gTe38dq6hh2WHcSK2eVoYFxF\nbdWeTTPnzu51Z4Vlo6Me5yNeYdlG4m45nLtgjAdOlIkG/WwcaSNHyKqWjatFhmXt1+U4d64CkjWG\n/f7Fc8fMhto2KNC8WjbQB/lZS2DGlXNn5wOT8+gt2TVxV+/c5VWIELAusjhx5/MpQgFfb48fqyuo\naJxnLAhu2hF3b8MIpZdZt78F/Es7T261I7mlZtt7XdezwMsbPPZa4FqP7XcBuzy2v7qdNfUKdlh2\nfgDny9oNjJcvLFszBsmmQRNjqMyXzSdnABh2z5W1sR2trFdY1soKGNkK/pB3zp0zX7aNM//kcfTw\nBvbPpNk2OdReGMk6sI77s8ymluDcRWudu7XX6242nSca9BNK1YTd3bRRUDGozp0t7tYNhZ0JOhRS\nEK9xvLvVyNhjtuxCKcAEMBFa/GcSCfh6e/xY3YQKce6E9minFUoB+CfrR1gmxqyw7EDm3E2n2Dwa\nIRbqPMnZk4Y5d43bAtjizm6FMjaxsf55PXPuapw7nx/GtzV37loVVJRLkJqmsPlSMoVS+46mFZYd\n9+cW59xlap07K+duLYZl0wVrOkXN5+vGce48cu5C9vixHhYCS2A6mWM0GiQU8DFqFSf4i+keCstm\nzKxnf9DZlLTE3Vho8c5bOOjv7Zw7W9QGaqtlJedOaE7DnDul1NVKqTNctz+plJpTSv1GKXX+6ixv\ncBmzw7IDVi2byhU5Op9dPtcOXM5dvHp7E+fOzrkL5IzAWb9hU/3zRr2cu0MmiXzYJQYnTjcHM0so\n2tjVsi2du/QJ0CWSAVPUsW0y1vz+NpYYG/NnObkocVeTc2eFeddiQYURdyFIWFXxtT3uwCXu6k8W\n7LDsIDt3dpPvsVgIH2X8pWzjsOxqNzIuZKrz7YBEwRy+RoNLcO6Cvt7OucunzOv2WYdqCcsKbdKs\noOIvMS1FUEq9CHg+8GxMSPYjK7+0wcYRd8vs3D1+Is1ffWMPiWx3HMF9VqXsGctVTAGLrpYFGCNJ\nUkcZj3sIqkiDgoqRLZUvU4Bxqx1KTVFFLNxmzp1VTDGjzIFxe7stYixxN+LLki2UOz8I1ebcrdGC\nikKpzEKuaHrcLVg5d8MeTm6TsGzQr/D71EDm3BVKZWbTlX6bo9EgMaypLTWCqmvOXTFT15dwtmD+\nx0cCbY4A9CAS8Pe2uCukqz8DfwiUX8KyQkuaiTuttbaPmldiCiJ+pbX+FOCRwCR0wugKtUL52/+6\njy/cdoD/uvvosj5vuzxqV8ouVzEFNBZ3bVTLjqoFEr4R7xw3W+zY4ctizhz8R0+tvp9TVFEt7hzn\nrlW1rCXujhbN79vernPn80NwiGHrQNtxO5TanLs16tzNOaPHgpA8BrF1To+0KpoUVCiliAR8ZNod\nN9dHnLDboFgjvEaiQaJ2g4S6sGy3cu48xF3OnFzF/UsQd70els2nqyeEKGU+E5lQIbSgmbhzt9x/\nCqaBsdc+YRGEA35iIf+yhmX3HJ7new9MAfDrx7sznKMyU3YZnTu7AKA2ROScxdY7dyMRI57HWSDj\nH/F+Xn/QPKft3Nkhu9p8rAbiru1qWWs6xb6cceLadu4AwnFimNfXcVFFbc7dGnXu5pzRYyHzWQx7\nhOihaZ87MO1Qsr08qmqR2MUUtrgbiwUZUpZz1zM5d+k6F/FkzpywDfkWL+7CAROWNR24ehCP100w\nKrNlhZY0E3c/Ukp9WSn1EWAS+DGAUmo9MHhVAF1gLBpcVufuH3/wCAA+Bb8+0PzLN1cs8Z5v3Mud\nLe7XEXu+xqX3XQvoZc65a9Dnzj6L9cq5iwQIkyeq8uRDo42fOzJaCV82SrZvMKWi7T53lnP3cCrK\nSCRgwoPtEo4TKZvX13FRRaOcu7Um7qyK9PWhIuTmId5A3DXpcwfmhCw3gGFZ9+gxMFGFIce5a9QK\npRs5d9XO3UzOHL6ivsV/h0aCfsoaCqV+EncxCcsKLWkm7t6Jmd2qgOdore0jyznAdSu9sLXAaCzE\n/DKJuweOJvjOfce5+AljPPXMSR6bSXEy1VgM/Oihab542+O8+Qt3OmfuS+Yn1/H0uW9wWnCOLaPR\n1vdvl0ZhWbC+6LzDsuMYB6bkNVfWJjIGGcu5ayTuxp5gHMIacde2c2c3ME5E2b6+w3m74Tjhknl9\nHTcyth1Ju59fj4RlD82meeW/3OaE8FeaWev/YIvfej8aibtAxHzOHmFZMMn3g1hQ4R49BkbcRe2c\nu5CHsPCHVte5K5ehmK0TOVMZ838UVUsRd+YQmOtFR7ZcMq/bKx1FwrJCCxqKO611QWv9Ia31O7XW\ne1zbf6q1/uLqLG+wGY8FSeaKFEpLdwP+6Qd7AXjHFWdx6WlGzFS5d4kj4Ao9/PzRE4AJyfzFTfcs\nPSyRT6Gn7gPg0tEFfL7OxwE1e27AW9yFYg2rZceU9Tiv0WM20THjZJXLLnFXk3PnDxqB18i5a5WH\nZYm7I6VRztscb37fWsJxAuUcQYqLy7kLj4DfagvTI2HZ79x3nF88doJv/KZ2GuHKYDt3G5TlNjUS\nd0oZ986joAKssOwAijvbuZuMm2rZoN/HuqAlmGr/55SyTohWUdwVPUaPAVPW5kB58Sen4V5uTu01\nlQMkLCu0RTvjx4QVwq6YXWoj44ePJ7llz1EuOmWUZ569viLu7Ly7x38J1+2APV91HvPzR2eIBH08\n5Yx1fP/BKb5424ElrYEjd6G0+YK8YHiZm+TmG+Tcgel155FzF48EGFfmcYHhdY2fOzIKaBOuq50r\n62ZiO6SmqvKx2u5ztzCFRnGSEc7b3CD/rxFWxewQi5hSkZmrJMCDcaZ8wa43Md5nNbm+59DqTMqw\n37d12mplE9/c+M6hYc8+d2AqKzO9nJ+1SGaS5v1ZPxxxtk2GbHHn8T8XHV9dcWeHIAORqs3H0jX7\nF0E42MMjyGrnytoEY1AuQEmyo4TGiLjrIqPR5Wlk/E8/2IvW8I7fOQulFDtPHUMpKvl0h+8wl/t/\nCpiGpQ8fX+CybRN85KqdjMWCvO9bD/DI8SUc9O3fAZwVWuYv/nwK/OGqBqYOoZjZX3PAHQoHGMOI\niHBtl3037kbGCctJ8po76syY3e9sijl97loVVBwjFRinhJ8dHYs7c/9htYj5spnZyusDy5mKdz0s\naxfd3Ht4flWEkv2+jZUscefVBsUmNNww5y4a8qM15JfBae8lZmqcO4DxkPU3XesagRF32Tnjdq8G\nHg6W1pqjKSs6UFy8cxcJWs2pezEs28i5s91UaWQsNEHEXRepOHeLr5jdO7XAf95zhPM2j3DFDtOh\nJh4Jcs7GOHcfmjMhX7vKc+p+wLh2AE89c5KNIxE+8NKLyBXLvOOGuxb/JXfodufqKb6ZRb8eT/Ip\n75AsmC8+XYJS9XsY9PvYEDAH6diYx1xZm4hr3ur8ISOGwh6hU48Zs36fIhL0kW4Zlp1iRhmRde4i\nnbs4mc7CssW8ycuJ1uQbRka6Hpa1xd3JVJ7DcyufGG6fPMULZs5wU+euSVjWCeHlB0vcTScro8ds\nJoLmb60UaCDudLmhw7nseMyVTWSKpMpWukFxCc5dwHbuevAzbRaWBQnNCk1pS9wppWJKqbOVUufZ\nPyu9sLXA2DL0uvvkrZZrd8VZVYn6l5w2TrZQ5oGjiYrbNPUAaM0vrHy7p5xhwpXPOX8Tr9z9BB44\nmuD/+/ZDi1vIoTvJ+k0IZ11patGvx5O8xwBzmyYd2zcEzJf+qNfoMRv3lIr5Q/X5djYe4g5Mr7tU\ns7BsPgX5JIcKI2xbF3P677WNJe6GyXT2d+I0MB6r3h4e6apzl8oVOZbIOrfvXYXQrB2WjeZscdfM\nuRuCUs4z5BW1wvCD1g5lZiHHWMyMHrMZ85v3LK0i9Q9Y7XYojririJyZVI4Sfkr4oZBt8MDW9LRz\n1ywsC+LcCU1pKe6UUm8FjgPfBb5l/fzXCq9rTTDuMV82Vyzxms/8ikv+7ru84XO384lb93LbYyeq\nmqdm8iUOzab5ySPTfOOuw5yzMc6zz6s+YF36BFdRhT1ZIZeA+YP87NEZRiIBzt9SaRHyVy/YwemT\nQ/zrT/fxk0emO3shiSOQPMLd/gtI6ihDmWVuoJxLNnbumsxaXO83gi862kZYdvaAqZL0yreDhuIu\nFvY3d+5cDYzP29KhaweOuBv1ZZpWP9fhNDCude5GjaNX7s7BzJ5gcuYGI9bvObw84u79//0gf3/L\nA5777P+vUMb6u24alrXn73rMlw30cH7WEjCjx6qbOo/4zXu2UPZo9rzajYw9nDu78XLRHzYVpYsk\n0tMFFdYJa7BB83YRd0IT2rER/gy4QGu9xIx7oZZRZ76s+SItlzX/5z/u4ccPTxOPBPj+g1N8/0Hj\nggV8ig3xMLPpQl07hrf9zpl11amVitkTvG7ucWf79KO/4eDJAM8+byN+12NioQAfu/piXviJn/KP\nP9jL085qEsqs5ZDJt/tR6jQ2x44TTxwyOXCdtPxoRj5V3+POxnHu6r/ofnurD/YD0SbVsnZY9rhV\nEN5I3I2dBijPKRVHmoUWrQbG04yxY9NixJ153RsjBfZ2Epa1+5BFPJw7MEK/VvitAnb7kxc9cQsf\n/u7Dy+LcHZ7L8P9+/Cj/P3tnHSZZeW393yntrnbv6Z6e6elxF5gZGGBwDRpISCAJl5AQIW4EvtzY\nDTd6IzeXKERJgoQIEtzDADOMu7e7S3V32fn+2OctPSWtg9R6nnlquupU1Vt2zjpr77W2VdP4/AUL\nguVThR63hxynDctgq3wXzKZTKIRn3UW5rJVy91aKQ1GjxxaWR7Yi5FikVNsfcBJTxJ525U6VJ8PJ\nnawvYBkjueupg+33wJm3gtX2xo5CiavcpcuyaSRHKuSuNU3spgahsqwctH/w5EEe2tnMmln5/PnD\np9A37GVbXQ9b63p4va6Htv4RakqyKMp2UpzloDDLwZySLN6xPLaHaHaRi8IsB411R6UfzZkHo320\nHNoKrA+WZMOxfGYeq6ry2VrXQ5/bGySfSWGYKbbr87i+oBXaj0tZcDLIg88jzrC4yp06i40ty1Y4\nDNKVaB1KhWhNQu7sGXKbyZQKt0cclKb5dYZy167nc8a4lDu5T6ndMzZDRTzlTvUTjpwYcqf67VZW\n5TOnOItdjb3x37sU8eDWRnQdfLrO4bZBllVGhlb3ur3kZ9mFaMf7fBUSjCBTJbw3pMozTigFrCQn\nsvyabZC7Xp/JPmC6g4xNy7Kybt2WMTZy9+8fwtbfQfVpUHPWm6TnLioz1J5W7tJIjlTI3VOapn0P\nuBcI/op0Xd83Zat6myA/rCz759fq+dnzR6kucnHXDWvJsFvJsFu5ePkMLjYhb8mgaRprZhUwdHA7\nOID558Oev+Jt2QOs57R55qXKcxaWsr2+lxcPd3DZygq58rVfiYqx/BrzJ2vcSgCN/dRQXNkC7S9A\nb8PkkAd1kE3Wc2cWhzDcLaG0GUkmVAC0SUZfwoN/QTXUvhSRlp/ltOEL6Hj8gRjFCIBBUV479PwJ\nlWUL7aP093nxB/QIxTUuwnrudF3n+YMdnFRdQO4Jzro71qnG02WxvDKPh3Y2U9/tZnbR+CaaBAI6\nD2xtCP69r7k/ltwNe1hWYofuPsg5OfEDqpMFE1OFKsu+lebLhkaPOSKud5EKuTuRZVlZn2bLGFug\nb60xRdNQ1EOEfZI/0+e+Le7+jV8Y/2MEyV10WTbdc5dGcqRiqPgA8C7gQdI9d5MK5ZZ96XAH//nP\nPRS47PzuxnUUZjmS3DM1nDS7gCrNMDfUnIluzyK3/zAlOc5gz1M0zl4kjtvnjHIw3hF4/FZ4+DPm\nZYCAn0DzNg4HKlk9fxbOotlyfV9D7LYK3hE49ERMfIkpguQuSc+d2doG22VIfCJVSJUtR43yYDxD\nBYTFoYSE7FDWXZyDw2Cr3O4spjzXpDk9GRS5s42i67CjoZeWvmH6R4ToxUWYcvev3a3c+LstfOmB\nXSd8SsWxjkEy7BYq8jJZMVNI2ETy7l493kVD9zCLjLLi3ubIxxrx+hnxBpjtMF5vvABjBaVsmjhB\nM96ChgrllI3uucvU5Ty+x2tC7jKmu+fOrCwryp3myExduRtsh67Dxv8jyd2obxKVu0AAXv4xbP71\nxB5nssqyug6P3Qo7753YetJ4UyEpudN1fY7Jv5rpWNxbHXlGWba2y43NonHXDWupLp68mawnzS5g\ntiY7MQprGClYwGy9idNr8uKWwZZW5FKW6+T5Qx1CHjoPhWIPDphw+vb9WLxudgTmcemKCsg3yJGa\n9mCG1++GP78b9j+c/EUEp1PEU+7ilGX9XuitD82FjYdoVS+RcmdiqshKknXn7RNyV1A6c3ylR4Ns\nFFjlAHb1zzdx6refZcXXn2Tu7f/ijO89y8FWk0gKo2QWcObxk2cOAfD43lbq3YZYfwKCjHVd53jn\nENVFWVgsGssNhW13AlNFfZc7oarywOvyPbv9ksVYLRr7WiJJqzJTVNmN15uM3Dniz5cNNt+/hZS7\n4FzZKHLn1EUt6xp9gyp3Q7Ju61jIXd2m0P8NcuecCpPMQLOsabg7tRPYeIhnqBhrWXakD177xcTJ\nZhpvKqScc6dpWqmmabPUv6lc1NsFGXYrWQ4rmgY/vnZV0AQxWVgxM4/ZmuEQLJhDg70ah+bnwrL4\nqo2maZy9sJTuIQ87G3slPkVhx59i72D02+1hHucvLYM846sRZuKIQcsuuTz6TPIXkWj0GMRX7nrr\nJf+ucG7ixw+PCtGsiQ/+QXJ3NHiVy6nmy5ofHNxdEoxcVjE78TriwSB3K0psfOysuVy/fhZXrKrg\n3EWl3Fx+mH8MfYCfP/h4bBiwceB9uTnAobZBVlbJ63zkgKGEnoCybGv/CG6Pn7klQqCWVuahabCr\n0bx3q6HbzXk/fIEP/f5107Dj/hEv/9rdQnWRizPmFzO3JIt9zf0EwhRNlQ1YYTWISHYy5c4gdyZl\n2bdiFIoqy5bkRJG7wDCjuo2eURNykhkW/D0dMMl76xz0oGkGufN7UnN/R5A7qUxMSR9ll7F/8Hvi\nzilOCfGUu7GWZd0SfUV/8/jXksabDkl77jRNOwf4PVAG+JEOri6gdGqX9vbAN65YhsthHVdfXTJk\n2K0sdHYy6rWjZ5aybaSCBcDazNaE9zt7USn3bmnguQPtrLEY5M6ZC8deMLLgQupW3+FXyAPss9eR\nm2EP3ZaoLNtpZOkdez75i0i55y5KaVE72KIkIrPdJSO5Al7IrQSLSd+cQpDchUwVQeUuTtadr7+V\nId3JvJlJSEU8qAkVuLn1okWRtz30B9g2QH7zizy253QuCf8OGT13v9rcjUXL5MfXruJ/njzI/j3I\nL3hkekZ/heN4R6jfDmT+79ySbPY0CSGLdnw/uK0Rjz/Av4908pfNDVy3PvKc8uGdzYz6Arzr5Co0\nTWNpRR6H2gap63Yzx1DAFbkrSTZXVkGdRJgaKlTP3Ruw+X6ciFeWtfmHGSIj6OSPgFLuRqaJ3Cll\nLqrnrsDlwKKu843EPwFUqNskk278ozJKkCkaPxZ28oe72zwUPRWYKJYRf8eZpBKDISNUfrAV/L7Q\nrOk03tJIRbn7PnAusBdwAR8BfjWVi3o74ZqTZkYelCcZM/VWGvQSdjb281SXOGSLho4kvM/p84px\nWC08s789pNyd/hlAj+nb8NZvwa07WX3yqXJFdhlYHfHLsoEAdEiZkJ7aiHFephhN1nOnDsZRZ7Fq\nB5tMudO0UGk2mZNSlXjDyrJqBFk85c4+3D5+MwWEDgxmZVTD4bvSepw7Ht0feYAylLttHXDFqkrm\nFGdx60WLGLbI++V1Tz+5O9oZSe4AVlTmMTjq43hX5IEqENB5cFsjmXYrORk2/vtf+2OmWdz/eiMW\nDa5eI5/bUuM9Du+76zPKskWBFObKQsKcu8ypar4/geg0etfCR48B2Hxuhsgwn3utfi8nsuduyENR\nlkNc7JB8BNlwj8QdVa2T9Ucpd5Pac9cVIne6Us3Gg6Rl2RQnc7gNcqcHguXoNN76SKksq+v6IcCu\nC+4CLpraZaUxKRjuIdM/QL1eyh9erWPbiOF+bU9sdM5y2lhfU8i+ln58rXshqxTWfkgGd+/4c7CP\nRB/pp9B9jL3UcO5S47EtFlHAeuMod/2NstOyGL08x15I/BrU2WmynLvoEkVQuUtC7iBUZkoak5El\nZb3wnjujLGuq3AX8ZPl66SQ/WIocM2xOIcvRZCPgDxLv07Maaeod5tcvhtalD/fix8KwlsEnzpkH\nQFWhi40r5P3YdTSBsjpFOGZk3M0pDr0Xyw1TRXTe3WvHu2noHuaS5TP4z0uXMDjq4/a/7Q6WZw+2\nDrCzoZczF5RQnicH+CXGaLd9zaGSc2iurHGQTTSdAiJz7qJvsr8Fy7Imo8cANO8Qw7rTnNxZDAf6\nCZpQ4fUH6HV7Kcp2yD4pfJt4qH8N0GH2BjkBncKeO29H6OS5uzNxlSQhJqssOxQ2DjJdmn3bIBVy\np37dTZqmXaZp2nIgQSpsGm8YGKpYnV7Gv3a30EMuI85iaEueYnP2wlKyGMbW3wCli2VnvvgyUcSM\nObK1u1/Ggk5v4YqgggUISRpqNx8L1GGUZJdeJZfJSrPJyrJB5S7qYBxU7lLw/qSq3IGQxb4Gyd8j\nsXLnG+jASoARZ3HEaKcxw5kTS+66jgZnahaP1DEzK8DPnj9Ka5+850N9HfTo2Vy+sjKCWL7z1MUA\nHK5vDpbkpgvHOkyUuziO2b9uFeX3XSfP5F0nzWTjghJeONQRvP6B14WcvvvkkLt5SVC5C5G7XmNu\nc47XIHeJplNAwpw7l0Hu7tvSwH1b6t8SCl6HyegxAM3rZsSSEVQ+Y5BZcMIMFT1Gxl1RtjNE7pKZ\nKuqMCJTZG+Rk1d0Nfu+UjB8LdIaUu9bWCZCpuLNl449cNIU7nNw1jX89abypkMoR5yeaphUA/wn8\nCHgW+OqUriqNyYFB7nqdlUHTlqV8KfTVJ43COGdRKfM1Y0dQaowSXnWdXBrGitpdLwJQvPC0yDvn\nG71RZjuSjgNyuegdovAdf0FKtfGQzFCRSLnLLkut3yUjReUOpDSrB6BX4lCCyp2JW7a5qRYAPVmf\nVzKYkTs1UcOehaYH+Ma6AMNeP999/ACBgI53sId+PYtPnDM/4m7ZuXJelhEY5EdPH5rYusaIY52D\nFGc7pTfTwJIZeVg02N0U6t8aGvXx2J4WqgozWVddiKZpfPudy8lyWPmvR/bR2OPm79ubKMxycO7i\nEFnLdzmozM+MJHcGOckcaU8+nQIS5tytrMrnqtWVNPYMc+uDuzntO8/ywycP0t4//vFXJxpmo8fw\n+8A3gseSaa7cgUHuToyhIlhKznKESrVJyd0msNhg5lrILgV0GOoMkbvJMlQE/Nj7a4N/9kxIuYuz\n70uU7WmGobDScFq5e9sglSiUv+i63qPr+mZd1+fpul6i6/o907G4NCYIo/E/o1RKcQvKsnFULJfb\nwl2wJqguzuK0XOlL8RYtkCvnnAk5FbDnb+geN5amrQAsXnt25J1VVpyZY1aRu5JF8njuLmjfG38h\n48m583lEXUvWb6cQLMsmyLhTiIpDUYYKs5y7poZaefiCCfZUJiJ3hgJ6dm4zyyvz+Pv2Jr73+AGy\nAwNoroLYPEPDoFHu8HDv5noOtU1PJMqI109jz3CEagfiQF1QlsOepv5gbt+ju1twe/xcvWZm0GRR\nmZ/JbZcspn/Ex7W/fJWuIQ9XrqqMUZyWVOTSOThK+4CR02aoPI7hjuT9dpA4585u5UfXruLft57N\nx86aiy+g87/PHuG07z7LwztTOGi27ILmHcE/vf4AOxp6p+0ziIbHJ+XN6BgU1evls7rik7uMfFGO\nUyUYE4F6DkOlUzEootwZazerEiiMDkLLDqhYbbRWGCcEg22hsuxkKXd9jVgCXtp02acM9bSP/7G8\nw6BZpC0jHGOLTaxVAAAgAElEQVQuy4bNCk8rd28bJCV3mqa5NE37lqZpfzb+XqRp2pVTv7Q0Jowe\nIXels8VluWFucUiFS0SoDJyRL3L+Hm+lXGGxwsr3wGg/tS/fzyL/QfpsxWQURSXjJHLMdhySM+jC\nGqg5S65LVJodT85dT62oa8mcssH1VgEaFM9Lvm0UuVNRKIMmPXfdbfL6C8pSII2J4MwVshGucKpx\naauvB8DSupOvXiaf7R9e3Idd81NaalKCdGQDGgsLIaDDp+/dERx/N5Wo63Kj6zC3JJakL6/MY9jr\nD86dVaVXZZRQuG7dLE6tKQoaK969NlZpXRpVmu0d9pLJCBZPf/J+O0iYc6cwIy+TWy9axCu3ncN/\nXbkMr1/n3i0Jon8MBO57P6P3vIcfPXWI6379Kiu+/iRX3vkyV9758gkp8SqSVBwVg6JOlAI2F8Ne\nv3nJcjqz7qIMFSrAWHrulHKXgGQ2boaAT0qyYCh3wGD75EehGO0g2wKimHsGOhNtnRjeIdm/Redj\nTqgsm1bu3i5IpSz7cyQyZaXxdyPwtSlbURqTB6Msu3HdyVywpIz3nTIbygxyl0Lf3UKLHGQfbw/L\n3zNKs67X/pcyrZfR8tWxd4wXZKzr0nNXOBdsDqg5U65PSO6S9dyZKHepOmUVzvgcfOiZ1Przoshd\nqTGT89kD7Xj9kQeIoS7ZkZaPN+NOIagmhZUK2/aIElW1Xt6b5h2srS7kspUV5CPbZeWVxD6WxQLO\nXPItw7zvlFnsb+nnht9spn9kDHNrxwFlpqgpjv0cw/vu6rqG2Hy8m1NriqgqjOw1slg0vnv1ClwO\nK2tm5bOoPNaBvLRCHkuZKnrdHsqDMSgpKHf2TFFLTMqy0XA5bLz/lNlU5mdyqC3J9h43lt5anO4W\nfvXMbjYd7WJWoYt5pdm4PX6OtE8gD22c6BwwyptRo8cUaQgYJ06m6l2W8d0KV4WmCt5hMWBZpZyv\nsvmKspxhbtkEyp3Kt5t9ulwqcjfUHhwpN2nkuiuS3FmGu2P2CynD4441U4AoeZp1DGXZTiHBmjVN\n7t5GSIXcrdB1/cuAB0DX9cEU75fGiUZ3LeTMoKQwn1994GQp0ZUskoNXEscsQP7AEZr1Yh4/MhR0\nKQ7mzKHetZSyEdmJFS7YEHvHYFk2SrkbaJUxXyUL5e+ccllP3aagQSEGyXru1Jl7eIliLE5ZEEPF\nzJNS2zaK3M0rzeadayrZ3dTHz58/GrFpoF/6bbKKKlJ77HiIjkNxd0t5pWyZqKnlKyQ70DPEVy9d\nwvUrDdITHtAc9XjayADfvHwZ15w0k52NfXzwt1viZvVNBo6ZxKAoLJ8p69zd2MuDhmp3zUnm/Y+z\nilw89bkzufuGtaa3L4mKQ+l1e5mTYRCnVHofNU3I8hjCZxeUZdMxMJpQAfWEOSh/c3kJO756Pk98\ndiP/saEagANmU0amGPECjNVr143fXL8ZuVMq6MA0RGt4RyJMBd1DYaQ06JZNRu40mLVe/g4ry9qs\nFqwWbfKiUIz9wl5NWlly9QFqO8cw+zYcXnesmQKM72hW6jN13V2QXSLf/7c7ues8An95b0RW6VsV\nqZC0CEudpmkZKd4vjRMJn0diRwqixm/ZM4WgtO1NPBrH3Y022EpX1lzqutwc6xzi5SOdXPijF/lF\n3ynBzWxVJgfZeGXZ8H47hZqzZCdmOHBjkCznzmKRHWB4iWKsyt1Y4MwRt11YltXXLltKeW4G//vM\n4SCpaB8YIdunHJoTNFQo1VKRO9VvV75MLitWSRm6dQ8lOU5uOUXyDIOls2hk5MJoX1AJu2xlBa/X\n9fCh378+ZeVBVXKtMYmEWVSeg82isaOxjwe3NZHlsHLx8vjvWWV+JgVx5i9X5GWQ77IHlbset5dq\nNVc21c/BkT2m8Wzzy4R8J1Lv2o7vCf7/1MIB8l2y/sUz5L4HWqZ/YogaPRZjqDBOlCxO+c31mjlm\n1Xs5OAHDQKrwuk3nyqbklvWOQOPrUL485IoPK8sCZNgsk6jcCYkfzJ+Px+qiUBsYP3H3uBMYyTJT\nmy2ri3EEVzHkVshotEQGtrc6DjwMB/8FT37lRK9kypEKSXtR07TbAaemaWcB9wP/nNJVpTFx9DXI\nAb+gOva20iWSLj/QEv/+huHCXr4UgFv+tI3r73qN1v4RKk67Dt3qFAWwwqQsa3PK2XEMuTNiUJRy\nB2KqgPil2WRlWRByZ6bcJZsrO14U1ohZxC8HvbxMO9+9ZgW+gM7n79/JqM/P/pYBSrQ+Alggq3hi\nzxet3Kl+uzKD3M1YJZctRrO+cjFmxFPucuWxdB2rReOH717JhUvLeOVYFzf/ceukxkIoHO8cwm7V\nqCrIjLktw25lYXkOOxt6aeod5h0rZkRG64wBMqkil9ouNwMjXnrdHirtBnFK1bXszE69nwmYb5hW\nDrfHP4j3NR0M/RGmGiwwiOGJUO5UFE6MocJ47RYj88+0LJs9ncrdsOlc2aLsFNyyzdtkIsXsMEd/\nmHIH8v2bLHIX6DxKt55NfmEpgYwC8rVBDrSOk7hHkdoI2F2plWU9g/L6swxyF/BNTyn9jYo+w1By\n4BFo3Hpi1zLFSIXc/T9AAwaA7wGbga9P4ZrSmAyoA4gZwSlNoe/OKNtWLFwDyMFnfmk2f//4Bj5x\nycloF94BZ98eP1w4r0p+SOFniUHlLozcVZ8mvSDH44QZe4bk7DzRyBy7K6rn7pj0VyUbRzReFNbI\n3NowN/CZC0q4bv0sDrQO8JOnD7OvuZ9SevBkFCUeaZYKDIdrcB5sm2GGKQtT7iDkxFRN7omUOz0Q\nPIjbrRZ++t41nLOolBcPdfDFB3ZNbL1R0HWdYx1DzCp0YbOa73JU3x3ANSdNzICi+u5er+3BF9CZ\nYUlx9JjCmMuyQtAOJ1Du/GFlWWV0AsjJsFNVmDl+AjABJCvL2jMSkDtVlp025S5yrqzDaiHHaQtz\ny8YhOuH5dgquYkCDQSE5GXbr5JRl/T60vjpq9XIq8zOxZhdTyAAHx0Pc/V4ZiWhWloXUy7IqwNhV\nLNFT8PZ2zIa/9me+fsKWMR1IJQrFq+v6Hbqur9d1fZ2u69/SdX3qmnPSmByoA4iZcleWgmPWUO5y\nq5Zz+yWL+MIFC3jkU6ezwuiPYt2HYeMX498/v0p2TuE7/85DovYVhblSM/Kg8iQpnZhl73mGkpM0\nhyu0o/OOiJFjKkqyCiYzZgFuv2QxVYWZ/OKFo/xzRxMlWh+WZKG5qSBauWvbLTMy1ftYNE9cdUq5\nUzM/E/TcyeOF3m+HzcLPrl/D6ln5PLSzmSf3Tt5Bu3vIQ9+w17Qkq7C8UtY6u8jF2uo4pDRFqEkV\nLx+RA1sZBtlNmdxliRLkT203p+JmEkWaZA4cJ6AbrseokXsLy3LpHPRMe6h0MC8uRrmTEyV7pryu\nhGXZgekgd5HKXcfAKIVZDjRNC3PLxnnvgmaKMHJntYGrKGJKxaS4ZXvr0AI+juvlzCzIxJ5dRKbm\n4VjLOByzSfM9UyzLqvFnWUUhQ9Hbue+ur1EI87zz4PiLcPS5E72iKUNccqdp2scT/ZvORaYxDqgD\nSHTPHUCplFoTKncdBwANShZy88a5fOKc+ThtY1Cggn13YY7ZjgNCNqNLDTVnihKmzrLD4RlMTu7C\nlbueWkBPPQZlPDCZMQuQ7bTx/WtWEtChvrWDbG0Ee/4kzA0Od8v6fdB+QKaGKDXTYoUZK+T99biT\nK3dKCYwi0xl2K9+7egV2q8ZX/7mXgUly0AbNFMXxP8fT5hXhsFn44Glz5KA9Aag4lJePyoGtUDfm\nyqZKtM3cyQmQ5bQldcwWjzbSrJVJkHLUSYHquxuXwjMBdBhZgEVx3LJOl7yPpsqdq0gijaZ6VmnA\nL2VFY58x4vXT3DfM7CJD0VLKnVkUit8nY8eKF8a2RmSXBXvunHYro5NRljX2B7UBIXe4pPfV3dth\nGpWUEPGmUyjYXXLy7E/yG41Q7gxj19ud3OVWwrnGHIZnvpG49/xNjETK3f8BNwInA2uj/p089UtL\nY0JQ5M6sLFs4R8544yl3ui5l2cKa+D0fyZBnZN+p0uVQp5xFhpspFGrOkkuzObOewdAw93hwZMkB\nIOCfWjOFQlC5Oxpz0yk1RXzwtDmUGPEb2mQrd12H5bUqM4XCDGWq2J285y4jqswbhvllOXz8rHm0\n9o/w/ScOxtw+HgRjUEycsgqzi7LY/fUL+MCpE4yNQUwbGXYL+w2TQp6vK7XpFAoJRpDFw4KybDoH\nR4OhyeHo6e6kkD56Mqvkt9dbL99VAyrSZbpLs52DHvJdduzRpXLjdWdkJSB3FosYi6a65y5q9NjR\njkF0HeaXZUdcb+qWbd0pin71abG3ZZeKc987QobdMjllWaPXt9ZQ7siUaTCF2jhKs/HmyiqoE95k\nQcaqvy4rXZaVE99uyKuEGSth6TuheTvsf+hEr2xKkIjcfRAYBJYBrwOf03X9RuPfB6dldWmMH93H\n5SBlnD1GwGKVvreOQ+alp8E2UX9KF4//+YNZd4apwqzfTmHmWiGb0aYKXU+tLBs+gmysMSjjQVQc\nSjS+dNFC3jnfUNWUM28iCCd3QTPF8shtKsJMFakqdybkDuDjZ89lbkkWf3y1jq11Ew+pDc2UTWCK\nAZw264RVOwCrRWNhWAZetrcrtYy74EKUO3kcfXcmeXUNR3bLw+XNESU94I04wC4sl/vub5le5a5z\ncDTWTAFB5S4zW9YVd0pFTpm0XUyl8hFF7lQe4PxS4zeRyC1bq/rt4pA7gKF2nDYLHn8gOCFl3DBO\n9o7r5VTmu8Al5C5fGxw7uUuq3BmkNllpVgUYZ5WElLtERrq3MpRimWtUlc75ivR7P/NfKbdgvJkQ\nl9zpuv47XdfPBq4FSoBNmqbdr2naimlbXRrjg66LclcwJzbdXKFsqShAJupTMANPGS/Gg+iyrCJ3\nxSbkzuaUnpiO/ZFKgN8j7q5Ueu5AdnTTodxl5gtpjkPuMuxWPr3eIBcTnSsLkWSsTYiCqXIHYqpI\n1nOnIiHizBd22qx85+oV6Drc9rddeCaoahztSF6WnWyo0mwmIzh8A6lNp1BQ37cxKHehOJTYg3h3\nvfSvOkrnh3pgw/ruqotcOG0WDrZNn3LXN+yl1+2lPC8j9kaDWGRl5wW3NUV2ufxGp3JKhSq3GiRH\nmVaUQzkhuWveLpdV62JvM5lSMWGXuHFi2WSZQWmOM3hiXcAgB8eqyqZSlg3fLh7Cy7Jv9567fuNY\nlGcomEVzYc37pRqy8y8nbl1ThFQMFceBHwE/Ac4CTH4pabyhMNQh5YiCBCWuoGPWpDSr5s5ORLmL\nDjI2i0EJR81ZcvnQJ6Bpm/w/WcadQvgIsqmOQVEorIGeuvhnfEY/z6Qrd0Gn7NLIbYrnh0wVwz2y\n849XhjQxVERjbXUh162fxaG2QX75QugEoM/t5a6XjrHxe8+x6ptPcudzR3B7Ep/1HuscJC/TTmGc\nbLqpgCJ3pWOZTqHgGFvPHYTFoZiQO2/7YQAKqhaH9WuG+u5sVgsLynI41DaIb7zTDMaIHQ3yvoS7\nlIMwXrcrOw+rRUus3MHU9t1FKXcqbmZesCybIMS4t14mW+SaBGKHxaFk2CZpBFn3UbrIIze/SGYi\nG8r5uLLugoaKCZZlww0VNoeU0t+uZVkVg5IX9n0481Y5QXj+24mDsN+ESGSo0DRNu0jTtPuATUAZ\nsF7X9bumbXVpjA+JYlAUlGO24bXY2yZDucvMF8WpL4rcFS8w337VdZKZd/hJ+PXZ8LtLJXASQmQk\nHiKUu2OyMx9vr2CqKKwxymuN5rcrF+FEA4whtiybOzO25Bpuquhvid9vB3ENFdG49aJFlOY4+emz\nR3hqXxu3/W03p3z7Gb716H7a+kfQdfj+EwfZ+L3n+f2mWlOFz+sPUN/lpqYka1JKrqlCOWZLMcjd\nWHofx1GWnRfMuou9j71Pfo/lc5aaKncgpVmPL0Bt1zinGYwR2+tFbVszy6R0bxALzZFFXqY9/uSN\n6XDMRilYh9sHyc2whcrJtgQ5d30NotJYTA5zQXLXjtMut09IufN50HvrORYok347CJZlq10jHGgd\nCE75SQnB153ALQvJy7Lhyh1Iaba/+S1rIkgIRWpV7yHI+7HuZrlt9/0nZl1ThETKXSPwX8CLwLuB\nB4BMTdOWaJo2gaN+GlOORE5ZhapTIKcCXv8NdB6OvK39gJzxTrRvLa8qrCx7UEwW8XLxsorhw8/B\n+/8Bc8+B2pfg4U/Lban23Lm75Ec6lU5ZhSR9d1Oi3HUflx6n6JKsgjJVDLXH77eDMEOFiZrQeUTI\nIRLO/I3Ll+LxB/jwH17nL5vrKcxy8OWLF/Hqbefy71vP5lPnzmfY4+NrD+3lnP95nns319PaFzrQ\nNnS78QV005myU4lF5blYNCjTVAzKWJS7sZdls5w2ZhbEOmYDAZ3CkQa82LAXzg79JnsiHbOLprnv\nbnu9kN5VVSYnAcFmfiF3fcNxlNlpVu48vgB1XW7ml+WEThSCbtkocucdkXXlzzJ/XDUbd7B9cpS7\n3jo0PUBtQDLugGBZdo5rlL5hL239Y4i6SWaosKeq3HWKMqW+07mV8l4N9/D1h/by7cf2p76mNzvU\nsSgvSsldcoVcdiQ2kPkDOh/83Rbu/vebY3RZohh4L1AMfAH4PBJkrKAD03AETWNcSJRxp+BwwcXf\ngfs/AI9+Dj7wkPTnBQKi/hTPDw7qHjfyZoojt6dOSMm88xNvr2kw92z517ILNv0v7P27OJsSQe24\nVMlyKvvtFBS56zoqZDQaKt9vMtyyjixAg5ad8ndZHHKnTBUQv98O4hsqvMPw63OE1N8s+U8XLSvn\nxtOqOdYxxHXrZ3He4jKsltCu4HPnL+CGU2dz53NHuefVOr78N+kJnFXoYt2cQrIccuBM5JSdCmQ6\nrMwtyaa0a4wBxhA77i1FLCjL4dkD7fQMeYLj0Rq6h5hNM92OCsosViGZVqdJHIp8JgdbB7gsydd9\noggEdLbX9zC7yCUjvKKhSK1dyF1jjxtd12OV12lV7jKp7RrCH9BD/XbG9bJdVBRK8EAeh9yFl2UN\n5W5CUyq6QmaKmQUGITPcsjMc8hoOtPab9ziaIVnPnSPVnrsuUe3UZ2eYKka7G/jjq024HFa+fNGi\naVXVTxjMlDtIuRexpW+YZw+00zfs5abTp7jtZxIQl9zpul49jetIYzxwd0Ptv2HRpZGlh1TKsgCL\nL4f5F8LhJ2DX/bDyWilleAYn1m+noByzR56Sy3j9dmaYsQKuvgve+ev4phAFtQNsNcwGU+mUVYgT\nZBzEYJuQhHhK5VigacbIMJlbm1C5U0ik3CklMLosW/+KPEfzNiHkBbPRNI2vXbY09jHCUJTt5KuX\nLeGmM+bw8M5mthzvZkttN3/dGipZz03ilJ0KfOTMucx4LQDtjI3cBXPuxlYinV+azbMH2jnUNsD6\nGlFtjtbXc47mpienWjayWKQXNqosq5S76YhDOdY5RP+Ij3MXxznx8AwJAbXayMu04/XrDHv9sSPh\nplW5cwXNFPPCyV3QUBGlivUZEUz5caadhJO7XGWomIBy1x2KQTk3Srkrtsj36GDrAGctTFHJn0y3\nbPH80N8GuWuoO4I/kMHAiI/uIY85yX+roa9JzGTR++TsMgnXT+Iiru+W93q6w8bHi/ENcEzjxEPX\n4b73SfDv6vfBZT8NEbyeWrF45yUZ46RpcMn34c4X4YnbYf75k2OmUFDPf+QZuRwLuQtfYzI4osjd\ndCp3icqyk1GSVXDmhMhddAyKgjJVeIcS99wpt2y0chee1n7gUTh1bFnllfmZfPTMuXz0zLkEAjoH\n2wbYfLyb9oERzl5UMqbHmgxcc9JMqPWOndyNI+cOwhyz7YNBctdRK78nS/gBtmCOTGsZ7gmS8KJs\nJ8XZzmkpy6p+u9Wz4nxHvKGB9XmZot73DXtjyd20KHcGubNlBM0U6n0GZP9gdcaGGKt8zXhl2cwC\n2UcOdeAsnEzlbkao587hAlsGObr8zsYUhzIZZVnPkNyu+u0gqFp1Nh0DpLuqtmvo7UHu+pvMj4lW\nmxC8JMpdQxi5M1Wy32BIZbZsGpMBXYc/XAlPfU3y3CbqzNnzoBA7zQrb74GHPxWa49pzXEqiqZRV\nC2bDWV+WM7xnvjE5ZgoF1dugwonNAownA2pH12EQ0+lQ7lyFQqDMyF3AL47lyTBTKCg1ye6Kr8ha\nrFBuEL+EZdk4btmjz4HVAWhC7iYAi0Vj8YxcbthQzRcvXDS26SaTifGUx1WZfwyGCpAgY4AjYY7Z\nkbZDAOTNDDuxiWOqWDwjh6beYfonaTJIPGwz+u1MzRRgZEvKa8l3yT7EfARZKTKjtT3mJn9A59Vj\nXXzz4X2851evUDdeo0iYgnW4PSoGRcGeEavcKZd+vBNci0XWP9iG06567iZA7oLKXRmVBWFmrsxC\nnJ5eMuyWsTlm1TjFeIaKVMqyykwRPp3DUO4GO0JzsVUO5bSibtPURuhEY6RP9nd5lea358wQ5S6B\n0UQpd8NeP0OeSZhoMsVIk7vpQk+tkLGXfwx/uAK+Ww1/fCds+r+YnXxSjA7Ck1+RM9YPPyM9adv/\nCI98Wm4bbBtbFMiptwiZ2/o72P2AXDcpZVnjrFntqOI5ZScKtaML+EReT9RrOJkorBEiHYj6obfs\nFGNDvB3JeKBKCaVLhMTFg+q7S0TurHYhieFl2cF2ydCbvUFyweo3hQ4Ob2YMtI5tOgWElWXHpqKF\nZsyGSKHVOOjnVoaRO5M4FAiVZg9N8Riy7fU9ZNgtwfDkGISN/AtX7mJgtRszWoVAj3j9PL2vjS8+\nsJO1dzzNe371Kr95+TivHuvmX7vHqe6pk2B7JkfaBslyWJkR3bdmyzTpuTPIXbyyLBjkLpRzNyFD\nRdcxuixFeCyZlOeGrc9VhObuZn5pDkc6xhB1k1S5U2XZBMQsPMBYwSB3gb6QSjVdDu0guo/Dby+B\nZ745fc/ZF6ffTiG3QjIbVXSMCeq7Q9+x9v43fmxKmtxNFwrnwK21cP1f4ZRbhIAcfQae/H/wv2vg\n7x8Tp2IqeOkHcpZx2qckPuT9/4DyFbDtD1KqhbERHKsdLv2x/L99n+ws88dw/3gIP2vOmZGYcEwE\n4X0peTPHdiCfCAprZIcQnRv1yv/J5arrJu+5FOGIzreLRtV6uUxWknfmRip3ajpIzdmw6B1CTg89\nPq6lTjm6jpqqRaYYaBt7kHSwLDu2g57LIY5ZVT4c8frJHxGSoRVFlWXBJA5FTBX7TcjdiNfPpqOd\nkXEaHYfgNxeL+chAIKDzzx1N9JkpbcDgqI9DbQOsqMzH3r47pHCFw+MOkoqE5A7Qs8vw9bXw+ft3\nsvZbT/OhP7zOA1sbsVk0rl8/i+9dI5n34+4lNJQpvzWDY52DzCvNji2H2ZyxbtneBjnRi3cwB1Fz\nvW6ykPuOOwrFOwJ9DdTp5ZTnZmALH+fmKgDPAEtKM8YWdZO0506VZU1m6ioMGUQlfEqRQe5cI61B\nV29tZ5K+vclG9zFAh4bN0/ecah+dSLmDhKVZpdzBm6PvLk3uphOOLOlru+i/4ZZX4XP74fKfiqK1\n889w51p48EMSRRIPXUdF7cudCad/Tq5zFcIH/ikE75jRN5UoBsUMs9bDmhvk/yULzbOhxorsMolU\nUY85VQiPSpmOfrvgc5n03fXUisO3fLkQpcmCInflcfrtFJZeBdc/CMuuTv544crd0Wflcu45YtAB\n2P/I+NY6lXB3wy83wgM3Jt/WMyR9imMld+PIuVNYUJZD56CH7iEPh9sGqdZa8WjOyCiWYFnWXLk7\n0BJLhL7yjz1c9+vXePZAGKnd/EtRWB/+dLAl47E9rXz63h1853HziItdDb0EdDitwg93nQ8P3hS5\ngd8rk2uilbsostjUO8ztf9/NpnYbNt8Q/9p2hNxMOzdvrOFvH9/Aq7edyx1XLeeaNTNxOaxjH7+l\nYJCXthELXr/OvFITtdGeaULu6iXqKVFrSpb0xM60y9oaexIQpUToOQ7oHPKVhvrtFAxitaJIPp+U\neypTNVQkKsu6Tcqy9kx8zgLK6ebsRSVk2q0c75xm5U4RqPb90xccrNzTZoHWALnG7zOBqaIhnNwN\nvs3JnRGCfFDTtCOapn3Z5Hanpmn3Gbe/pmladdhttxnXH9Q07cKw6/M1TfurpmkHNE3br2naqcb1\nhZqmPaVp2mHjMoFd8A2C3ApY8wH42CZ49x+k5Lb7AfjZKfDXm8zPqh//soTnXnhHpGQfJHjGwT+8\ngTtVnPd1uf/Sq8bzamJhsYTOlKaq3w4id4DT0W+nYEbuXrlTVK8Nn07NDJIqVHxJvBgUBU2D+ecl\n77fMCFPudF367bJK5PGL5kLJYiF84yA4U4rt90jZsOG1xKoFhBr9x5JxB8b3SRuzoQJCA+0Ptw2w\nv6WPOVoLQ9mzIk+W1OSYqLLsvNJsrBYtpjdrW31P0HkcdCD7fbD3H/L/5m1ycgj8fbvc/tCOZoZG\nY/PpthuTKS7yPCskrmGzEGaF4GQEeR1myp3XH+Cm323hz6/V06VJ3McD18/hpS+dze2XLGbNrAKZ\n0ID0Xi4sz+FI++D4xtgZ5KWuXxRL9f5GwJYRSRL8XhhoTlyShaDhaWG2PMe+5nGqi8pMESiP7LeD\nYBzKojx5/1ImucnKssEsxgTELDrA2EC/o5QZWhcrKvKYXeSitmtobAHLE4Uid7pforKm5TlNplOE\nQym8cZS7gREv3UOe4C79ba3caZpmBe4ELkZsOe81CT++CejRdX0eMuLsu8Z9lwDvAZYCFwE/Mx4P\nZAza47quLwJWAuoU9cvAM7quzweeMf5+c8BikSDFj7wE7/mzxIDs+Sv831p44Xuhg9jBx2WCw5yN\noeDFcLgK4YZH4J13ScTJWOEqhI/+G07/zMReTzhUeXCq+u3gxCl3ikgqcjfUBdv+KNlaS6+c3Oc6\n+YNw2jtgWOkAACAASURBVKfN52SOB85cKSn7RuUMerBVRsApErL4Ujn4H30m9cfc8zf5zv5kFfx4\nBfxoGfxwCdx5Chx+euJrDvhhizEgJ+CVObqJoCI6xpo1qGlCbsaj3JWGHLNNDbVkaaNQOC9yI3um\nEM6euoirM+xWaoqzOBg2zSAQ0Pn6Q3IALMpy8Mz+dlHRjr8gysyiS4WMPv0Nurs6ef5gBwBDHj+P\n7opVIbbV9aARYG7Dg8Y1Ohx/MbSBIgvGCVO+S/L6wsnd716u5UDrAO9cU8mlG6THc1nuSJDQRWNR\neQ6+gM6xznGcKBj7vuN9BrmLNlOAkDvfcKgZvr/Z6HlNRu7ke1FML3mZdvaZKKYpISwGJZhxp2BM\nqajJEjKQsqkimaEiOFs2wQmOmXIHtFFIljbKilILc4qzcHv800tWwttYkv2GJwt9KZZl4yh3DUa/\n3ULDqf22JnfIDNojuq4f03XdA9wLRDOSK4DfG///K3CuJg0VVwD36ro+asy2PQKs0zQtD9gI3A2g\n67pH1/Vek8f6PTDJR9dpgMUi/U4ffh6u/IWUzp67A+5cJwfOx28Vd+zF34uvCmXmw4p3ib37jQBl\nqpjKsmz4qLETotwZCsyWX8tB5tRbJh4AHY3KNXD+NxObKcaCjLARZOElWYWxlmYDAWmQ7joqhDHg\nBzSw2KDrCPzpGnj+OyFH93hw5GnorQudZZuNzguH2lGPVbkDKc1OULkbbJHE+6wKkxObgjkyus4X\nOdprYXkOg6O+YInwga0N7Grs4/KVFXx4Yw0ef4BHdjfL/gDg1E/A6Z+FoXZaHv4mvoDOjadVo2lw\n3+uRyr+u62xv6OXSnKPY+mpDKrD6/CFU5osqy/YOyzqbeof54VOHKMxy8J/vWIIlWM6Kb5hQB8QD\n44l5McjLkW5RIeeblmUzhMwFDKUyGIOSmnKnDXWwtCKX451DDJqonUkRHmCcb16WzWeAwiwHB9tS\nJJAetzjX4+3HUynLmvXcAbUeiUKa6+yjulg+52ktzYarYyqYfcqfU5VlExgqIO7c3fpueX9Omi0F\nwbc7uasEwvcujcZ1ptvouu4D+oCiBPedA3QAv9U0bbumaXdpmqZObcp0XVe0uxWZhfvmhMUCq94L\nn9wKGz4l46D+eqP0c63/6OQ4WacL6z4sBpKqU6buOcLLstOp3LmKRAHrPiY749d+KflZa94/fWsY\nL8LjUNTBPbxHcMZKUT4OPSFlrmQ4/oL0Hq24Fj6/Hz63Fz67Gz6zC256Uh7r+W/Dn98VWQYcCzb/\nSi7f8UO5TNaQPWAodznj2BU4xkfuQo7ZASG1gKPEpEWicI4Qkr5IAqYmVRxoHaBv2Mv3Hj+Iy2Hl\n9ksWc8WqCjQNHt56HPY/LP1DVethwychfxYLav/EXEsLHztzLqfPK2ZrXQ9H2kOEqq7LTfeQh//I\neF6uuOT7knl49LmQ6qVec0xZVkjP1/65l2Gvn9svWSxTOMLCgONhUdhrGjMM8nKw20eG3RJb9oTQ\nfFmlYgWdsnEy7hRUDuVgW3AWsVm/YxC6Dpt+Kj3PDZtD8SuGcl+nl8X23BllWc3dzeIZOTR0pxh1\n4x1OPB/bkULOnYlyN+rzc9Atv337UAtzThS5s2dJ2kPLNCp3WSXxzXZBQ4W5cqfMFEFy93bvuZsC\n2IA1wM91XV8NDGFSftWlppG0iUDTtK9rmqZrmqY3NycOMDwhyMiFC/4LPv4KLLhIDBNn3XqiVzU2\nVKwWA8lUKolqR6dZQ/1M0wFNk4N09zGJohnuhrUfSj4L940ApxFkPNQhmVMli0NNxSCvbdE7xJBQ\n+1Lyx9v6W7k8+YOxt1WugY+8AHPPFfXtl2dC8/axrbfrqNx31qmw8CIhNg2vJR6APhHlzpGVelm2\n/tUgYXU5bFQVZrKzoY8Sj6ECFM2LvY8yVZjEoczWWtF2/IkfP3WQriEPt5w9j/K8DGbkZbJhbhE5\njS/I57LsKjkRtGfSdspXsOPjf3LvozQ3g/esFWJz35YQedze0EMh/awafEl6YGedKqX4vvpQa0Gw\n506VZUM9d0/sbeXp/W2sn1PI1WuM8/Sc5EHGyihycDyOWYOwHejyUVOcHTH6Lojo+bLJMu4Uwojp\n0kohd3sT9d217JAIqif/H9x9Pnx7Jtx1HjTvoMdWyiiOWPJplGUZ7mZZpfzm9jT1JVxW37AX91A/\nerySLIiqp1kTT6gY6hRDm+rXBQ61DtIUMNrR+5tD5G4S4lC21HZz3g9fkBObRFD9kGVLoW1fjHo9\n6dB1UeQSOaed2fI+xSnLKnK3eEYumXbr2165awLCf10zjetMt9E0zQbkAV0J7tsINOq6ruoxf0XI\nHkCbpmkzjMeageTSJ4Su61/XdV3TdV2rqKgYw0ubZhTPh+vug4++FJoukEYIVrvs7PJnTX45NBkK\na+Sg8vx35Ex03Uem9/nHC1WWPfyklJLN5uMueodcJgs0HmiTbcqWwcyTzbdxFcL1D8CZXxZl5e4L\nInu9kmHL3XK59kNyWbVOlIl4E0IgzFAxjjBpZ468L/4kZbqeWvjNRfCX9waJ5oLSHIa9fqo14/nN\nWgWCcSiR5G5heQ7ftf+a8w59g/7Nf6K6yMWHzgg5369aPZPLrK/IH2GO6D/1r2KTfwmrRjbDoSc5\nb0kpBS47f9vWFDQybK/v5Wrri1h1H5z0H0LglVqr1FtPZFk2w27FYbPQ3DvM1x/ai92qccdVy0Nx\nJCkod/kuB+W5GRNS7nq9NnMzBYQULkXugqPHUlXu2lkyQ/arCU0Vja/L5ZobYN3NYoBr2gaeAY5Y\na9A0mJEXh9y5u1lRKVFQuxsTk7ufPX+EocF+BgKO+BtpmlQsvIkMFR2i2oW18Oxp7qNFN8q0/S1U\nF8nnXKuUu5d+CP+8JeH6zBAI6Hztn3s50j7IIzsTCCUet4QX51ZIdSDgDQXnTxXc3fLdiGemUMit\niGuoUBl3swpdlOY6aX+bk7stwHxN0+ZomuZADBIPRW3zEGDkb3AN8Kyhuj0EvMdw084B5gObdV1v\nBRo0TVMNXOcC+0we6wbgn1PxotJ4g+KsL8PGL07/86q+u+FuWH09ZE//mK1xQZ3NK8elGbmbtUHK\nzAceTdwrt/2P0u+kCEM8WKxw9m1yohLww0OfTD4bE0RN2n6PEInFl8t1Ks8vUWm267BknY3VUAGh\nrLtEB0+Q2c7o0PAq7JP3cp5BQuZoLXhtWZEhsgpxplRUjh7lFIt4xL5svYdvXjgzYrrHRQtyOM+y\njUZtBnr5SkB66f6xo5nvajeiaxZ44jac+Hnnmpl0DXl4Zr8Qr2113bzX9hy61Snlc4C50eQusiwL\nUpo90j5IS98IHz1zbuRs1xSUOxDS2tI3Ejd/Ly58IwQsdvxYzc0UEFLulGNW9dwlO5g7c8WMMdjO\n3JIsHDYLe1sSEK+mbXJ5yselpP2RF+C2RrjpKb7KxyjLycBhizqkZoaRu5lCIHclUe62HO8mk1Fa\n3BrDiSYhOFxJDBVdMWaK3U19tOjGmvqbKM52kO20SdbdYLu0Tmy/J8bskwyP7m4JGlK21CaYPKGU\nMUXuYOr77pL12ynkzICRXtP3tKHbTXG2gyynjZJsJ12Do/gD0+gwHgemjNwZPXSfAJ5AHK3367q+\nV9O0b2qaZuyhuRso0jTtCPA5jBKrrut7gfsR4vY4cIuu6+pb/kngT5qm7QJWAf9tXP8d4HxN0w4D\n5xl/p/F2wRmfF3I13VDkDk2a298sUMpd91FRPWdviN3GaoMFF8sOOV4ZNRCAbb8XFWHFu1N77gUX\nytzanlp48XvJt991v5QhT7oRbIaaoVzD8UwVfY2y5urTxxdqnWrWXd0rof8/9VXwjrCgNAeNALO1\nNvwFc80Jb5wpFZrRV/iyfyklWj8bm+6KuD277mlc2igPek9hW4OQhG31PdR3u6lZug7t5Juk1+/x\nW7n2JKlG3Pd6A8MePzltm6nRWtCWXBFSlAqqpU/1+EvSWxnllgXIN/ruZhe5uOVsE+evMy+hcgdh\nGX5jLc16h/FaZOKDacYdhHru1HzZ3gbJsEvUswbyuWTJlAqb1cKi8hwOtQ7ijTdFommrkN7wmCmH\nC1/FyRwacMT220HIzDDczcyCTPJd9oRl2VGfnz3NfbgYpc/v4DcvH4+7LXZX/JMj74gQ9agYlD1N\nfXRZlHLXjKZpVBdLHErg9d+Kgx5Sa8Uw4PMH+OFTh7BZNMpynWxv6Ikfe6MMC7mVoWk6U913pzLu\nkk0MCpoqItU7f0CnscdNVaH8JkpynAR06B6a4nLyBDGlPXe6rv9L1/UFuq7P1XX9DuO6r+q6/pDx\n/xFd19+l6/o8XdfX6bp+LOy+dxj3W6jr+mNh1+/Qdf1kXddX6Lp+pa7rPcb1Xbqun6vr+nxd18/T\ndX2cXdtppDEGqPy+xZdNr1N3onCGHShnnRI/T2ux4Zo98LD57UefFaVk+TVjaxk46zaJjNn0U2hL\nkHWl6xJ/YrGJMqhQvlwO6vGUu/3Ges0ig1JBMEcsGbl7WcjNKbfI+/Dqz1hQlsMMusnQvDhKTfrt\nQA76juxI5c7dDbseoDejks9Yb8ObN0dMJK27Q9vslgiTh/2nBjPt/rZNDphXra6Ec/6flAtf/w0L\nXvwk66pcvHCogyf3tXKtxYi1CX8fQdQ7z4CUHaPcsgCFWUKov3XlsuCorgjklCVV7hbNMPrukvVj\nRcPrZgQh5/HLssa4L9+onGz0NSZ3yipkl8JQO+g6Syty8fgDHGk3+cxH+qDzkPQQRznWW/tH8Ad0\nc7OHM0e+u+4uNE1jeWUedV3uuArmvuZ+NN8oFk3Hb8ng588fpSte836isqyJmcLrD3CgZYCZ5aWi\nWhokprooC7/Pg77lN7JWELKfIv66tZHjnUNcu7aK85eUMeINsLc5DoFVxCm3whilaJ965S7Z6DGF\nOFMqWvtH8Pp1ZoWRO3jjO2bfbIaKNNJ4Y6HyJLj6brjsJyd6JWNDWJO1aUlWoeZsIVE77wvtJMOh\njBQnpTAxIhyOLHjH/0g5N2zCQgzqX4G2PUKeww0fVru89+375MAbjX3/BDRYdNnY1hVcXwrKXX+L\n9MzNOgXO/JIQtpd+yDyXm7lWITsWMzMFiGpUMEfInTKFbPsD+IbJ2/gx/v2VS7Bf+gNx1D76Bdlm\nuBeOPIVeuoT+7Lk8squFwVEfj+xqoSTHyYa5RVJGv/ExqD4D9j/E//m+SY4+yP89spmLLZsZzJ4T\nq9Kqz//Yc6Zl2dsuWcyPr13FGfPjtBxkl0lbQoLG+IVlxmi1scaheIcZ0h3YrRqzC+OcgNgygtsy\n2Cp9XMnMFArZZaJWjfQGHbOmpormHYAu5qAoqNgaU+VO06Q0axhulhumit1KvTv2PDx2a9CRvq2+\nl0yENFSUFjE46uOnz8YZS5moLGsSYHyobQCPPyBryK0IqmhzirO4yLIF61ArnHyTfI9rX0psVjIw\n4vXzk2cOk2G38Klz57O2WhThLbVxtJVw5c7mlOSH1j2pOfLHC1WWTdpzZ551V98lJzxBcpdtkLs3\nuGM2Te7SSGMi0DRRrVSZ682CjDByl2hMmsMlOWoDzfDbiyOVpv5mOPiY9M6YHPSSYsEFMg2lcQu8\nfrf5Nir+ZN3NsbdVrQP0UKN7cF0t4mCdvWF8MSgQUjYTKXf1m+Ry9gbJlzzrNvAMkPnvb3P7eqN8\nHI/cARRWi/Iy1GEENN8Ndhfa6vdLn93884TUNrwKO++V3ke/B23Z1VyxqoJet5ev/XMvfcNerlhZ\nEZppmpkP73sQll5Fac82/ub8Ju8aeQCn5sO/5obYMnH1GeK8PPpsjFsWYFVVPleuTqB6qL67BKXZ\nuaVZ2CzamB2zutfNgM9GTXF25MzWcChy5xsJOWWTmSkUVI/sYDtLKhKYKpq2ymXlSbE3GeSuMj8O\n+XQVBQfSh/rujHjWl38Cr/1C+laRErvLIHczS4uZXeTinlfrQoaHcNhdQkzNTD9B5S6UcafKwcsU\nuRvpBc8Qc4qzuMH2hGy0/iPSytDflNisZOCeV+to6Rvhhg3VlOVmhJG7OH134codyL7DPwodB5M+\n17gRDDBOQu5yzMuyauxYVVq5SyONNN7wUFEoriKJ2EmEM78EZ90uAcK/uRg6D8v12/4oI4TGqtqF\n46Lvylqe+WZkxlTrbnjww6LAlS2T2I5ozDKyE6NLswceAfSQ+WI8UMpVInJXF0buQN6HkkWw/Y8s\n7n1erktUqg+PQzn4mLg8V75HyJnChd8W5fSp/xRlD2DZ1Vy1Wg5UD24TVSKGfNmccPVv4NRPME9r\n5Gbbo3iwkbf+A7HryMiFmWuFwKgD21jifFJwzDptVmpKZPpGYCyN6IZyNy+emQIi3bKpZtwphK19\n8YwcNA3zkmICcpdQuQM58Rvpg4Cf5TPlsw323amS+wvfB+8wO+p7meESFdvqzOJLFy7CF9D5/pMm\n5Cc4pcKE+AUDjEPK3Z4mIa3LKvLC+staWMxx1loOcST3VPm+Vp8htyXpuxsY8XLnc0fIcdr42Jny\nPa/IdVCZn8nrtd3mn3M0uQv23U1haba/yTBWJXHNqzVFK3fdUcpdmtylkUYab1hklwqBWXxZ5NxT\nM2ia5Cte8K2QgteyU4wUjhxRLseLnDI4/+sSpvzYl6TX556r4Renw+77hSxd9hNzU8LMtXIZbarY\nZxjlF4+zJAshcpOoLFv3ihCvGcYBymqDC+6QUuqx5+W6oOHGBME4lFpRbyBWocyvgo1fEHWv4VUh\nF4VzWFKRGzQpLCjLZmlFLjGwWODCO2hY+xUAtuWcG6HkRGDuObLuw08arz8BmYqGIkhJHbO5DHn8\nNPUmmQmscPhpNL+HTj0vMbkLd8sGnbJj6LkDGGzH5bAxpziLfS39sbNWm7bJ6zTp22rqlYO/ac8d\nGKq+lNUr8jIoynKwq7FPIoSGOoR4DDQz8O9f0tQ7zKpyI87JkcUly8tZWZXPo7ta2F4fpYYpddWs\nNGvSc7e7qQ+bMes3NEu1iZpj9wDwSKbxe5mzUS6T9N3d/e/j9Li93LyxRsbUHXoCvlXKNWUt9Li9\n5uPm+puElGYYJzAzEpsqfvHCUX6/qTbhOpKir0n66ZJlrcYxVKTJXRpppPHmQUauTEC56Lup32fD\nJ6VPbqhDwlv7m2TUnTOOizFVrPkPmWCy/yH4/aUSVjz7NLjuAfjYpsTZecULpCwbMMz0gx1icpi5\nLrk7LhFUGHbjFvPb3d0y9HzmySEHL0gpdd558v/MwsTleqXcHfyXqCRzNppPn9nwydDklbBsu6vX\niHp31eqZodw5E1S944u8cMkzVN3wq/hrUX13RvkwYupLMgTLsklMFUHHbAp9d8M98NAn8Ws2fuS7\nJr6ZAsLcsiOpjx5TCCp3Eou6tCKPgZHQ+DdADvYDzUKsTd7nxmBZNg65C8ahGKaKmXk09gwzUGdE\nq6z9MDhzcb7yY7IYZmmJ8X2yZ6JpGrdfLKatbz92IJJ0qs/IY6bcyYxhpdz5/AH2t/SzoCxHTDGK\nyLTuwrn/79Qxg0eGjO9e8QJ5XxL03XUPebjrpeMUZzv44OnGScprv4CAj7OdEuWz+bhJaba/WZ5b\nvY9lS6UlwES5G/H6+cETB/n+EwfHpvaGI+CXzy6ZmQLkvbLYY8hdXbcbh9VCWa6U/0tz5DLdc5dG\nGmm8MZFTHnIapoq1H4Irfx6a4zmRkqyCxSLqXF6VzLS96Wm48V/Sk5coNw+k784zAO1yQOHAI6JA\njdclq1C9UQ5wux8IjZkKh1ILZ58We9sFd8gBK9mYQBWHYuTjxQ3Atjnhnb+GJVfCyvcGr75hQzU/\nunYlHzy9OvHzAGeuO5nK4vz4G1SsjnQ7j6csO5BiHEqiEV8Kj30ZBpp5uvRG9uuzzWfKKtjDeu5U\nWTZV5S4rNIIMCDNVhJVmVb5dnL7Spt5hirOd5k5iiJhSASFTRcdho1d0zkY49RYcnh5utD7OoiLj\nsGyQt/U1RZy3uIzNx7vZdLQr9LjBsqxJHMpQpHJ3uH2QUV+AZcYkjiDZefl/wT/Kk1mXU99jZLdp\nmvTdDbaFWjCi8PtNtQyO+rjl7HlkOW1CiAy1ukaXVoEYU4VvVEinIpYgJfWSRVKeDkRm+u1r6ccX\n0Bkc9XG0Y+yjAAEh7QFfaid6FovsE6PKsg3dbmYWZganoxRlC/lu7x8Z35qmCWlyl0YaaYwNq66D\n9/8drrgTZiTp10sVpYvgs3vgPX+CqrWp3y8YZmyQLVWSXTKBfjuQEs6Ka6Xp/OBjsbfXvSyXs016\nAUsXwQefgMt/mvg58qqEBILEwiy8OP62M0+Cd/8+Qgl02CxctToy5HjcsNpC5TgYG7lLVblT81uT\nxaHsfxh23QsVa7hbvwKrRbLY4iLcLdvbICW/DJMytRnCyrJAsLwdYapoVuQutt/O5w/Q3DscvyQL\noaw7QxVV5M7XvEuuL18Gp3ycfi2Xm22PMtdpPHfYZ3DDBlGSXz7SGXrchGVZgwQa5E71+KnnDhKs\noXZwZHOk4nI8xmsBwvruzKfIPLWvDYfVwrtPNkj07gfkpArIGTxGvsseS+6CAcZRRKtilRDUKCK5\nq6E3+P8dYf8fE/pTjEFRyJkh7QUG0RwY8dI95AmWZNnxF+zP38EXMh9mY/cD8PpvJUkgKoz8jYA0\nuUsjjTTGjpqzYPX7TvQqIidVuLtlpFnF6tQb6hNh1XVyuePPsbfVvSKZYDPjENGqtclzD632kINv\n3Ydi8tOmHao0a8sc21pSVO4q8jLIybAlVu6GOuHhz4DVSe9FP2V/u5vZRa7EBDbCLVufekkWwsid\nodxVmMShKDNFxeqYu+9u6sPr1817HhXCplQArDBMFTm9BySSKH82Hls2P/ddRq7mxvnKj2X7sNK4\nuk8EyVGzZ03Lsp3y/cyINHAsiyZ3AKuuY0aZvA/HlSs3Qd9dc+8w+1r6OWVukah2ug47/mKMgJyN\n1nGItbOk9NzSF1Xejn5uiDupYlfYmLZxk7u+FGNQFHJniEnMKGs3hI0dY6AN/vFReOkHfEL/C7eM\n3g2PfAb+frP0CacQHTOdSJO7NNJI482LovlyAGt4TXrXdP/ES7IKpYuhYo30AIabBTxD0gA+Y9XY\nFC4zqHLo6vdP7HEmA4rcxQu0joeMPGOMV2LlTtM0FpblcLxziBGvyVgtXYdHPgvuTjrX38rl93Yw\nMOLjwqVJXI7KLdvfJFMq8menvnZHlpiChkS5K852UpbrDI7SIhCApu0SaZNZEHN3VSbdMDeOUQUi\nplQAlOU6mZkNpd5GCePWNPa39PNb73kM2IrElQ4Rn0Nepp25JVnsauwLjb1Sr9usLOvulOc12hp2\nN/VhtWgsNtRTMvJD5HHdzcwpNmbMdhnkrrBGokFq/x1DWp49IO/VuYsMYty6Czr2w4KLpAfVN8xZ\n5ZJ5GBGJkpTcRZoqdjb2ku204bBZJk7uUlXugkYTWWuEmaLJKKOf/EG+W/zffMTzWTxX/FKc/F1H\n4pawTxTS5C6NNNJ488Jikb67nuMyyQImFoESjVXXCWHcdX/ousYt0sdjNrJtrLjiTrhlyxsjJ7Gg\nWghromw+M2iaqHdJlDuQSRUBHfMpEHsehP0P0Ve6lvM2LaG+280nz5nHFy9YGLttOJRbVh1cU+23\nU8guCZZlQfruWvpGZLxU91EZfWdSkgV49ZiQu1NqEpG7kKEChOReVNKNlQDuQunL3FbfwwhOjiz6\naOh+UaaWVVUFkf1nicqyQ11BM8XgqI99Lf3ML80O9QVqmvTLnvoJKJ4fJHfHOoZCt885Q0ii6mc1\noMjdOYrc7bxXLle+NzixZ122KF9bjoeVZuOVSMuXA1qEctc/4uVoxxBnlY9yepmPA60D5icEyaCe\nM1VzVdSUioiMO2WuWnw5rSWn8URgLW2zLw+dmB1+Yuzrm0KkyV0aaaTx5oaaM9u8XQ4UkzkGbtnV\nUm7a8eeQghGdbzcROLPHH7Q8FfiPR6SfcqzIKRf1K6opHl2H9gPBCSQLy42+u2jHbOcRePTz+KyZ\nXNV4PUNenf9510o+f8FCLJYkphrllu08JJdjKcuCEFMVJI04ZsHou0uQbzfq87OltpuFZTkUZyeY\nXxxVlgU4xSWko84uUTnb6kWZyj/jw9J/CbHkbpZRmjW2jVuW9XmEkBqxN3c+d4QRb4CLl82I3O6i\n/4YL7wCgOlq5A9O8u2GPn5ePdLKwLEcIj98r/XauInGJlwgRn0MjGXZLZN9dPOXOkSUO3ZZdwe/J\nnoZe3md9ip+038i3h76KP6AnnMkbF0HlLtWybGTWXYRy1/g6oEHlmlAcyuAozD9f7nMoTe7SSCON\nNCYPqu8OJq8kq+AqhIWXSNmpebtcV7cJ0EIhym8lOHPGV2rOLpOG+qHOyOu3/R5+th4evAn8XhYb\njtmISRX9zeh/vBJGerlt5P10Z1Ryz03rufqkFA/Iyi2rTARjVu5KZe0G+Qr13fUlJHc7G/oY8QY4\nNVFJFsLcsqES5SJNSq87PLLW7fU9FLjsVJfmS9xQ1foYs9LqKiF321WJMl5ZVr0PrmLquoa4+6Xj\nVORlcPPG+JmLuRl2irIckZMwqk+Xy+MhU8Wmo52M+gKcs9hQ7Y4+K8R42TUSCVQs5M7WdZBVVfkc\nbBugb9gYLaZUtJwocgdiqvAMyFSM0UFKnvoE37L/Fqvuo2zkGLO0tvGVZvub5OQsK87ovGhEKXeK\n3FXlO+X3X7IQMvJCI8gGRuX7U7FGRiWajUI8QUiTuzTSSOPNjYo1Idfp4kkmdwCrrpfLHX8WVaRx\niww9N+nBetvCbARZIACbDMfw3r/B/TewoFhiJILKnbubwB+vQutr4Afed/F6wTv4+8dPY32iMmc0\nbFFxPmM100RN2Fgabqpo2irZZ2XLYu626agQ2YQlWZD+Ns0SIl1AqfswPt3CCz3FtA+M0NgzzOpZ\niKfl5wAAHnlJREFUBZJXuOACuOnJmO/XwvIcnOH9ZypfMiq6IzzA+FuP7sfjD3DbJYvJdCQ2yVQX\nZ9HQM4zXb8x5LqgWolz3clBReya6327nX+Ry5bVyWVgjRo6OQ6ytLkTXYVudQWr7m4VouUzeL9V3\nt+s++PU5zG9/nK2B+fSv+ywAGy27xkfu+ppEjUsW1K4QNV+2odtNUZaD7P4jMq2mUjI3S3OjgowX\nXCitGkeflad1e8efzTdJSJO7NNJI480NpzFpY+65ULJg8h9/7jmhzLuGV8WVORkl2bcSzEaQHX1G\nGs2XXiXuy4OPkvv3D1CTZxFy53Hju+fdWDoO8FvfhbxSeSN/+9iGYP9XypgouYvKuqsqcJHjtHG4\nuUvy18qXmeZBvnK0C02DU2qS9EtaLELwVFk2EMDRsY9ay0y2t7jZViekZc2sBDmEgN1qYXllHgdb\n+3F7fOLUzsiTkw5vWOaa4fSsG8nkqX1trKsu5NIVM+I8agjVRVn4A3oowFnTpDQ73APte9F1nWf3\nt5PvsrN61v9v786j4zjLfI9/n27t+2JZtmx5X2QntmVHSRyykBVCQnAYMlkgIThkWBLOAIdcLgNc\nLusw4WQYljvkDjMEAgMJmQAhdxhCdpIhC7HxGtvybsu2NtvabEmW1HrvH1UltfZuW1Ir8u9zjo/U\nVaXqalXKefy87/s8+dDWCDv+yxtSLfFrACaleAFefSXnz/aC0z8HQ7PNR7zM2GCBVtCp4qVvwdFK\nHg3fwD3JXyd79Z0AXJ28Jf7grqvDu6exDslCn/6ywe+itGdIlp6C6kHmri4I7ha+w/u60+vwcu8v\n/sKqrz9DW8dpzBMcJQruROSt7+aH4Y5fj825o2vePftlb9tg9e3OZkHmLnpV8WsPel8v+TS8/zHv\nf4B7nuMH9k1OtRyj5WfvJ+nIGzwReRtvLP4f/PxvVpOfmTLw3CNJjqoxl5wZf0Y1CAb//EPoOkXI\nX1WaemwbRDoGHZJt74yw4WAjS6fneK23RpJR2Ju5a9gHnSc5mrmQ2uZTPP2m9ztbNWvk6y4vzaPb\nwZZDTd4/as5b6wVzW/6j9yC/r+wTOzswgy/dsHTYDiaBuX4twT5Ds3P9eXf7XmZbdTM1ze1csXiq\nV9B32xMQOeX1Q44+f9FiONXEqoJ2Qgbr9h/35ua11Ay9anXaMi+rl5JN0w0/4nMnb+Pc0kKsYC4U\nzOdCe5PahhaOxtMVoqUacPF1qklO8+ZINh+hprmdjki3P9/OX0wRBHf9W5BNL/f+kbD7GbojETYd\naqQgI2XEbOlYUnAnIjKSoOZdMAdrljJ3fWT1K2Rcv9PL3M16mzfklpwOt/wclryHsvZN/Hfqp8iu\neoEXIyvYUvFNvv+BiqE7PIwklOQNe4IXqMUQyPSxdA3MuwJ2PgW/vAO6TrG0JIdltsfbP0hwt/5A\nAx2R7uFLoETLKPAyYM552UCgs8gb6v3PzdWEDJaXDp+5g6hFFUEW64KPeJ//tR/0Lvjxh2W3N6dy\n6/mlvbXtRhAsqth3dPBFFc9tH2yVrMGym/ueyJ93l9Wyl6UlOd7cxMYjgBu4mCKQlgNrn4J7XuWN\ndO89g9p+LLiKdNfGKtvFpniyd/EWMA7klEBLNQePRZdBWe8tcCnyVjcPCO5CIW84/WQ9R7a/Qkt7\nFytiuJ9jScGdiMhIgpp34A075Yw8zHVWye5XyPjP/+J9vTCqpVpSCtz0Yw6VesV6/9K9gP1XPcj/\nWlPe09rptJj1rpiNd6UseNma2x7xht93/QF+eTvnFqdSHho6uAvm2424mCKQUeiV1Glv6gnusmd7\nQ5EdkW4WFWeTlTpCY3u8zB1EBXe5M7y2dHXbYO8LALQ1evegPSWPz4xURibKnMJBVszmlXpz7/a9\nRMm6+/lQ0tNc6V73urYcfNXL7PX/nfvlUKivpGJ2AR2Rbvbu8cvUDBXcgdeFJa+UzYe8z7ai1A9K\n518FwGXhTfEFd01xlkEJZE+HjhNU13rB7Lycbq8cTMkqL4uPV3cwOWx9+8sufCcALVt+B8DymbEF\n1WNFwZ2ISCyC7J2ydgNFZ+7aGr2OBUGv4GjhJLJu+VcemPr31N/4KB+6/JzRef+g1l28K2UDyelw\n6yNeOY9dT/PubfdxXmgXJ0knUjCw7t+re44RDhnnz4mxPmF6VK272q0AlC65oGf3qtmxDSXPyEtn\nSlZq3/lnF93rX9QPANi6ay8A7169bPgSLf3MHSxzB9581o4T3NT2H3w56SdkPvEheORWb19Ur+Me\nwbzX+koumOt97qr9u71tMWTRNvmdKXoyd3MuwYWSuSy0uXelcCyOBQFlHHPuoOcfbo213ormsu7d\ngPOCT5+ZUZSVytGWqOBu/hUQSib3oLeoItGZu5H/qSAiIl5wd3QXVKxN9JVMPBmF3vBgSy1s+Bl0\nnoTzP9uT6YiWl5XOfffcO7rvn5wObZxe5q7nHGne0PFjd5C262nmGPwpcg7VG6u5Kaosy4lTXWw+\n1MSyGblkpyXHdu4MP3hra/Ayd9nTKSyeyYy8nRxubOspczISM6O8NI9nt9dS29xOcU4azFjldUnY\n/QxVlRs4XncEwvCet62I6+NnpiYxNTuVPXUn6Ip0kxT2cz/XfI3fpV7Hj596lY+vyuSqmd3efDYz\nrw5kf4ULAYP6Ss69yMtenaw/6O0bLnMHOOfYfKiR0oJ0CoL5l6lZ2KzVLNv/MlVVB+juvmDk2ocb\nfwEvPeBldKfH93sIFlW0HqsCSph5cpu3vV+rwaLsVLZXt+Cc8+Y0pmbD7LdRsu+PTA958zETSZk7\nEZFYpGTCdd/yhmilr1DIm1DefMRbmJCUDqs+OH7vH6yYPdOewslpcMu/w6J3AbCZhXzn2Z10dHX3\nHPLG/uN0dbvY59tBb/mPo7u8uWB+aZVgmLUi1gwgsNKfd7fh4MDs3ZE/fJt8a8YRIiUrjuvzrZqV\nz5Gmdv76X17lwLHebhX/72Aq61wZcy6/HS66B97xNbjmq70Z02gpGd59OFrJzPx0MlPCuKbY5r9V\nHW+jobWTFTP7BbsLvKHZFR0b+g4b9+ccvPxteOLj3jy+D/42/ikUfgAaaTpCSjhE9lG/vqVfBiVQ\nlJ1KR6Sb5raunm1dC7xVs7fm7zj9OaSjRMGdiIicuexiaD4EjQe9umfj2VItCO5yzzC4Ay9gufmn\ncOP/pWXVRznU0MYv11X17H7N7ycb83w76B2WDQoCT1sGwBeuX8JDH6qIq/zLgHl3AIuvoyt3NiuO\n/Z754Trvdx9rbbco979vOTesKGHDwUau++7LPPZGFae6Iry8q545hRnMi/U6i8rgZD2h9gYWT8sm\nrc1faDNC5m5TMN+uf3DXM+9umHp33RH4/f+E577iDcXe9QeYdeHgxw7Hv8akE9XMzEvDDq/3gtJ+\nQWJvl4reMjR78rzCz1cn9e2TmwgK7kRE5MwF8+4ALvzY0MeNhaAO3ZkMy0ZLSoHy21h79XmkJ4f5\n/nO7enqbvrLnGMlho2J2HMFrkLnb90fvqx/cleSlc2VZfO3nls/MxQw2VvV2vCAU5oXcvyLNOil0\nDVjmlLjOGcjNSOb7t63ku7eWEzLjs7/azE0PvsrJjghXlhXHVFIF6GlDRn0li6flUGzHcRb2ujkM\nI1hMMWAxQvG5dKZP4bLQFjYfPD7wBzvb4fG7vIU8U5fC3c/0XkO8/C4VOZ31rMxt8drqzawYcFhR\ntvffXF3UvLs3WvLZ2z2NRSfWQVccZVvGgII7ERE5c8GK2XmXj//QdVGZt6ozc/jgIe7TZqdy1yVz\nqGs5xU9f3U9TaydvHmliZWl+fDXMgixmUJ7DD+5OR3ZaMguKsthyqImI3wWhqa2TLxwo5wR+P9qM\n0wvuAmvKZ/D7T13KBXML2OL3dL16SRy/257gbgdLpmczzY7TllYEoeF/Z5uqmggZA8u3hEKEFlxF\nkTXRuH9D333d3fD4Wq/u3uyLYe3vR8wQDsv/2WnWwAXJ3uKU/kOyMEg5FGBTVSMvdK8kOdLqdfZI\nIAV3IiJy5qb4qyQv+sT4v/cN34N7XjutociRfOTS+WSnJfHgi3t4vrKWbger4xmShd5hWfDqpRUM\n3ec1FuWleZzsiLCrzmvj9u+vHaDuVDJ7Sv0FDqeZuYs2Mz+DR/5mNV+8fgkfuHAW58+NI1MZlEM5\nupOyqZkU08Dx8PD9XSPdjq1Hmlg4NZvMQcrChBdeDcCMY6/2ZFEBeOHrUPlfXheU238N6We4SjU9\nn0gohWI7znL8Vb79FlMAffvL+jYdauSVkF8yye9WkSgK7kRE5Mydfzd87E+w8Jrxf+9wUt9OFaMo\nNyOZj142j4bWTr78pLdyMq7FFNC3n+rUpSNmsEYSlNnYeLCR9s4IP/7TPrLTkph/w33eew0SjJyO\ncMi4+9J5fOO9y0gOxxEuTFnofa3fQVl2O8kW4XD38OVedtedoLUjMnR9uHlXAHAxm9he3ext2/or\nePkfvaztXz88aJu4uJnRnFzENGugtPVNr2/1ICtu+2fuTpzqYlfdCVpLVkNKllczMYEU3ImIyJlL\nSvX6sE5Cay+eS2FmCk1tnaQmhXpWrMYsuiXaGQzJBqIXVTy+/hBHT3Rwx+rZZE2dA/ftgrclIHsa\nLS3XKylSv5OcTq8Y8J724UuDBAWKh+zUkVVEQ+5SKkKVbN13BKo3wRP3eoHUbY+O6gKeWgqYQhOZ\nx9+E4nO8FcD9TO0X3G093IRzsGxWkVcvMbMI2ptH7ZripeBORERkGJmpSXz88vkAVMzJJzUpzsxb\nOAlS/YzUKAR3ZdOySUsOsf5AAz98aS8pSSHWXjzX23mGWcFRU7TIWz1dvxOAPadyOX6yY8jDg5Wy\n5f1XykabfyUpFiFp+xPwyPuhqw3+6oejPsdzf0cuIXNY5NSQWdCgQHTQpWJz9Erfmx6CDz/tlWNJ\nEAV3IiIiI7h99Wzef+Es7rl8YMeKmASZpVEI7pLCIZbNyGVX3QkOHm/l5oqZPcOEE0Yw727viwDU\nuEJ21Aydydp8qImUcIjF07KHPCb33GsBuLnmAS9wvOKLUHb9qF0ywLETpzjQGTU0PMhKWYD0lDDZ\nqUk9mbtNVUFnjdwJEWAruBMRERlBWnKYv3/vMi5ecJqLFbKKwULenLtREAzNhsxb9DHhBAts/J63\n1a6AHdUtgx7a1hFhR00zS0pySEkaOiwJzbqQNksnTDcdi98Dl90X1yU9t72WKx94kZ21g18HQGVN\nC7Uuaoh3mPmLRdmpPcHdxqpGCjNTmJk/NnM/46X2YyIiImPtnd/w2nalZo3K6VbNygf2cf3yEmYV\nDpwTlnBB5u5ELQA1roDKmsGDqlf2HKUzEkPXj6QUNpfcQvvBv8Dyr/H2WOvuAbvrWvjbRzZwsiPC\n77fUsKh48AzhjpoWapw/RzItFwqGDpyLslPZd+wktc3tHG5s44rFRbHXAhxjCu5ERETG2hDDe6fr\nmqXFfPH6JawpH76lV8JEFRF2GI3hgiGHZZ/f4S26uGLxyLX0Tl76ee76yTo+eaSDt58T26U0t3fy\nkZ+u52SHV0Jl3YFBCiH7dtQ0UxNk7macN2x5naLsVJzrvf4VMfYIHg8alhUREXmLSQqHuPvSeRNv\nrl0gc0pPCRjLKmbO1Dwqa1t6Ci8HnHO8WFlPbnoyq2JYhRy0JhuyDVk/3d2OTz+6kb1HT/LRy+Yx\nb0omGw42DriOQGVNC7tDc+meezlU3DXsuYPf/bPbvOykgjsRERGZ3Kb42bucEsqmZdPe2c3B4619\nDtlZe4LDjW1ctqiIpBhq6RVmpTKrIINNhxpxbvAALdp3nt3JczvquHThFD57bRnnzc7nxKmuQefd\nRbodlbUtzJhaSOjO38KSG4Y9dxDc/ffuo8AgPXETSMGdiIiIjL6iqOBuujfHbUd136HZ3iHZ4TtY\nRCsvzaOxtZP9x1qHPe6prTV87/ndlBak8/3bVhIOGRVzvPl06w40DDj+4PFW2ju7WTLMit1oQZeK\nU13dlBakU5CZEvNnGGsK7kRERGT0BYsqcmZQNs2r+ba936KKFyrrMIO3L4ovuAPYWDUwQAvsrjvB\nZx7bSHpymB/eUUFehhd4nTfbm0+3fv/AeXeV/pzA4cqxRIseEl8+gbJ2oOBORERExkLpBd7Xact6\nMneVUYsqmlo7WX+ggRUz8yjMin3uYLk/N2/DwaHn3T344h5OdkT4h/ctY8n03mLC86ZkkpeRzPqD\nAwPD7X6plrLpsRUfjg7uhi2+nAAK7kRERGT0zVgFn9oC5e+nKCuVgswUdkRl7l7aVU+k23Fl2cir\nZKMtnZ5DctiGXFTRFenm+R21FOekcsPykj77QiHjvFn5VB1vo665vc++oFRL2Wlk7ibSYgpQcCci\nIiJjJW8WhMKYGWXTsjlwrJWTp7oAb0gWiDu4S0sOs3R6Dturm2nvjAzYv/5AAw2tnVy9pJhQaGDd\nufOGmHe3o6aZvIzknr6xIynMTCVkXiHpc2ckrtXYYBTciYiIyJgL5t3trG2hu9vxx8p6irJTWRrj\nMGi08tI8OiOON48MrJ33jF+a5JqlxYP+7HmzvOBufVRw19rRxYHjrZRNy465EHE4ZJRNy+H8OQVk\npEysssET62pERERkUupZMVvTgplx7GQHN1fMHDS7NpKVs/J5+NUDbKxq5LzZ+T3bnXM8s72WrNQk\nLhqi48WK0jySw9Ync7ez9gTO9QagsXrsYxcxMXpS9KXgTkRERMZcMJdtR3Uz1U3efLd4h2QDvStm\n+86721V3ggPHWrl+2XRSk8KD/mxacphzSnLZeriJto4I6SnhnoUesc63C2SlTswwSsOyIiIiMuYW\nTs0mZF45lBd21JEcNi5eMOW0zjW7MIP8jOQB5VBGGpINnDc7n65ux+ZDXnAYrJSNtQzKRKfgTkRE\nRMZcekqYOVMy2XKoiS2Hmzh/TgHZacmndS4zY0VpHlXH2zh24lTP9qe31RIO2Yh9aitm911UEayU\nXVSs4E5EREQkZmXTsmnzV7iOFICNpP/QbG1zO5uqGrlwbgG5GcMHjcE8vfUHGnDOsaOmmdmFGWRO\n0GHWeCm4ExERkXERvWDhitOcbxfoH9w9uz22IVmAqTlplBak85eDDdS1nKKhtZPFkyRrBwruRERE\nZJwECxZmFWQwvyjzjM7VP7iLdb5doGJ2AY2tnfxuc3Wfa5sMxjS4M7NrzazSzHab2ecG2Z9qZr/0\n979uZnOi9v2dv73SzN4ZtX2/mW0xs41mti5q+5fN7LC/faOZXTeWn01ERETiUz4rj/TkMGvKS2Ku\nJzeUvIwU5k7JZGNVIy3tnbyy+xhLpucwMz8jpp8PhmZ//voBIPa2Y28FYza4bGZh4J+Ba4BDwBtm\n9qRzblvUYR8GGpxzC8zsVuB+4BYzWwrcCpwDlADPmtki51xQivoK59zRQd72n5xzD4zVZxIREZHT\nNzU7jde/cBWZo1T0t7w0j99sOMxP/rSfjkh3zFk76A3u9tSfBCbPSlkY28zdBcBu59xe51wH8Ciw\npt8xa4CH/e8fB64yL5RfAzzqnDvlnNsH7PbPJyIiIm9hOWnJhE+jcPFggqHZH760F4BrlsQe3C0q\nzibbX0CRmhRiTuGZDRNPJGMZ3M0AqqJeH/K3DXqMc64LaAIKR/hZBzxtZuvN7CP9zvcJM9tsZg+Z\nWT4iIiIyaQXBXcupLqbnpsXV4zUcMlb62btFxdmjFnBOBG/FBRWXOOdWAe8C7jWzy/ztDwLzgXKg\nGvjHkU7kz9NzZuaOHDkyZhcsIiIio2/J9BxSkrxQ5uolxXHP4wv6zE6mIVkY2+DuMFAa9Xqmv23Q\nY8wsCcgFjg33s8654Gsd8Bv84VrnXK1zLuKc6wb+lRiGcZ1zX3bOmXPOSkpK4v6AIiIikjgpSSHO\nKfGydfHMtwtcWTaVkMHFCwbvQ/tWNZbB3RvAQjOba2YpeAsknux3zJPAnf73NwHPO+ecv/1WfzXt\nXGAh8GczyzSzbAAzywTeAWz1X0+POu97g+0iIiIyed19yTxuLC/hovnxB2jLZuay4Uvv4Mby/rPG\n3trGbLWsc67LzD4B/AEIAw855940s68C65xzTwI/An5mZruB43gBIP5xjwHbgC7gXudcxMyKgd/4\nadck4BfOuaf8t/yWmZXjzcnbD3x0rD6biIiITAzXL5/O9cunj3zgEHLTT68F2kRmXqJMKioq3Lp1\n60Y+UERERCTBzGy9c65isH1vxQUVIiIiIjIEBXciIiIik4iCOxEREZFJRMGdiIiIyCSi4E5ERERk\nElFwJyIiIjKJKLgTERERmUQU3ImIiIhMIgruRERERCYRdajwmVk9cGAc3qoEODIO7yPx0X2ZuHRv\nJibdl4lL92ZiGu37Mts5VzTYDgV348zMnHPOEn0d0pfuy8SlezMx6b5MXLo3E9N43hcNy4qIiIhM\nIgruRERERCYRBXfj7yuJvgAZlO7LxKV7MzHpvkxcujcT07jdF825ExEREZlElLkTERERmUQU3ImI\niIhMIgruRERERCYRBXciIiIik4iCOxEREZFJRMHdODGza82s0sx2m9nnEn09ZzMzKzWzF8xsm5m9\naWaf9LcXmNkzZrbL/5qf6Gs9G5lZ2Mw2mNl/+q/nmtnr/rPzSzNLSfQ1no3MLM/MHjezHWa23cwu\n0jOTeGb2af/vsa1m9oiZpemZSQwze8jM6sxsa9S2QZ8R83zPv0ebzWzVaF6LgrtxYGZh4J+BdwFL\ngdvMbGlir+qs1gV8xjm3FFgN3Ovfj88BzznnFgLP+a9l/H0S2B71+n7gn5xzC4AG4MMJuSr5LvCU\nc64MWIF3j/TMJJCZzQD+Fqhwzp0LhIFb0TOTKD8Bru23bahn5F3AQv/PR4AHR/NCFNyNjwuA3c65\nvc65DuBRYE2Cr+ms5Zyrds79xf++Be9/UjPw7snD/mEPAzcm5grPXmY2E7ge+Df/tQFXAo/7h+i+\nJICZ5QKXAT8CcM51OOca0TMzESQB6WaWBGQA1eiZSQjn3EvA8X6bh3pG1gA/dZ7XgDwzmz5a16Lg\nbnzMAKqiXh/yt0mCmdkcYCXwOlDsnKv2d9UAxQm6rLPZd4DPAt3+60Kg0TnX5b/Ws5MYc4F64Mf+\nkPm/mVkmemYSyjl3GHgAOIgX1DUB69EzM5EM9YyMaVyg4E7OWmaWBfwK+JRzrjl6n/Nat6h9yzgy\ns3cDdc659Ym+FhkgCVgFPOicWwmcpN8QrJ6Z8efP31qDF3yXAJkMHBaUCWI8nxEFd+PjMFAa9Xqm\nv00SxMyS8QK7nzvnfu1vrg3S4v7XukRd31nqYuA9ZrYfb+rClXjzvPL8ISfQs5Moh4BDzrnX/deP\n4wV7emYS62pgn3Ou3jnXCfwa7znSMzNxDPWMjGlcoOBufLwBLPRXMKXgTXh9MsHXdNby53H9CNju\nnPt21K4ngTv97+8Efjve13Y2c879nXNupnNuDt4z8rxz7gPAC8BN/mG6LwngnKsBqsxssb/pKmAb\nemYS7SCw2swy/L/XgvuiZ2biGOoZeRL4oL9qdjXQFDV8e8bMyxLKWDOz6/DmE4WBh5xz30jwJZ21\nzOwS4GVgC71zuz6PN+/uMWAWcAC42TnXf3KsjAMzuxy4zzn3bjObh5fJKwA2ALc7504l8vrORmZW\njrfQJQXYC6zFSxDomUkgM/sKcAteFYANwN14c7f0zIwzM3sEuByYAtQC/xt4gkGeET8Y/z94w+it\nwFrn3LpRuxYFdyIiIiKTh4ZlRURERCYRBXciIiIik4iCOxEREZFJRMGdiIiIyCSi4E5ERERkEkka\n+RARkbObX1i53f8TuNE5t38U32MOsM45N2W0zikiZycFdyIisbnJObc10RchIjISDcuKiJwmM3Nm\n9hUz22hmlWb2vqh915rZBjPbbGbPmdmCqH13mdkm/88bZlYcte8b/s9V+gW3RUTiosydiEhsHjez\nYFi2yzlX4X8fcc6V+625XjGzl/3tPwPe7pzbZmYfBn4OXOh33/g8cIlzrsbMsvC6C6QDhcCrzrkv\nmNkHgPvxeoWKiMRMHSpEREbgz7l7d/9hWTNzwEzn3GH/9TPA9wEHfNI5d7W/PQS04bUl+hLQ4pz7\nar9zzQG2OOey/dfzgT8556aN3ScTkclIw7IiIhNHdP/PCBpdEZHToOBOROTMrAUws4XASuA1/88K\nMyvzj7kT2OCcawF+B3wwmGdnZllmljb+ly0ik5X+VSgiEpvoOXcAd/tfk8xsA5ABfNQ5VwdgZncA\nvzCzJKAeuB3AOfeimX0TeNbMuvGydTeM14cQkclPc+5ERE6TP+cu2zl3ItHXIiIS0LCsiIiIyCSi\nzJ2IiIjIJKLMnYiIiMgkouBOREREZBJRcCciIiIyiSi4ExEREZlEFNyJiIiITCIK7kREREQmkf8P\nOjmvZ6Y2QtgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#epochs plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.savefig('lstm2plot.png')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "9PIQn9fnxa6H",
    "outputId": "a698cdc3-ba8e-4386-f8b6-d7a0f294abb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on the data: 0.5000\n",
      "RMSE on the data: 0.6311\n",
      "MAPE on the data: 13.1000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAFACAYAAACLPLm0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#vizualising result\n",
    "errors = abs(predicted_birth - Y_test)\n",
    "MAE=round(np.mean(errors), 2)\n",
    "rmse =np.sqrt(mean_squared_error(Y_test,predicted_birth))\n",
    "mape = 100 * (errors / Y_test)\n",
    "MAPE=round(np.mean(mape), 2)\n",
    "print('MAE on the data: %.4f' %MAE)\n",
    "print('RMSE on the data: %.4f' %rmse)\n",
    "print('MAPE on the data: %.4f' %MAPE)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(training_set,'o-',color='green',label='data')\n",
    "plt.plot(range(0,380),training_set[0:380], color='red', label='Training data')\n",
    "plt.plot(range(380,449) ,predicted_birth, color='blue', label='Predicted data')\n",
    "plt.xlabel('Draw.up.date.index')\n",
    "plt.ylabel('MVA8')\n",
    "plt.legend()\n",
    "#plt.savefig('lstm3plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVwODtTcEAEg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_Grid_search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
